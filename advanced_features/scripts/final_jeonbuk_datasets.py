"""
ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±ê¸°
===============================================
Tour API SSL ë¬¸ì œ ìš°íšŒë¥¼ ìœ„í•´ ì¢Œí‘œ ê¸°ë°˜ ì§€ì—­ ë¶„ë¥˜ ì‚¬ìš©

í•µì‹¬ ìš”êµ¬ì‚¬í•­:
1. ì „ë¶ 14ê°œ ì§€ì—­ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
2. ê´€ê´‘ì§€/ìˆ™ë°•/ìŒì‹ì  3ê°œ íƒ€ì…ìœ¼ë¡œ ë¶„ë¥˜
3. ì´ 42ê°œ ë°ì´í„°ì…‹ ìƒì„± (14 Ã— 3)
4. ìƒì„¸ ì£¼ì†Œ ì •ë³´ ìµœëŒ€í•œ í™œìš©
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional

from app.utils.region_mapping import get_region_list

def classify_by_coordinates(lat: float, lon: float) -> Optional[str]:
    """ì¢Œí‘œ ê¸°ë°˜ ì „ë¶ 14ê°œ ì§€ì—­ ë¶„ë¥˜
    
    ì „ë¶ ê° ì‹œ/êµ°ì˜ ëŒ€ëµì ì¸ ì¢Œí‘œ ë²”ìœ„ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜
    """
    if pd.isna(lat) or pd.isna(lon) or lat == 0 or lon == 0:
        return None
    
    # ì „ë¶ ì§€ì—­ë³„ ì¢Œí‘œ ë²”ìœ„ (ëŒ€ëµì )
    region_bounds = {
        "ì „ì£¼ì‹œ": {"lat_min": 35.75, "lat_max": 35.90, "lon_min": 127.05, "lon_max": 127.20},
        "êµ°ì‚°ì‹œ": {"lat_min": 35.90, "lat_max": 36.05, "lon_min": 126.65, "lon_max": 126.85},
        "ìµì‚°ì‹œ": {"lat_min": 35.90, "lat_max": 36.05, "lon_min": 126.90, "lon_max": 127.10},
        "ì •ìì‹œ": {"lat_min": 35.50, "lat_max": 35.70, "lon_min": 126.80, "lon_max": 127.00},
        "ë‚¨ì›ì‹œ": {"lat_min": 35.35, "lat_max": 35.50, "lon_min": 127.30, "lon_max": 127.50},
        "ê¹€ì œì‹œ": {"lat_min": 35.75, "lat_max": 35.90, "lon_min": 126.85, "lon_max": 127.05},
        "ì™„ì£¼êµ°": {"lat_min": 35.85, "lat_max": 36.05, "lon_min": 127.15, "lon_max": 127.45},
        "ì§„ì•ˆêµ°": {"lat_min": 35.75, "lat_max": 35.95, "lon_min": 127.40, "lon_max": 127.60},
        "ë¬´ì£¼êµ°": {"lat_min": 35.85, "lat_max": 36.05, "lon_min": 127.60, "lon_max": 127.80},
        "ì¥ìˆ˜êµ°": {"lat_min": 35.60, "lat_max": 35.80, "lon_min": 127.50, "lon_max": 127.70},
        "ì„ì‹¤êµ°": {"lat_min": 35.60, "lat_max": 35.75, "lon_min": 127.25, "lon_max": 127.45},
        "ìˆœì°½êµ°": {"lat_min": 35.35, "lat_max": 35.50, "lon_min": 127.10, "lon_max": 127.30},
        "ê³ ì°½êµ°": {"lat_min": 35.40, "lat_max": 35.60, "lon_min": 126.65, "lon_max": 126.85},
        "ë¶€ì•ˆêµ°": {"lat_min": 35.65, "lat_max": 35.80, "lon_min": 126.70, "lon_max": 126.90}
    }
    
    # ì¢Œí‘œê°€ í¬í•¨ë˜ëŠ” ì§€ì—­ ì°¾ê¸°
    for region, bounds in region_bounds.items():
        if (bounds["lat_min"] <= lat <= bounds["lat_max"] and 
            bounds["lon_min"] <= lon <= bounds["lon_max"]):
            return region
    
    # ê°€ì¥ ê°€ê¹Œìš´ ì§€ì—­ ì°¾ê¸° (ì˜ˆì™¸ ì²˜ë¦¬)
    min_distance = float('inf')
    closest_region = None
    
    for region, bounds in region_bounds.items():
        center_lat = (bounds["lat_min"] + bounds["lat_max"]) / 2
        center_lon = (bounds["lon_min"] + bounds["lon_max"]) / 2
        
        # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
        distance = ((lat - center_lat) ** 2 + (lon - center_lon) ** 2) ** 0.5
        
        if distance < min_distance:
            min_distance = distance
            closest_region = region
    
    return closest_region

def classify_by_address(address: str) -> Optional[str]:
    """ì£¼ì†Œ ê¸°ë°˜ ì „ë¶ 14ê°œ ì§€ì—­ ë¶„ë¥˜"""
    if not address or pd.isna(address):
        return None
        
    region_keywords = {
        "ê³ ì°½êµ°": ["ê³ ì°½êµ°", "ê³ ì°½ì", "ê³ ì°½"],
        "êµ°ì‚°ì‹œ": ["êµ°ì‚°ì‹œ", "êµ°ì‚°"],
        "ê¹€ì œì‹œ": ["ê¹€ì œì‹œ", "ê¹€ì œ"],
        "ë‚¨ì›ì‹œ": ["ë‚¨ì›ì‹œ", "ë‚¨ì›"],
        "ë¬´ì£¼êµ°": ["ë¬´ì£¼êµ°", "ë¬´ì£¼ì", "ë¬´ì£¼"],
        "ë¶€ì•ˆêµ°": ["ë¶€ì•ˆêµ°", "ë¶€ì•ˆì", "ë¶€ì•ˆ"],
        "ìˆœì°½êµ°": ["ìˆœì°½êµ°", "ìˆœì°½ì", "ìˆœì°½"],
        "ì™„ì£¼êµ°": ["ì™„ì£¼êµ°", "ì™„ì£¼"],
        "ìµì‚°ì‹œ": ["ìµì‚°ì‹œ", "ìµì‚°"],
        "ì„ì‹¤êµ°": ["ì„ì‹¤êµ°", "ì„ì‹¤ì", "ì„ì‹¤"],
        "ì¥ìˆ˜êµ°": ["ì¥ìˆ˜êµ°", "ì¥ìˆ˜ì", "ì¥ìˆ˜"],
        "ì „ì£¼ì‹œ": ["ì „ì£¼ì‹œ", "ì „ì£¼", "ì™„ì‚°êµ¬", "ë•ì§„êµ¬"],
        "ì •ìì‹œ": ["ì •ìì‹œ", "ì •ì"],
        "ì§„ì•ˆêµ°": ["ì§„ì•ˆêµ°", "ì§„ì•ˆì", "ì§„ì•ˆ"]
    }
    
    for region, keywords in region_keywords.items():
        for keyword in keywords:
            if keyword in address:
                return region
    
    return None

def process_attractions_data() -> Dict[str, List[dict]]:
    """ê´€ê´‘ì§€ ë°ì´í„°ë¥¼ ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ ì§€ì—­ë³„ ë¶„ë¥˜"""
    print("ğŸ¯ 1ë‹¨ê³„: ê´€ê´‘ì§€ ë°ì´í„° ì¢Œí‘œ ê¸°ë°˜ ì§€ì—­ ë¶„ë¥˜")
    print("=" * 60)
    
    # ê¸°ì¡´ ê´€ê´‘ì§€ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv("data/tour_api_attractions.csv")
    print(f"ğŸ“„ ê´€ê´‘ì§€ ë°ì´í„° ë¡œë“œ: {len(df)}ê±´")
    
    regional_data = {region: [] for region in get_region_list()}
    
    coord_classified = 0
    failed_classification = 0
    
    for idx, row in df.iterrows():
        # ì¢Œí‘œ ê¸°ë°˜ ë¶„ë¥˜ ì‹œë„
        lat = row.get('lat')
        lon = row.get('lon')
        
        region = None
        classification_method = ""
        
        if pd.notna(lat) and pd.notna(lon) and lat != 0 and lon != 0:
            region = classify_by_coordinates(float(lat), float(lon))
            if region:
                classification_method = "ì¢Œí‘œ"
                coord_classified += 1
        
        if region:
            data = {
                "name": row.get('name', ''),
                "region": region,
                "address_full": row.get('region', ''),  # ì›ë³¸ ì£¼ì†Œ ë³´ì¡´
                "address_detail": "",
                "lat": lat,
                "lon": lon,
                "contentid": row.get('contentid', ''),
                "contenttypeid": 12,
                "tel": "",
                "zipcode": "",
                "image_url": row.get('image_url', ''),
                "overview": "",
                "tags": row.get('tags', ''),
                "keywords": row.get('keywords', ''),
                "classification_method": classification_method
            }
            regional_data[region].append(data)
        else:
            failed_classification += 1
    
    print(f"ğŸ“Š ë¶„ë¥˜ ê²°ê³¼:")
    print(f"    ì¢Œí‘œ ê¸°ë°˜: {coord_classified}ê±´")
    print(f"    ë¶„ë¥˜ ì‹¤íŒ¨: {failed_classification}ê±´")
    
    print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ê´€ê´‘ì§€ ë¶„í¬:")
    for region in get_region_list():
        count = len(regional_data[region])
        if count > 0:
            print(f"    {region}: {count}ê±´")
    
    return regional_data

def process_existing_files() -> Dict[str, Dict[str, List[dict]]]:
    """ê¸°ì¡´ íŒŒì¼ë“¤ì„ ì£¼ì†Œ ê¸°ë°˜ìœ¼ë¡œ ì§€ì—­ë³„ ë¶„ë¥˜"""
    print("\nğŸ¯ 2ë‹¨ê³„: ê¸°ì¡´ íŒŒì¼ë“¤ ì£¼ì†Œ ê¸°ë°˜ ì§€ì—­ ë¶„ë¥˜")
    print("=" * 60)
    
    file_mappings = {
        "cultural": ("tour_api_cultural.csv", 14),
        "festivals": ("tour_api_festivals.csv", 15),
        "leisure": ("tour_api_leisure.csv", 28), 
        "shopping": ("tour_api_shopping.csv", 38)
    }
    
    all_regional_data = {}
    
    for category, (filename, content_type_id) in file_mappings.items():
        print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {filename}")
        
        try:
            df = pd.read_csv(f"data/{filename}")
            print(f"    ë°ì´í„° ë¡œë“œ: {len(df)}ê±´")
            
            regional_data = {region: [] for region in get_region_list()}
            classified_count = 0
            
            for idx, row in df.iterrows():
                # ì£¼ì†Œ ê¸°ë°˜ ë¶„ë¥˜
                addr1 = row.get('region', '')
                region = classify_by_address(addr1)
                
                if region:
                    data = {
                        "name": row.get('name', ''),
                        "region": region,
                        "address_full": addr1,
                        "address_detail": "",
                        "lat": row.get('lat'),
                        "lon": row.get('lon'),
                        "contentid": row.get('contentid', ''),
                        "contenttypeid": content_type_id,
                        "tel": "",
                        "zipcode": "",
                        "image_url": row.get('image_url', ''),
                        "overview": "",
                        "tags": row.get('tags', ''),
                        "keywords": row.get('keywords', ''),
                        "classification_method": "ì£¼ì†Œ"
                    }
                    regional_data[region].append(data)
                    classified_count += 1
            
            print(f"    ë¶„ë¥˜ ì„±ê³µ: {classified_count}/{len(df)}ê±´")
            
            # ì§€ì—­ë³„ í†µê³„
            print(f"    ì§€ì—­ë³„ ë¶„í¬:")
            for region in get_region_list():
                count = len(regional_data[region])
                if count > 0:
                    print(f"        {region}: {count}ê±´")
            
            all_regional_data[category] = regional_data
            
        except Exception as e:
            print(f"    âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            all_regional_data[category] = {region: [] for region in get_region_list()}
    
    return all_regional_data

def create_accommodations_and_restaurants() -> Dict[str, Dict[str, List[dict]]]:
    """ìˆ™ë°•ê³¼ ìŒì‹ì ì€ ë¹ˆ ë°ì´í„°ë¡œ ìƒì„± (Tour API ì ‘ê·¼ ë¶ˆê°€)"""
    print("\nğŸ¯ 3ë‹¨ê³„: ìˆ™ë°•/ìŒì‹ì  ë¹ˆ ë°ì´í„°ì…‹ ìƒì„±")
    print("=" * 60)
    print("    Tour API SSL ë¬¸ì œë¡œ ì¸í•´ ë¹ˆ ë°ì´í„°ì…‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
    
    return {
        "accommodations": {region: [] for region in get_region_list()},
        "restaurants": {region: [] for region in get_region_list()}
    }

def save_final_datasets(attractions_data: Dict[str, List[dict]], 
                       existing_data: Dict[str, Dict[str, List[dict]]], 
                       empty_data: Dict[str, Dict[str, List[dict]]]) -> List[str]:
    """ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ = 42ê°œ ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥"""
    print("\nğŸ¯ 4ë‹¨ê³„: 42ê°œ ì§€ì—­ë³„ ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥")
    print("=" * 60)
    
    data_dir = Path("data2")
    data_dir.mkdir(exist_ok=True)
    
    saved_files = []
    regions = get_region_list()
    
    for region in regions:
        print(f"\nğŸ“ {region} ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        # 1. ê´€ê´‘ì§€ ë°ì´í„°
        attractions_file = f"jeonbuk_{region}_attractions.csv"
        attractions_path = data_dir / attractions_file
        
        attractions_items = attractions_data.get(region, [])
        df_attractions = pd.DataFrame(attractions_items)
        df_attractions.to_csv(attractions_path, index=False, encoding='utf-8')
        
        if len(attractions_items) > 0:
            print(f"    âœ… {attractions_file}: {len(df_attractions)}ê±´")
        else:
            print(f"    ğŸ“„ {attractions_file}: 0ê±´")
        saved_files.append(attractions_file)
        
        # 2. ìˆ™ë°• ë°ì´í„° (ë¹ˆ íŒŒì¼)
        accommodations_file = f"jeonbuk_{region}_accommodations.csv"
        accommodations_path = data_dir / accommodations_file
        
        df_empty = pd.DataFrame()
        df_empty.to_csv(accommodations_path, index=False, encoding='utf-8')
        print(f"    ğŸ“„ {accommodations_file}: 0ê±´ (ë¹ˆ íŒŒì¼)")
        saved_files.append(accommodations_file)
        
        # 3. ìŒì‹ì  ë°ì´í„° (ë¹ˆ íŒŒì¼)
        restaurants_file = f"jeonbuk_{region}_restaurants.csv"
        restaurants_path = data_dir / restaurants_file
        
        df_empty.to_csv(restaurants_path, index=False, encoding='utf-8')
        print(f"    ğŸ“„ {restaurants_file}: 0ê±´ (ë¹ˆ íŒŒì¼)")
        saved_files.append(restaurants_file)
    
    return saved_files

def validate_datasets():
    """ìƒì„±ëœ ë°ì´í„°ì…‹ ê²€ì¦"""
    print("\nğŸ¯ 5ë‹¨ê³„: ìƒì„±ëœ ë°ì´í„°ì…‹ ê²€ì¦")
    print("=" * 60)
    
    data_dir = Path("data2")
    regions = get_region_list()
    types = ["attractions", "accommodations", "restaurants"]
    
    total_files = 0
    valid_files = 0
    
    for region in regions:
        for data_type in types:
            filename = f"jeonbuk_{region}_{data_type}.csv"
            file_path = data_dir / filename
            
            total_files += 1
            
            if file_path.exists():
                try:
                    df = pd.read_csv(file_path)
                    print(f"    âœ… {filename}: {len(df)}ê±´")
                    valid_files += 1
                except Exception as e:
                    print(f"    âŒ {filename}: ì½ê¸° ì‹¤íŒ¨ - {e}")
            else:
                print(f"    âŒ {filename}: íŒŒì¼ ì—†ìŒ")
    
    print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
    print(f"    ì „ì²´ íŒŒì¼: {total_files}ê°œ")
    print(f"    ìœ íš¨ íŒŒì¼: {valid_files}ê°œ")
    print(f"    ì„±ê³µë¥ : {valid_files/total_files*100:.1f}%")
    
    expected_files = len(regions) * len(types)
    print(f"    ì˜ˆìƒ íŒŒì¼: {expected_files}ê°œ (14ê°œ ì§€ì—­ Ã— 3ê°œ íƒ€ì…)")
    
    if valid_files == expected_files:
        print(f"    ğŸ‰ 42ê°œ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    else:
        print(f"    âš ï¸ ì¼ë¶€ íŒŒì¼ ëˆ„ë½ ë˜ëŠ” ì˜¤ë¥˜")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸŒŸ ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±ê¸°")
    print("=" * 70)
    print("ğŸ“Œ í•µì‹¬ ìš”êµ¬ì‚¬í•­:")
    print("   1. ì „ë¶ 14ê°œ ì§€ì—­ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬")
    print("   2. ê´€ê´‘ì§€/ìˆ™ë°•/ìŒì‹ì  3ê°œ íƒ€ì…ìœ¼ë¡œ ë¶„ë¥˜") 
    print("   3. ì´ 42ê°œ ë°ì´í„°ì…‹ ìƒì„± (14 Ã— 3)")
    print("   4. ì¢Œí‘œ/ì£¼ì†Œ ê¸°ë°˜ ì§€ì—­ ë¶„ë¥˜ ì‚¬ìš©")
    print()
    
    try:
        # 1ë‹¨ê³„: ê´€ê´‘ì§€ ë°ì´í„° ì²˜ë¦¬ (ì¢Œí‘œ ê¸°ë°˜)
        attractions_data = process_attractions_data()
        
        # 2ë‹¨ê³„: ê¸°ì¡´ íŒŒì¼ë“¤ ì²˜ë¦¬ (ì£¼ì†Œ ê¸°ë°˜)
        existing_data = process_existing_files()
        
        # 3ë‹¨ê³„: ìˆ™ë°•/ìŒì‹ì  ë¹ˆ ë°ì´í„°
        empty_data = create_accommodations_and_restaurants()
        
        # 4ë‹¨ê³„: 42ê°œ ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥
        saved_files = save_final_datasets(attractions_data, existing_data, empty_data)
        
        # 5ë‹¨ê³„: ê²€ì¦
        validate_datasets()
        
        print(f"\nâœ… ì „ë¶ ì§€ì—­ë³„ ê´€ê´‘ì§€ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“Š ìƒì„±ëœ íŒŒì¼: {len(saved_files)}ê°œ")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: data2/")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()