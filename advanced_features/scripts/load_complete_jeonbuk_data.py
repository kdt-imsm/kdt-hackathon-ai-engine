"""
ì „ë¶ 14ê°œ ì§€ì—­ì˜ ê´€ê´‘ì§€, ìˆ™ë°•, ìŒì‹ì  ë°ì´í„°ë¥¼ ì™„ì „íˆ ë°ì´í„°ë² ì´ìŠ¤ì— ë¡œë“œ
System_Improvements.md ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ ì™„ì „í•œ ë°ì´í„° í†µí•©
"""

import pandas as pd
from pathlib import Path
from app.db.database import SessionLocal, Base, engine
from app.db.models import TourSpot
from app.embeddings.embedding_service import embed_texts
from sqlalchemy import func

def load_complete_jeonbuk_data():
    """ì „ë¶ 14ê°œ ì§€ì—­ì˜ ëª¨ë“  ìœ í˜• ë°ì´í„°ë¥¼ ì™„ì „íˆ ë¡œë“œ"""
    
    print("ğŸŒ¾ ì „ë¶ ì™„ì „ ë°ì´í„° ë¡œë“œ ì‹œì‘ (ê´€ê´‘ì§€+ìˆ™ë°•+ìŒì‹ì )")
    print("=" * 60)
    
    # í…Œì´ë¸” ìƒì„±
    Base.metadata.create_all(bind=engine)
    
    # ì§€ì—­ë³„ ë°ì´í„° í´ë”
    regional_dir = Path('data/regional')
    all_data = []
    
    # ì „ë¶ 14ê°œ ì§€ì—­
    jeonbuk_regions = [
        'ê³ ì°½êµ°', 'êµ°ì‚°ì‹œ', 'ê¹€ì œì‹œ', 'ë‚¨ì›ì‹œ', 'ë¬´ì£¼êµ°', 'ë¶€ì•ˆêµ°', 'ìˆœì°½êµ°',
        'ì™„ì£¼êµ°', 'ìµì‚°ì‹œ', 'ì„ì‹¤êµ°', 'ì¥ìˆ˜êµ°', 'ì „ì£¼ì‹œ', 'ì •ìì‹œ', 'ì§„ì•ˆêµ°'
    ]
    
    # ë°ì´í„° ìœ í˜•ë³„
    data_types = ['attractions', 'accommodations', 'restaurants']
    data_type_korean = {
        'attractions': 'ê´€ê´‘ì§€',
        'accommodations': 'ìˆ™ë°•ì‹œì„¤', 
        'restaurants': 'ìŒì‹ì '
    }
    
    # ì§€ì—­ë³„, ìœ í˜•ë³„ ë°ì´í„° ìˆ˜ì§‘ í†µê³„
    region_stats = {}
    type_stats = {'attractions': 0, 'accommodations': 0, 'restaurants': 0}
    
    for region in jeonbuk_regions:
        print(f"ğŸ“ {region} ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        region_dir = regional_dir / region
        region_total = 0
        
        region_stats[region] = {'attractions': 0, 'accommodations': 0, 'restaurants': 0}
        
        for data_type in data_types:
            data_file = region_dir / f"{data_type}.csv"
            
            if data_file.exists():
                try:
                    df = pd.read_csv(data_file)
                    
                    type_data = []
                    for _, row in df.iterrows():
                        name = str(row.get('name', '')).strip()
                        if name and name != 'nan':
                            type_data.append({
                                'name': name,
                                'region': region,
                                'data_type': data_type,
                                'data_type_korean': data_type_korean[data_type],
                                'contentid': str(row.get('contentid', '')),
                                'tags': str(row.get('tags', data_type)),
                                'keywords': str(row.get('keywords', '')),
                                'lat': float(row.get('lat', 0)) if pd.notna(row.get('lat')) else None,
                                'lon': float(row.get('lon', 0)) if pd.notna(row.get('lon')) else None,
                            })
                    
                    region_stats[region][data_type] = len(type_data)
                    type_stats[data_type] += len(type_data)
                    region_total += len(type_data)
                    all_data.extend(type_data)
                    
                    print(f"  - {data_type_korean[data_type]}: {len(type_data)}ê°œ")
                    
                except Exception as e:
                    print(f"  âŒ {data_type} ë¡œë“œ ì‹¤íŒ¨: {e}")
                    region_stats[region][data_type] = 0
            else:
                print(f"  âš ï¸ {data_type}.csv íŒŒì¼ ì—†ìŒ")
                region_stats[region][data_type] = 0
        
        print(f"  {region} ì†Œê³„: {region_total}ê°œ")
        print()
    
    print("=" * 60)
    print(f"ğŸ¯ ì „ë¶ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_data)}ê°œ")
    print()
    
    # ìœ í˜•ë³„ í†µê³„
    print("ğŸ“Š ìœ í˜•ë³„ í†µê³„:")
    for data_type, count in type_stats.items():
        print(f"  {data_type_korean[data_type]}: {count}ê°œ")
    print()
    
    # ì§€ì—­ë³„ í†µê³„ (ìƒìœ„ 5ê°œ)
    region_totals = {region: sum(stats.values()) for region, stats in region_stats.items()}
    sorted_regions = sorted(region_totals.items(), key=lambda x: x[1], reverse=True)
    
    print("ğŸ“Š ì§€ì—­ë³„ í†µê³„ (ìƒìœ„ 10ê°œ):")
    for i, (region, total) in enumerate(sorted_regions[:10]):
        stats = region_stats[region]
        print(f"  {i+1:2d}. {region}: {total}ê°œ (ê´€ê´‘ì§€:{stats['attractions']}, ìˆ™ë°•:{stats['accommodations']}, ìŒì‹ì :{stats['restaurants']})")
    print()
    
    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    save_complete_data_to_database(all_data, region_stats, type_stats)

def save_complete_data_to_database(all_data, region_stats, type_stats):
    """ì™„ì „í•œ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    
    print("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì™„ì „ ì €ì¥ ì‹œì‘...")
    
    with SessionLocal() as db:
        # ê¸°ì¡´ ë°ì´í„° ìƒíƒœ í™•ì¸
        existing_count = db.query(TourSpot).count()
        print(f"  ê¸°ì¡´ ë°ì´í„°: {existing_count}ê°œ")
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
        db.query(TourSpot).delete()
        db.commit()
        print("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
        
        # ë²¡í„°í™”ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì¤€ë¹„
        print(f"ğŸ“Š {len(all_data)}ê°œ í•­ëª© ë²¡í„°í™” ì¤€ë¹„ ì¤‘...")
        
        tour_texts = []
        tour_data = []
        
        for item in all_data:
            # ê° í•­ëª©ì˜ ì •ë³´ë¥¼ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ ê²°í•©
            text_parts = [
                item['name'],
                item['region'],
                item['data_type_korean'],  # ê´€ê´‘ì§€/ìˆ™ë°•ì‹œì„¤/ìŒì‹ì 
                item['keywords'],
                item['tags']
            ]
            # ë¹ˆ ê°’ ì œê±°í•˜ê³  ê²°í•©
            text_parts = [str(part).strip() for part in text_parts if part and str(part).strip() and str(part) != 'nan']
            tour_text = ' '.join(text_parts)
            
            tour_texts.append(tour_text)
            tour_data.append(item)
        
        print(f"ğŸ“Š {len(tour_texts)}ê°œ í…ìŠ¤íŠ¸ ë²¡í„°í™” ì‹œì‘...")
        
        # ë²¡í„°í™” (ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬)
        try:
            tour_vectors = embed_texts(tour_texts)
            print(f"âœ… ë²¡í„°í™” ì™„ë£Œ: {len(tour_vectors)}ê°œ")
        except Exception as e:
            print(f"âŒ ë²¡í„°í™” ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            tour_vectors = []
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        print(f"ğŸ’¾ {len(tour_data)}ê°œ í•­ëª© ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
        
        saved_count = 0
        for i, item in enumerate(tour_data):
            vector = tour_vectors[i] if i < len(tour_vectors) else None
            
            tour_spot = TourSpot(
                name=item['name'],
                region=item['region'],
                tags=f"{item['data_type_korean']},{item['tags']}",  # ìœ í˜• ì •ë³´ í¬í•¨
                lat=item.get('lat'),
                lon=item.get('lon'),
                contentid=item['contentid'],
                pref_vector=vector
            )
            
            db.add(tour_spot)
            saved_count += 1
            
            # ì§„í–‰ìƒí™© ì¶œë ¥ (1000ê°œë§ˆë‹¤)
            if saved_count % 1000 == 0:
                print(f"  ì €ì¥ ì§„í–‰: {saved_count}/{len(tour_data)}")
        
        db.commit()
        print(f"âœ… {saved_count}ê°œ í•­ëª© ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ")
        
        # ì €ì¥ ê²°ê³¼ ìµœì¢… ê²€ì¦
        verify_saved_data(db, region_stats, type_stats)

def verify_saved_data(db, expected_region_stats, expected_type_stats):
    """ì €ì¥ëœ ë°ì´í„° ì™„ì „ì„± ê²€ì¦"""
    
    print("\nğŸ” ë°ì´í„° ì €ì¥ ì™„ì „ì„± ê²€ì¦...")
    print("=" * 50)
    
    # ì „ì²´ í†µê³„
    total_count = db.query(TourSpot).count()
    vectorized_count = db.query(TourSpot).filter(TourSpot.pref_vector.isnot(None)).count()
    
    print(f"ğŸ“Š ì „ì²´ ê²°ê³¼:")
    print(f"  ì´ ì €ì¥ëœ í•­ëª©: {total_count}ê°œ")
    print(f"  ë²¡í„°í™”ëœ í•­ëª©: {vectorized_count}ê°œ")
    print(f"  ë²¡í„°í™” ë¹„ìœ¨: {vectorized_count/total_count*100:.1f}%" if total_count > 0 else "  ë²¡í„°í™” ë¹„ìœ¨: 0%")
    print()
    
    # ì§€ì—­ë³„ ê²€ì¦
    actual_region_stats = db.query(TourSpot.region, func.count(TourSpot.id)).group_by(TourSpot.region).order_by(func.count(TourSpot.id).desc()).all()
    
    print("ğŸ“Š ì§€ì—­ë³„ ì €ì¥ ê²°ê³¼:")
    for region, count in actual_region_stats:
        print(f"  {region}: {count}ê°œ")
    print()
    
    # ìœ í˜•ë³„ ê²€ì¦ (tagsì—ì„œ ì¶”ì¶œ)
    print("ğŸ“Š ìœ í˜•ë³„ ë¶„í¬ í™•ì¸:")
    attraction_count = db.query(TourSpot).filter(TourSpot.tags.contains('ê´€ê´‘ì§€')).count()
    accommodation_count = db.query(TourSpot).filter(TourSpot.tags.contains('ìˆ™ë°•ì‹œì„¤')).count()  
    restaurant_count = db.query(TourSpot).filter(TourSpot.tags.contains('ìŒì‹ì ')).count()
    
    print(f"  ê´€ê´‘ì§€: {attraction_count}ê°œ")
    print(f"  ìˆ™ë°•ì‹œì„¤: {accommodation_count}ê°œ")
    print(f"  ìŒì‹ì : {restaurant_count}ê°œ")
    print()
    
    # ê¹€ì œì‹œ íŠ¹ë³„ í™•ì¸ (ë¬¸ì œ í•´ê²° ê²€ì¦ìš©)
    kimje_total = db.query(TourSpot).filter(TourSpot.region == 'ê¹€ì œì‹œ').count()
    kimje_vectorized = db.query(TourSpot).filter(
        TourSpot.region == 'ê¹€ì œì‹œ',
        TourSpot.pref_vector.isnot(None)
    ).count()
    kimje_attractions = db.query(TourSpot).filter(
        TourSpot.region == 'ê¹€ì œì‹œ',
        TourSpot.tags.contains('ê´€ê´‘ì§€')
    ).count()
    kimje_accommodations = db.query(TourSpot).filter(
        TourSpot.region == 'ê¹€ì œì‹œ', 
        TourSpot.tags.contains('ìˆ™ë°•ì‹œì„¤')
    ).count()
    kimje_restaurants = db.query(TourSpot).filter(
        TourSpot.region == 'ê¹€ì œì‹œ',
        TourSpot.tags.contains('ìŒì‹ì ') 
    ).count()
    
    print("ğŸ¯ ê¹€ì œì‹œ ì™„ì „ì„± ê²€ì¦:")
    print(f"  ì „ì²´: {kimje_total}ê°œ")
    print(f"  ë²¡í„°í™”: {kimje_vectorized}ê°œ")
    print(f"  ê´€ê´‘ì§€: {kimje_attractions}ê°œ") 
    print(f"  ìˆ™ë°•ì‹œì„¤: {kimje_accommodations}ê°œ")
    print(f"  ìŒì‹ì : {kimje_restaurants}ê°œ")
    print()
    
    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
    print("ğŸ“‹ ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ:")
    samples = db.query(TourSpot).limit(5).all()
    for spot in samples:
        has_vector = spot.pref_vector is not None
        if has_vector:
            if hasattr(spot.pref_vector, 'shape'):
                vector_len = spot.pref_vector.shape[0]
            elif hasattr(spot.pref_vector, '__len__'):
                try:
                    vector_len = len(spot.pref_vector) 
                except:
                    vector_len = "í™•ì¸ë¶ˆê°€"
            else:
                vector_len = "ì•Œ ìˆ˜ ì—†ìŒ"
        else:
            vector_len = 0
        print(f"  - {spot.name} ({spot.region}) [{spot.tags}] - ë²¡í„°: {has_vector} ({vector_len}ì°¨ì›)")
    
    print("\nâœ… ë°ì´í„° ë¡œë“œ ë° ê²€ì¦ ì™„ë£Œ!")

if __name__ == "__main__":
    load_complete_jeonbuk_data()