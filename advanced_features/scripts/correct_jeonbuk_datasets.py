"""
ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ ë°ì´í„°ì…‹ ìƒì„±ê¸° (ì˜¬ë°”ë¥¸ ë²„ì „)
=======================================================
data/ í´ë”ì˜ ê¸°ì¡´ íŒŒì¼ë“¤ì„ í™œìš©í•˜ì—¬ ì •í™•í•œ ë°ì´í„°ì…‹ ìƒì„±

ë°ì´í„° ì†ŒìŠ¤:
1. ê´€ê´‘ì§€: tour_api_*.csv 6ê°œ íŒŒì¼ í†µí•© (attractions, cultural, festivals, leisure, shopping, courses)
2. ìˆ™ë°•: accommodations.csvì—ì„œ ì „ë¶ë§Œ ì¶”ì¶œ
3. ìŒì‹ì : restaurants.csvì—ì„œ ì „ë¶ë§Œ ì¶”ì¶œ

ìµœì¢… ê²°ê³¼: 14ê°œ ì§€ì—­ Ã— 3ê°œ íƒ€ì… = 42ê°œ íŒŒì¼
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional

from app.utils.region_mapping import get_region_list

def classify_by_coordinates(lat: float, lon: float) -> Optional[str]:
    """ì¢Œí‘œ ê¸°ë°˜ ì „ë¶ 14ê°œ ì§€ì—­ ë¶„ë¥˜"""
    if pd.isna(lat) or pd.isna(lon) or lat == 0 or lon == 0:
        return None
    
    # ì „ë¶ ì§€ì—­ë³„ ì¢Œí‘œ ë²”ìœ„
    region_bounds = {
        "ì „ì£¼ì‹œ": {"lat_min": 35.75, "lat_max": 35.90, "lon_min": 127.05, "lon_max": 127.20},
        "êµ°ì‚°ì‹œ": {"lat_min": 35.90, "lat_max": 36.05, "lon_min": 126.65, "lon_max": 126.85},
        "ìµì‚°ì‹œ": {"lat_min": 35.90, "lat_max": 36.05, "lon_min": 126.90, "lon_max": 127.10},
        "ì •ìì‹œ": {"lat_min": 35.50, "lat_max": 35.70, "lon_min": 126.80, "lon_max": 127.00},
        "ë‚¨ì›ì‹œ": {"lat_min": 35.35, "lat_max": 35.50, "lon_min": 127.30, "lon_max": 127.50},
        "ê¹€ì œì‹œ": {"lat_min": 35.75, "lat_max": 35.90, "lon_min": 126.85, "lon_max": 127.05},
        "ì™„ì£¼êµ°": {"lat_min": 35.85, "lat_max": 36.05, "lon_min": 127.15, "lon_max": 127.45},
        "ì§„ì•ˆêµ°": {"lat_min": 35.75, "lat_max": 35.95, "lon_min": 127.40, "lon_max": 127.60},
        "ë¬´ì£¼êµ°": {"lat_min": 35.85, "lat_max": 36.05, "lon_min": 127.60, "lon_max": 127.80},
        "ì¥ìˆ˜êµ°": {"lat_min": 35.60, "lat_max": 35.80, "lon_min": 127.50, "lon_max": 127.70},
        "ì„ì‹¤êµ°": {"lat_min": 35.60, "lat_max": 35.75, "lon_min": 127.25, "lon_max": 127.45},
        "ìˆœì°½êµ°": {"lat_min": 35.35, "lat_max": 35.50, "lon_min": 127.10, "lon_max": 127.30},
        "ê³ ì°½êµ°": {"lat_min": 35.40, "lat_max": 35.60, "lon_min": 126.65, "lon_max": 126.85},
        "ë¶€ì•ˆêµ°": {"lat_min": 35.65, "lat_max": 35.80, "lon_min": 126.70, "lon_max": 126.90}
    }
    
    # ì¢Œí‘œê°€ í¬í•¨ë˜ëŠ” ì§€ì—­ ì°¾ê¸°
    for region, bounds in region_bounds.items():
        if (bounds["lat_min"] <= lat <= bounds["lat_max"] and 
            bounds["lon_min"] <= lon <= bounds["lon_max"]):
            return region
    
    # ê°€ì¥ ê°€ê¹Œìš´ ì§€ì—­ ì°¾ê¸°
    min_distance = float('inf')
    closest_region = None
    
    for region, bounds in region_bounds.items():
        center_lat = (bounds["lat_min"] + bounds["lat_max"]) / 2
        center_lon = (bounds["lon_min"] + bounds["lon_max"]) / 2
        distance = ((lat - center_lat) ** 2 + (lon - center_lon) ** 2) ** 0.5
        
        if distance < min_distance:
            min_distance = distance
            closest_region = region
    
    return closest_region

def classify_by_address(address: str) -> Optional[str]:
    """ì£¼ì†Œ ê¸°ë°˜ ì „ë¶ 14ê°œ ì§€ì—­ ë¶„ë¥˜"""
    if not address or pd.isna(address):
        return None
        
    region_keywords = {
        "ê³ ì°½êµ°": ["ê³ ì°½êµ°", "ê³ ì°½ì", "ê³ ì°½"],
        "êµ°ì‚°ì‹œ": ["êµ°ì‚°ì‹œ", "êµ°ì‚°"],
        "ê¹€ì œì‹œ": ["ê¹€ì œì‹œ", "ê¹€ì œ"],
        "ë‚¨ì›ì‹œ": ["ë‚¨ì›ì‹œ", "ë‚¨ì›"],
        "ë¬´ì£¼êµ°": ["ë¬´ì£¼êµ°", "ë¬´ì£¼ì", "ë¬´ì£¼"],
        "ë¶€ì•ˆêµ°": ["ë¶€ì•ˆêµ°", "ë¶€ì•ˆì", "ë¶€ì•ˆ"],
        "ìˆœì°½êµ°": ["ìˆœì°½êµ°", "ìˆœì°½ì", "ìˆœì°½"],
        "ì™„ì£¼êµ°": ["ì™„ì£¼êµ°", "ì™„ì£¼"],
        "ìµì‚°ì‹œ": ["ìµì‚°ì‹œ", "ìµì‚°"],
        "ì„ì‹¤êµ°": ["ì„ì‹¤êµ°", "ì„ì‹¤ì", "ì„ì‹¤"],
        "ì¥ìˆ˜êµ°": ["ì¥ìˆ˜êµ°", "ì¥ìˆ˜ì", "ì¥ìˆ˜"],
        "ì „ì£¼ì‹œ": ["ì „ì£¼ì‹œ", "ì „ì£¼", "ì™„ì‚°êµ¬", "ë•ì§„êµ¬"],
        "ì •ìì‹œ": ["ì •ìì‹œ", "ì •ì"],
        "ì§„ì•ˆêµ°": ["ì§„ì•ˆêµ°", "ì§„ì•ˆì", "ì§„ì•ˆ"]
    }
    
    for region, keywords in region_keywords.items():
        for keyword in keywords:
            if keyword in address:
                return region
    
    return None

def classify_by_region_field(region: str) -> Optional[str]:
    """ì „ë¶ ì§€ì—­ í•„í„°ë§"""
    if not region or pd.isna(region):
        return None
        
    if "ì „ë¶" in region or "ì „ë¼ë¶ë„" in region:
        return classify_by_address(region)
    
    return None

def process_tourism_data() -> Dict[str, List[dict]]:
    """6ê°œ tour_api íŒŒì¼ì„ í†µí•©í•˜ì—¬ ê´€ê´‘ì§€ ë°ì´í„° ìƒì„±"""
    print("ğŸ¯ 1ë‹¨ê³„: ê´€ê´‘ì§€ ë°ì´í„° í†µí•© ë° ì§€ì—­ë³„ ë¶„ë¥˜")
    print("=" * 60)
    
    # 6ê°œ tour_api íŒŒì¼ ì •ì˜
    tour_files = [
        "tour_api_attractions.csv",
        "tour_api_cultural.csv", 
        "tour_api_festivals.csv",
        "tour_api_leisure.csv",
        "tour_api_shopping.csv",
        "tour_api_courses.csv"
    ]
    
    all_tourism_data = []
    regional_data = {region: [] for region in get_region_list()}
    
    for filename in tour_files:
        file_path = Path("data") / filename
        
        if not file_path.exists():
            print(f"âš ï¸ {filename} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            continue
            
        try:
            df = pd.read_csv(file_path)
            print(f"ğŸ“„ {filename}: {len(df)}ê±´")
            
            classified_count = 0
            
            for idx, row in df.iterrows():
                region = None
                classification_method = ""
                
                # attractions íŒŒì¼ì€ ì¢Œí‘œ ê¸°ë°˜ ë¶„ë¥˜
                if filename == "tour_api_attractions.csv":
                    lat = row.get('lat')
                    lon = row.get('lon')
                    if pd.notna(lat) and pd.notna(lon):
                        region = classify_by_coordinates(float(lat), float(lon))
                        if region:
                            classification_method = "ì¢Œí‘œ"
                else:
                    # ë‹¤ë¥¸ íŒŒì¼ë“¤ì€ ì£¼ì†Œ ê¸°ë°˜ ë¶„ë¥˜
                    addr = row.get('region', '')
                    region = classify_by_address(addr)
                    if region:
                        classification_method = "ì£¼ì†Œ"
                
                if region:
                    data = {
                        "name": row.get('name', ''),
                        "region": region,
                        "address_full": row.get('region', ''),
                        "lat": row.get('lat'),
                        "lon": row.get('lon'),
                        "contentid": row.get('contentid', ''),
                        "image_url": row.get('image_url', ''),
                        "tags": row.get('tags', ''),
                        "keywords": row.get('keywords', ''),
                        "source_file": filename,
                        "classification_method": classification_method
                    }
                    regional_data[region].append(data)
                    classified_count += 1
            
            print(f"    ë¶„ë¥˜ ì„±ê³µ: {classified_count}/{len(df)}ê±´")
            
        except Exception as e:
            print(f"âŒ {filename} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ê´€ê´‘ì§€ ë¶„í¬:")
    total_count = 0
    for region in get_region_list():
        count = len(regional_data[region])
        if count > 0:
            print(f"    {region}: {count}ê±´")
            total_count += count
    
    print(f"ğŸ“Š ì´ ê´€ê´‘ì§€ ë°ì´í„°: {total_count}ê±´")
    return regional_data

def process_accommodations_data() -> Dict[str, List[dict]]:
    """accommodations.csvì—ì„œ ì „ë¶ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ì§€ì—­ë³„ ë¶„ë¥˜"""
    print("\nğŸ¯ 2ë‹¨ê³„: ìˆ™ë°• ë°ì´í„° ì „ë¶ ì¶”ì¶œ ë° ì§€ì—­ë³„ ë¶„ë¥˜")
    print("=" * 60)
    
    regional_data = {region: [] for region in get_region_list()}
    
    file_path = Path("data/accommodations.csv")
    
    if not file_path.exists():
        print("âŒ accommodations.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return regional_data
    
    try:
        df = pd.read_csv(file_path)
        print(f"ğŸ“„ ì „ì²´ ìˆ™ë°• ë°ì´í„°: {len(df)}ê±´")
        
        jeonbuk_count = 0
        classified_count = 0
        
        for idx, row in df.iterrows():
            # ì „ë¶ ì§€ì—­ í•„í„°ë§
            region_field = row.get('region', '')
            
            if "ì „ë¶" in region_field or "ì „ë¼ë¶ë„" in region_field:
                jeonbuk_count += 1
                
                # ì§€ì—­ ë¶„ë¥˜
                region = classify_by_address(region_field)
                
                if not region:
                    # ì¢Œí‘œë¡œë„ ì‹œë„
                    lat = row.get('lat')
                    lon = row.get('lon') 
                    if pd.notna(lat) and pd.notna(lon):
                        region = classify_by_coordinates(float(lat), float(lon))
                
                if region:
                    data = {
                        "name": row.get('name', ''),
                        "region": region,
                        "address_full": region_field,
                        "lat": row.get('lat'),
                        "lon": row.get('lon'),
                        "contentid": row.get('contentid', ''),
                        "image_url": row.get('image_url', ''),
                        "tags": row.get('tags', ''),
                        "checkin_time": row.get('checkin_time', ''),
                        "checkout_time": row.get('checkout_time', ''),
                        "room_count": row.get('room_count', ''),
                        "parking": row.get('parking', ''),
                        "facilities": row.get('facilities', '')
                    }
                    regional_data[region].append(data)
                    classified_count += 1
        
        print(f"ğŸ“Š ì „ë¶ ìˆ™ë°• ë°ì´í„°: {jeonbuk_count}ê±´")
        print(f"    ë¶„ë¥˜ ì„±ê³µ: {classified_count}ê±´")
        
        print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ìˆ™ë°• ë¶„í¬:")
        for region in get_region_list():
            count = len(regional_data[region])
            if count > 0:
                print(f"    {region}: {count}ê±´")
                
    except Exception as e:
        print(f"âŒ ìˆ™ë°• ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    return regional_data

def process_restaurants_data() -> Dict[str, List[dict]]:
    """restaurants.csvì—ì„œ ì „ë¶ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ì§€ì—­ë³„ ë¶„ë¥˜"""
    print("\nğŸ¯ 3ë‹¨ê³„: ìŒì‹ì  ë°ì´í„° ì „ë¶ ì¶”ì¶œ ë° ì§€ì—­ë³„ ë¶„ë¥˜")
    print("=" * 60)
    
    regional_data = {region: [] for region in get_region_list()}
    
    file_path = Path("data/restaurants.csv")
    
    if not file_path.exists():
        print("âŒ restaurants.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return regional_data
    
    try:
        df = pd.read_csv(file_path)
        print(f"ğŸ“„ ì „ì²´ ìŒì‹ì  ë°ì´í„°: {len(df)}ê±´")
        
        jeonbuk_count = 0
        classified_count = 0
        
        for idx, row in df.iterrows():
            # ì „ë¶ ì§€ì—­ í•„í„°ë§
            region_field = row.get('region', '')
            
            if "ì „ë¶" in region_field or "ì „ë¼ë¶ë„" in region_field:
                jeonbuk_count += 1
                
                # ì§€ì—­ ë¶„ë¥˜
                region = classify_by_address(region_field)
                
                if not region:
                    # ì¢Œí‘œë¡œë„ ì‹œë„
                    lat = row.get('lat')
                    lon = row.get('lon')
                    if pd.notna(lat) and pd.notna(lon):
                        region = classify_by_coordinates(float(lat), float(lon))
                
                if region:
                    data = {
                        "name": row.get('name', ''),
                        "region": region,
                        "address_full": region_field,
                        "lat": row.get('lat'),
                        "lon": row.get('lon'),
                        "contentid": row.get('contentid', ''),
                        "image_url": row.get('image_url', ''),
                        "tags": row.get('tags', ''),
                        "menu": row.get('menu', ''),
                        "open_time": row.get('open_time', ''),
                        "rest_date": row.get('rest_date', ''),
                        "parking": row.get('parking', ''),
                        "reservation": row.get('reservation', ''),
                        "packaging": row.get('packaging', '')
                    }
                    regional_data[region].append(data)
                    classified_count += 1
        
        print(f"ğŸ“Š ì „ë¶ ìŒì‹ì  ë°ì´í„°: {jeonbuk_count}ê±´")
        print(f"    ë¶„ë¥˜ ì„±ê³µ: {classified_count}ê±´")
        
        print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ìŒì‹ì  ë¶„í¬:")
        for region in get_region_list():
            count = len(regional_data[region])
            if count > 0:
                print(f"    {region}: {count}ê±´")
                
    except Exception as e:
        print(f"âŒ ìŒì‹ì  ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    return regional_data

def save_final_datasets(tourism_data: Dict[str, List[dict]], 
                       accommodation_data: Dict[str, List[dict]],
                       restaurant_data: Dict[str, List[dict]]) -> List[str]:
    """ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ = 42ê°œ ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥"""
    print("\nğŸ¯ 4ë‹¨ê³„: 42ê°œ ì§€ì—­ë³„ ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥")
    print("=" * 60)
    
    data_dir = Path("data2")
    data_dir.mkdir(exist_ok=True)
    
    # ê¸°ì¡´ íŒŒì¼ë“¤ ì‚­ì œ (ìƒˆë¡œ ìƒì„±)
    for existing_file in data_dir.glob("jeonbuk_*.csv"):
        existing_file.unlink()
    
    saved_files = []
    regions = get_region_list()
    
    for region in regions:
        print(f"\nğŸ“ {region} ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        # 1. ê´€ê´‘ì§€ ë°ì´í„°
        tourism_file = f"jeonbuk_{region}_attractions.csv"
        tourism_path = data_dir / tourism_file
        
        tourism_items = tourism_data.get(region, [])
        if tourism_items:
            df_tourism = pd.DataFrame(tourism_items)
            df_tourism.to_csv(tourism_path, index=False, encoding='utf-8')
            print(f"    âœ… {tourism_file}: {len(df_tourism)}ê±´")
        else:
            # ë¹ˆ íŒŒì¼ë„ í—¤ë”ì™€ í•¨ê»˜ ìƒì„±
            empty_df = pd.DataFrame(columns=['name', 'region', 'address_full', 'lat', 'lon', 'contentid', 'image_url', 'tags', 'keywords'])
            empty_df.to_csv(tourism_path, index=False, encoding='utf-8')
            print(f"    ğŸ“„ {tourism_file}: 0ê±´")
        saved_files.append(tourism_file)
        
        # 2. ìˆ™ë°• ë°ì´í„°
        accommodation_file = f"jeonbuk_{region}_accommodations.csv"
        accommodation_path = data_dir / accommodation_file
        
        accommodation_items = accommodation_data.get(region, [])
        if accommodation_items:
            df_accommodation = pd.DataFrame(accommodation_items)
            df_accommodation.to_csv(accommodation_path, index=False, encoding='utf-8')
            print(f"    âœ… {accommodation_file}: {len(df_accommodation)}ê±´")
        else:
            # ë¹ˆ íŒŒì¼ë„ í—¤ë”ì™€ í•¨ê»˜ ìƒì„±
            empty_df = pd.DataFrame(columns=['name', 'region', 'address_full', 'lat', 'lon', 'contentid', 'image_url', 'tags', 'checkin_time', 'checkout_time', 'room_count', 'parking', 'facilities'])
            empty_df.to_csv(accommodation_path, index=False, encoding='utf-8')
            print(f"    ğŸ“„ {accommodation_file}: 0ê±´")
        saved_files.append(accommodation_file)
        
        # 3. ìŒì‹ì  ë°ì´í„°
        restaurant_file = f"jeonbuk_{region}_restaurants.csv"
        restaurant_path = data_dir / restaurant_file
        
        restaurant_items = restaurant_data.get(region, [])
        if restaurant_items:
            df_restaurant = pd.DataFrame(restaurant_items)
            df_restaurant.to_csv(restaurant_path, index=False, encoding='utf-8')
            print(f"    âœ… {restaurant_file}: {len(df_restaurant)}ê±´")
        else:
            # ë¹ˆ íŒŒì¼ë„ í—¤ë”ì™€ í•¨ê»˜ ìƒì„±
            empty_df = pd.DataFrame(columns=['name', 'region', 'address_full', 'lat', 'lon', 'contentid', 'image_url', 'tags', 'menu', 'open_time', 'rest_date', 'parking', 'reservation', 'packaging'])
            empty_df.to_csv(restaurant_path, index=False, encoding='utf-8')
            print(f"    ğŸ“„ {restaurant_file}: 0ê±´")
        saved_files.append(restaurant_file)
    
    return saved_files

def validate_final_datasets():
    """ìƒì„±ëœ ë°ì´í„°ì…‹ ê²€ì¦"""
    print("\nğŸ¯ 5ë‹¨ê³„: ìµœì¢… ë°ì´í„°ì…‹ ê²€ì¦")
    print("=" * 60)
    
    data_dir = Path("data2")
    regions = get_region_list()
    types = ["attractions", "accommodations", "restaurants"]
    
    total_files = 0
    valid_files = 0
    total_records = 0
    
    print("ğŸ“Š ì§€ì—­ë³„ ë°ì´í„° í˜„í™©:")
    
    for region in regions:
        region_total = 0
        print(f"\nğŸ—ºï¸ {region}:")
        
        for data_type in types:
            filename = f"jeonbuk_{region}_{data_type}.csv"
            file_path = data_dir / filename
            
            total_files += 1
            
            if file_path.exists():
                try:
                    df = pd.read_csv(file_path)
                    record_count = len(df)
                    print(f"    {data_type}: {record_count}ê±´")
                    region_total += record_count
                    total_records += record_count
                    valid_files += 1
                except Exception as e:
                    print(f"    {data_type}: ì½ê¸° ì‹¤íŒ¨ - {e}")
            else:
                print(f"    {data_type}: íŒŒì¼ ì—†ìŒ")
        
        print(f"    ì†Œê³„: {region_total}ê±´")
    
    print(f"\nğŸ“Š ì „ì²´ ê²€ì¦ ê²°ê³¼:")
    print(f"    ìƒì„±ëœ íŒŒì¼: {valid_files}/{total_files}ê°œ")
    print(f"    ì „ì²´ ë ˆì½”ë“œ: {total_records}ê±´")
    print(f"    ì˜ˆìƒ íŒŒì¼: {len(regions) * len(types)}ê°œ (14ê°œ ì§€ì—­ Ã— 3ê°œ íƒ€ì…)")
    
    if valid_files == len(regions) * len(types):
        print(f"    ğŸ‰ 42ê°œ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    else:
        print(f"    âš ï¸ ì¼ë¶€ íŒŒì¼ ëˆ„ë½ ë˜ëŠ” ì˜¤ë¥˜")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸŒŸ ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ ë°ì´í„°ì…‹ ìƒì„±ê¸° (ì˜¬ë°”ë¥¸ ë²„ì „)")
    print("=" * 70)
    print("ğŸ“Œ ë°ì´í„° ì†ŒìŠ¤:")
    print("   1. ê´€ê´‘ì§€: tour_api_*.csv 6ê°œ íŒŒì¼ í†µí•©")
    print("   2. ìˆ™ë°•: accommodations.csvì—ì„œ ì „ë¶ ì¶”ì¶œ")
    print("   3. ìŒì‹ì : restaurants.csvì—ì„œ ì „ë¶ ì¶”ì¶œ")
    print("ğŸ“Œ ìµœì¢… ê²°ê³¼: 14ê°œ ì§€ì—­ Ã— 3ê°œ íƒ€ì… = 42ê°œ íŒŒì¼")
    print()
    
    try:
        # 1ë‹¨ê³„: ê´€ê´‘ì§€ ë°ì´í„° í†µí•© ì²˜ë¦¬
        tourism_data = process_tourism_data()
        
        # 2ë‹¨ê³„: ìˆ™ë°• ë°ì´í„° ì²˜ë¦¬
        accommodation_data = process_accommodations_data()
        
        # 3ë‹¨ê³„: ìŒì‹ì  ë°ì´í„° ì²˜ë¦¬
        restaurant_data = process_restaurants_data()
        
        # 4ë‹¨ê³„: 42ê°œ ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥
        saved_files = save_final_datasets(tourism_data, accommodation_data, restaurant_data)
        
        # 5ë‹¨ê³„: ê²€ì¦
        validate_final_datasets()
        
        print(f"\nâœ… ì „ë¶ ì§€ì—­ë³„ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“Š ìƒì„±ëœ íŒŒì¼: {len(saved_files)}ê°œ")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: data2/")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()