"""
ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ ê´€ê´‘ì§€ ë°ì´í„° ìƒì„±ê¸°
===============================================
Tour APIì—ì„œ ì‹¤ì œ ìƒì„¸ ì£¼ì†Œë¥¼ ìˆ˜ì§‘í•˜ì—¬ 
ì „ë¶ 14ê°œ ì§€ì—­ë³„ë¡œ ê´€ê´‘ì§€/ìˆ™ë°•/ìŒì‹ì  ë°ì´í„°ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.

í•µì‹¬ ìš”êµ¬ì‚¬í•­:
1. ì „ë¶ 14ê°œ ì§€ì—­ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
2. ê´€ê´‘ì§€/ìˆ™ë°•/ìŒì‹ì  3ê°œ íƒ€ì…ìœ¼ë¡œ ë¶„ë¥˜  
3. ì´ 42ê°œ ë°ì´í„°ì…‹ ìƒì„± (14 Ã— 3)
4. ìƒì„¸ ì£¼ì†Œ ì •ë³´ ìˆ˜ì§‘ (ì‹œ/êµ° ë‹¨ìœ„ê¹Œì§€)
"""

import httpx
import pandas as pd
import time
import json
import ssl
import urllib3
from pathlib import Path
from typing import List, Dict, Optional, Tuple

from app.config import get_settings
from app.utils.region_mapping import get_region_list

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# í™˜ê²½ ì„¤ì •
settings = get_settings()
BASE_URL = settings.tour_base_url.rstrip("/")
SERVICE_KEY = settings.tour_api_key

# SSL ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ëª¨ë“  ê²€ì¦ ë¬´ì‹œ)
ssl_context = ssl.create_default_context()
ssl_context.check_hostname = False
ssl_context.verify_mode = ssl.CERT_NONE

# httpx í´ë¼ì´ì–¸íŠ¸ SSL ìš°íšŒ ì„¤ì • ê°•í™”
CLIENT = httpx.Client(
    timeout=httpx.Timeout(30.0, connect=15.0),
    verify=False,  # SSL ê²€ì¦ ì™„ì „ ë¹„í™œì„±í™”
    headers={
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'application/json',
        'Connection': 'close'
    }
)

def classify_jeonbuk_region(addr1: str, addr2: str = "") -> Optional[str]:
    """ì‹¤ì œ ì£¼ì†Œë¡œ ì „ë¶ 14ê°œ ì§€ì—­ ë¶„ë¥˜"""
    if not addr1:
        return None
        
    full_address = f"{addr1} {addr2}".strip()
    
    # ì „ë¶ 14ê°œ ì§€ì—­ í‚¤ì›Œë“œ ë§¤í•‘ (ì •í™•ë„ ìˆœì„œ)
    region_keywords = {
        "ê³ ì°½êµ°": ["ê³ ì°½êµ°", "ê³ ì°½ì", "ê³ ì°½"],
        "êµ°ì‚°ì‹œ": ["êµ°ì‚°ì‹œ", "êµ°ì‚°"],
        "ê¹€ì œì‹œ": ["ê¹€ì œì‹œ", "ê¹€ì œ"],
        "ë‚¨ì›ì‹œ": ["ë‚¨ì›ì‹œ", "ë‚¨ì›"],
        "ë¬´ì£¼êµ°": ["ë¬´ì£¼êµ°", "ë¬´ì£¼ì", "ë¬´ì£¼"],
        "ë¶€ì•ˆêµ°": ["ë¶€ì•ˆêµ°", "ë¶€ì•ˆì", "ë¶€ì•ˆ"],
        "ìˆœì°½êµ°": ["ìˆœì°½êµ°", "ìˆœì°½ì", "ìˆœì°½"],
        "ì™„ì£¼êµ°": ["ì™„ì£¼êµ°", "ì™„ì£¼"],
        "ìµì‚°ì‹œ": ["ìµì‚°ì‹œ", "ìµì‚°"],
        "ì„ì‹¤êµ°": ["ì„ì‹¤êµ°", "ì„ì‹¤ì", "ì„ì‹¤"],
        "ì¥ìˆ˜êµ°": ["ì¥ìˆ˜êµ°", "ì¥ìˆ˜ì", "ì¥ìˆ˜"],
        "ì „ì£¼ì‹œ": ["ì „ì£¼ì‹œ", "ì „ì£¼", "ì™„ì‚°êµ¬", "ë•ì§„êµ¬"],
        "ì •ìì‹œ": ["ì •ìì‹œ", "ì •ì"],
        "ì§„ì•ˆêµ°": ["ì§„ì•ˆêµ°", "ì§„ì•ˆì", "ì§„ì•ˆ"]
    }
    
    # ì£¼ì†Œì—ì„œ ì§€ì—­ ì°¾ê¸°
    for region, keywords in region_keywords.items():
        for keyword in keywords:
            if keyword in full_address:
                return region
    
    return None

def fetch_detail_with_retry(contentid: str, max_retries: int = 5) -> Optional[dict]:
    """ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ìƒì„¸ ì£¼ì†Œ ìˆ˜ì§‘ ì‹œë„"""
    
    # ë°©ë²• 1: ê¸°ë³¸ detailCommon2
    detail_info = fetch_detail_common_basic(contentid)
    if detail_info and detail_info.get("addr1"):
        return detail_info
    
    # ë°©ë²• 2: ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë¡œ ì¬ì‹œë„
    detail_info = fetch_detail_common_alternative(contentid)
    if detail_info and detail_info.get("addr1"):
        return detail_info
        
    return None

def fetch_detail_common_basic(contentid: str) -> Optional[dict]:
    """ê¸°ë³¸ detailCommon2 í˜¸ì¶œ"""
    params = {
        "serviceKey": SERVICE_KEY,
        "MobileOS": "ETC",
        "MobileApp": "KDT-JeonbukTour",
        "_type": "json",
        "contentId": contentid,
        "defaultYN": "Y",
        "addrinfoYN": "Y",
        "mapinfoYN": "Y"
    }
    
    return call_detail_api(params)

def fetch_detail_common_alternative(contentid: str) -> Optional[dict]:
    """ëŒ€ì•ˆ íŒŒë¼ë¯¸í„°ë¡œ detailCommon2 í˜¸ì¶œ"""
    params = {
        "serviceKey": SERVICE_KEY,
        "MobileOS": "WIN",
        "MobileApp": "AppTest",
        "_type": "json",
        "contentId": contentid,
        "defaultYN": "Y",
        "addrinfoYN": "Y"
    }
    
    return call_detail_api(params)

def call_detail_api(params: dict) -> Optional[dict]:
    """ì‹¤ì œ API í˜¸ì¶œ (SSL ìš°íšŒ ê°•í™”)"""
    url = f"{BASE_URL}/detailCommon2"
    
    try:
        # requests ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œë„ ì‹œë„
        import requests
        requests.packages.urllib3.disable_warnings()
        
        response = requests.get(
            url, 
            params=params, 
            timeout=15,
            verify=False,  # SSL ê²€ì¦ ë¹„í™œì„±í™”
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
        )
        response.raise_for_status()
        data = response.json()
        
        if "response" not in data:
            return None
            
        body = data["response"]["body"]
        if not body or body.get("totalCount", 0) == 0:
            return None
        
        items = body.get("items", {})
        if not items:
            return None
        
        item = items.get("item", {})
        if isinstance(item, list):
            item = item[0] if item else {}
            
        return item
        
    except Exception as e:
        try:
            # httpxë¡œ ì¬ì‹œë„
            response = CLIENT.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            if "response" not in data:
                return None
                
            body = data["response"]["body"]
            if not body or body.get("totalCount", 0) == 0:
                return None
            
            items = body.get("items", {})
            if not items:
                return None
            
            item = items.get("item", {})
            if isinstance(item, list):
                item = item[0] if item else {}
                
            return item
            
        except Exception as e2:
            return None

def process_attractions_data():
    """ê´€ê´‘ì§€ ë°ì´í„° ì²˜ë¦¬ - ìƒì„¸ ì£¼ì†Œ ìˆ˜ì§‘í•˜ì—¬ ì§€ì—­ë³„ ë¶„ë¦¬"""
    print("ğŸ¯ 1ë‹¨ê³„: ê´€ê´‘ì§€ ë°ì´í„° ìƒì„¸ ì£¼ì†Œ ìˆ˜ì§‘ ë° ì§€ì—­ë³„ ë¶„ë¦¬")
    print("=" * 70)
    
    # ê¸°ì¡´ ê´€ê´‘ì§€ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv("data/tour_api_attractions.csv")
    print(f"ğŸ“„ ê´€ê´‘ì§€ ë°ì´í„° ë¡œë“œ: {len(df)}ê±´")
    
    # contentidê°€ ìˆëŠ” ë°ì´í„°ë§Œ ì²˜ë¦¬
    df_with_contentid = df[df['contentid'].notna()].copy()
    print(f"ğŸ“Š ì²˜ë¦¬ ëŒ€ìƒ: {len(df_with_contentid)}ê±´ (contentid ë³´ìœ )")
    
    regional_data = {region: [] for region in get_region_list()}
    failed_data = []
    
    processed_count = 0
    success_count = 0
    
    for idx, row in df_with_contentid.iterrows():
        contentid = str(row['contentid']).strip()
        title = row['name']
        processed_count += 1
        
        print(f"[{processed_count}/{len(df_with_contentid)}] {title}")
        
        # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        detail_info = fetch_detail_with_retry(contentid)
        
        if detail_info and detail_info.get("addr1"):
            addr1 = detail_info.get("addr1", "")
            addr2 = detail_info.get("addr2", "")
            region = classify_jeonbuk_region(addr1, addr2)
            
            print(f"    âœ… ì£¼ì†Œ: {addr1}")
            if region:
                print(f"    ğŸ—ºï¸ ë¶„ë¥˜: {region}")
                
                # ë°ì´í„° ë³‘í•©
                merged_data = {
                    "name": title,
                    "region": region,
                    "address_full": addr1,
                    "address_detail": addr2,
                    "lat": row.get('lat'),
                    "lon": row.get('lon'),
                    "contentid": contentid,
                    "contenttypeid": 12,
                    "tel": detail_info.get("tel", ""),
                    "zipcode": detail_info.get("zipcode", ""),
                    "image_url": detail_info.get("firstimage", ""),
                    "overview": detail_info.get("overview", ""),
                    "tags": row.get('tags', ''),
                    "keywords": row.get('keywords', '')
                }
                
                regional_data[region].append(merged_data)
                success_count += 1
            else:
                print(f"    âš ï¸ ì§€ì—­ ë¶„ë¥˜ ì‹¤íŒ¨: {addr1}")
                failed_data.append(row.to_dict())
        else:
            print(f"    âŒ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")
            failed_data.append(row.to_dict())
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        if processed_count % 50 == 0:
            print(f"\nğŸ“Š ì§„í–‰ ìƒí™©: {processed_count}/{len(df_with_contentid)} ({processed_count/len(df_with_contentid)*100:.1f}%)")
            print(f"    ì„±ê³µ: {success_count}ê±´, ì‹¤íŒ¨: {len(failed_data)}ê±´")
            
            # ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥
            region_counts = {region: len(items) for region, items in regional_data.items() if items}
            print(f"    ì§€ì—­ë³„ ìˆ˜ì§‘: {region_counts}")
            print()
        
        # API ì•ˆì •ì„±ì„ ìœ„í•œ ëŒ€ê¸° (ì¤‘ìš”!)
        time.sleep(0.2)
    
    print(f"\nğŸ“Š ê´€ê´‘ì§€ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ:")
    print(f"    ì´ ì²˜ë¦¬: {processed_count}ê±´")
    print(f"    ì„±ê³µ: {success_count}ê±´")
    print(f"    ì‹¤íŒ¨: {len(failed_data)}ê±´")
    
    # ì§€ì—­ë³„ í†µê³„
    print(f"\nğŸ—ºï¸ ì§€ì—­ë³„ ê´€ê´‘ì§€ ë¶„í¬:")
    for region in get_region_list():
        count = len(regional_data[region])
        if count > 0:
            print(f"    {region}: {count}ê±´")
    
    return regional_data, failed_data

def process_existing_data():
    """ê¸°ì¡´ íŒŒì¼ë“¤ì˜ ë°ì´í„°ë¥¼ ì§€ì—­ë³„ë¡œ ë¶„ë¦¬"""
    print("\nğŸ¯ 2ë‹¨ê³„: ê¸°ì¡´ íŒŒì¼ë“¤ ì§€ì—­ë³„ ë¶„ë¦¬")
    print("=" * 70)
    
    file_mappings = {
        "tour_api_cultural.csv": ("cultural", 14),
        "tour_api_festivals.csv": ("festivals", 15), 
        "tour_api_leisure.csv": ("leisure", 28),
        "tour_api_shopping.csv": ("shopping", 38)
    }
    
    all_regional_data = {}
    
    for filename, (category, content_type_id) in file_mappings.items():
        print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {filename}")
        
        try:
            df = pd.read_csv(f"data/{filename}")
            print(f"    ë°ì´í„° ë¡œë“œ: {len(df)}ê±´")
            
            regional_data = {region: [] for region in get_region_list()}
            
            for idx, row in df.iterrows():
                addr1 = row.get('region', '')  # region í•„ë“œì— ì´ë¯¸ ìƒì„¸ ì£¼ì†Œê°€ ìˆìŒ
                region = classify_jeonbuk_region(addr1)
                
                if region:
                    data = {
                        "name": row.get('name', ''),
                        "region": region,
                        "address_full": addr1,
                        "address_detail": "",
                        "lat": row.get('lat'),
                        "lon": row.get('lon'), 
                        "contentid": row.get('contentid', ''),
                        "contenttypeid": content_type_id,
                        "tel": "",
                        "zipcode": "",
                        "image_url": row.get('image_url', ''),
                        "overview": "",
                        "tags": row.get('tags', ''),
                        "keywords": row.get('keywords', '')
                    }
                    regional_data[region].append(data)
            
            # í†µê³„ ì¶œë ¥
            print(f"    ì§€ì—­ë³„ ë¶„í¬:")
            for region in get_region_list():
                count = len(regional_data[region])
                if count > 0:
                    print(f"        {region}: {count}ê±´")
            
            all_regional_data[category] = regional_data
            
        except Exception as e:
            print(f"    âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    return all_regional_data

def create_accommodations_and_restaurants():
    """ìˆ™ë°•ê³¼ ìŒì‹ì  ë°ì´í„°ë¥¼ Tour APIë¡œ ìƒˆë¡œ ìˆ˜ì§‘"""
    print("\nğŸ¯ 3ë‹¨ê³„: ìˆ™ë°•/ìŒì‹ì  ë°ì´í„° Tour API ìˆ˜ì§‘")
    print("=" * 70)
    
    content_types = {
        32: "accommodations",  # ìˆ™ë°•
        39: "restaurants"      # ìŒì‹ì   
    }
    
    all_data = {}
    
    for content_type_id, type_name in content_types.items():
        print(f"\nğŸ“¡ {type_name} (contentType: {content_type_id}) ìˆ˜ì§‘ ì¤‘...")
        
        # areaBasedList2ë¡œ ì „ë¶ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘
        all_items = []
        page = 1
        
        while True:
            items, total_count = fetch_area_based_list(content_type_id, page)
            if not items:
                break
            all_items.extend(items)
            
            total_pages = (total_count + 99) // 100
            if page >= total_pages:
                break
            page += 1
            time.sleep(0.3)
        
        print(f"    ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘: {len(all_items)}ê±´")
        
        if not all_items:
            all_data[type_name] = {region: [] for region in get_region_list()}
            continue
        
        # ìƒì„¸ ì£¼ì†Œ ìˆ˜ì§‘ ë° ì§€ì—­ë³„ ë¶„ë¥˜
        regional_data = {region: [] for region in get_region_list()}
        
        for item in all_items[:100]:  # í…ŒìŠ¤íŠ¸ìš© 100ê°œë§Œ
            contentid = item.get("contentid")
            if not contentid:
                continue
            
            detail_info = fetch_detail_with_retry(contentid)
            
            if detail_info and detail_info.get("addr1"):
                addr1 = detail_info.get("addr1", "")
                addr2 = detail_info.get("addr2", "")
                region = classify_jeonbuk_region(addr1, addr2)
                
                if region:
                    data = {
                        "name": item.get("title", ""),
                        "region": region,
                        "address_full": addr1,
                        "address_detail": addr2,
                        "lat": float(item.get("mapy", 0)) if item.get("mapy") else None,
                        "lon": float(item.get("mapx", 0)) if item.get("mapx") else None,
                        "contentid": contentid,
                        "contenttypeid": content_type_id,
                        "tel": detail_info.get("tel", ""),
                        "zipcode": detail_info.get("zipcode", ""),
                        "image_url": detail_info.get("firstimage", ""),
                        "overview": detail_info.get("overview", ""),
                        "tags": "",
                        "keywords": ""
                    }
                    regional_data[region].append(data)
            
            time.sleep(0.2)
        
        # í†µê³„ ì¶œë ¥
        print(f"    ì§€ì—­ë³„ ë¶„í¬:")
        for region in get_region_list():
            count = len(regional_data[region])
            if count > 0:
                print(f"        {region}: {count}ê±´")
        
        all_data[type_name] = regional_data
    
    return all_data

def fetch_area_based_list(content_type_id: int, page: int = 1) -> Tuple[List[dict], int]:
    """areaBasedList2 API í˜¸ì¶œ"""
    params = {
        "serviceKey": SERVICE_KEY,
        "MobileOS": "ETC",
        "MobileApp": "KDT-JeonbukTour",
        "_type": "json",
        "arrange": "A",
        "numOfRows": 100,
        "pageNo": page,
        "areaCode": 37,  # ì „ë¶
        "contentTypeId": content_type_id
    }
    
    url = f"{BASE_URL}/areaBasedList2"
    
    try:
        response = CLIENT.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        
        if "response" not in data:
            return [], 0
        
        body = data["response"].get("body", {})
        if not body or body.get("totalCount", 0) == 0:
            return [], 0
        
        items = body.get("items", {})
        if not items:
            return [], body.get("totalCount", 0)
        
        item_list = items.get("item", [])
        if not isinstance(item_list, list):
            item_list = [item_list]
        
        return item_list, body.get("totalCount", 0)
        
    except Exception as e:
        print(f"    âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return [], 0

def save_regional_datasets(attractions_data, existing_data, new_data):
    """ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ = 42ê°œ ë°ì´í„°ì…‹ ì €ì¥"""
    print("\nğŸ¯ 4ë‹¨ê³„: 42ê°œ ì§€ì—­ë³„ ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥")
    print("=" * 70)
    
    data_dir = Path("data2")
    data_dir.mkdir(exist_ok=True)
    
    saved_files = []
    regions = get_region_list()
    
    for region in regions:
        print(f"\nğŸ“ {region} ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        # 1. ê´€ê´‘ì§€ íŒŒì¼
        attractions_file = f"jeonbuk_{region}_attractions.csv"
        attractions_path = data_dir / attractions_file
        
        if region in attractions_data and attractions_data[region]:
            df = pd.DataFrame(attractions_data[region])
            df.to_csv(attractions_path, index=False, encoding='utf-8')
            print(f"    âœ… {attractions_file}: {len(df)}ê±´")
            saved_files.append(attractions_file)
        else:
            # ë¹ˆ íŒŒì¼ì´ë¼ë„ ìƒì„±
            pd.DataFrame().to_csv(attractions_path, index=False, encoding='utf-8')
            print(f"    ğŸ“„ {attractions_file}: 0ê±´ (ë¹ˆ íŒŒì¼)")
            saved_files.append(attractions_file)
        
        # 2. ìˆ™ë°• íŒŒì¼  
        accommodations_file = f"jeonbuk_{region}_accommodations.csv"
        accommodations_path = data_dir / accommodations_file
        
        accommodations_items = new_data.get("accommodations", {}).get(region, [])
        if accommodations_items:
            df = pd.DataFrame(accommodations_items)
            df.to_csv(accommodations_path, index=False, encoding='utf-8')
            print(f"    âœ… {accommodations_file}: {len(df)}ê±´")
        else:
            pd.DataFrame().to_csv(accommodations_path, index=False, encoding='utf-8')
            print(f"    ğŸ“„ {accommodations_file}: 0ê±´ (ë¹ˆ íŒŒì¼)")
        saved_files.append(accommodations_file)
        
        # 3. ìŒì‹ì  íŒŒì¼
        restaurants_file = f"jeonbuk_{region}_restaurants.csv"  
        restaurants_path = data_dir / restaurants_file
        
        restaurants_items = new_data.get("restaurants", {}).get(region, [])
        if restaurants_items:
            df = pd.DataFrame(restaurants_items)
            df.to_csv(restaurants_path, index=False, encoding='utf-8')
            print(f"    âœ… {restaurants_file}: {len(df)}ê±´")
        else:
            pd.DataFrame().to_csv(restaurants_path, index=False, encoding='utf-8')
            print(f"    ğŸ“„ {restaurants_file}: 0ê±´ (ë¹ˆ íŒŒì¼)")
        saved_files.append(restaurants_file)
    
    print(f"\nğŸ‰ ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ìƒì„± íŒŒì¼: {len(saved_files)}ê°œ")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {data_dir}/")
    
    return saved_files

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸŒŸ ì „ë¶ 14ê°œ ì§€ì—­ë³„ Ã— 3ê°œ íƒ€ì…ë³„ ê´€ê´‘ì§€ ë°ì´í„° ìƒì„±ê¸°")
    print("=" * 70)
    print("ğŸ“Œ í•µì‹¬ ìš”êµ¬ì‚¬í•­:")
    print("   1. ì „ë¶ 14ê°œ ì§€ì—­ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬") 
    print("   2. ê´€ê´‘ì§€/ìˆ™ë°•/ìŒì‹ì  3ê°œ íƒ€ì…ìœ¼ë¡œ ë¶„ë¥˜")
    print("   3. ì´ 42ê°œ ë°ì´í„°ì…‹ ìƒì„± (14 Ã— 3)")
    print("   4. ìƒì„¸ ì£¼ì†Œ ì •ë³´ ìˆ˜ì§‘ (ì‹œ/êµ° ë‹¨ìœ„ê¹Œì§€)")
    print()
    
    try:
        # 1ë‹¨ê³„: ê´€ê´‘ì§€ ë°ì´í„° ì²˜ë¦¬ (ê°€ì¥ ì¤‘ìš”!)
        attractions_data, failed_attractions = process_attractions_data()
        
        # 2ë‹¨ê³„: ê¸°ì¡´ íŒŒì¼ë“¤ ì²˜ë¦¬ 
        existing_data = process_existing_data()
        
        # 3ë‹¨ê³„: ìˆ™ë°•/ìŒì‹ì  ì‹ ê·œ ìˆ˜ì§‘
        new_data = create_accommodations_and_restaurants()
        
        # 4ë‹¨ê³„: 42ê°œ ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥
        saved_files = save_regional_datasets(attractions_data, existing_data, new_data)
        
        print(f"\nâœ… ì „ë¶ ì§€ì—­ë³„ ê´€ê´‘ì§€ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼: {len(saved_files)}ê°œ")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()