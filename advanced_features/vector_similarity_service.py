"""
ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ê´€ê´‘ì§€/ë†ê°€ ì¶”ì²œ ì„œë¹„ìŠ¤
PostgreSQL + pgvectorë¥¼ í™œìš©í•œ ì˜ë¯¸ì  ê²€ìƒ‰ ì‹œìŠ¤í…œ

ì£¼ìš” ê¸°ëŠ¥:
1. ì‚¬ìš©ì ìì—°ì–´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
2. ê´€ê´‘ì§€ ë²¡í„°ì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
3. ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ê²°ê³¼ ë°˜í™˜
"""

import numpy as np
from typing import List, Dict, Any, Tuple
from sqlalchemy.orm import Session
from sqlalchemy import text
from app.db.models import TourSpot, JobPost, User
from app.embeddings.embedding_service import embed_text, embed_texts
from app.config import get_settings

class VectorSimilarityService:
    """ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.settings = get_settings()
    
    def calculate_cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """
        ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            vec1: ì²« ë²ˆì§¸ ë²¡í„° (1536ì°¨ì›)
            vec2: ë‘ ë²ˆì§¸ ë²¡í„° (1536ì°¨ì›)
            
        Returns:
            ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’ (0-1 ì‚¬ì´, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
        """
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        a = np.array(vec1, dtype=np.float32)
        b = np.array(vec2, dtype=np.float32)
        
        # ë²¡í„° í¬ê¸° ê³„ì‚°
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        
        # 0 ë²¡í„° ì²˜ë¦¬
        if norm_a == 0 or norm_b == 0:
            return 0.0
            
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = (AÂ·B) / (|A| * |B|)
        similarity = np.dot(a, b) / (norm_a * norm_b)
        
        # ìœ ì‚¬ë„ë¥¼ 0-1 ì‚¬ì´ ê°’ìœ¼ë¡œ ì •ê·œí™” (ì½”ì‚¬ì¸ ê°’ì€ -1~1)
        return float((similarity + 1) / 2)
    
    def find_similar_tours_by_vector(self, 
                                   db: Session, 
                                   query_text: str, 
                                   region: str = None,
                                   limit: int = 10,
                                   similarity_threshold: float = 0.7) -> List[Dict[str, Any]]:
        """
        ë²¡í„° ìœ ì‚¬ë„ë¥¼ í™œìš©í•œ ê´€ê´‘ì§€ ê²€ìƒ‰
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            query_text: ì‚¬ìš©ì ìì—°ì–´ ì…ë ¥
            region: ì§€ì—­ í•„í„° (ì˜µì…˜)
            limit: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
            similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
            
        Returns:
            ìœ ì‚¬ë„ ê¸°ë°˜ ì •ë ¬ëœ ê´€ê´‘ì§€ ëª©ë¡
        """
        
        print(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì‹œì‘: '{query_text}'")
        
        # 1. ì‚¬ìš©ì ì…ë ¥ì„ ë²¡í„°ë¡œ ë³€í™˜
        try:
            query_vector = embed_text(query_text)
            print(f"âœ… ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì™„ë£Œ: {len(query_vector)}ì°¨ì›")
        except Exception as e:
            print(f"âŒ ë²¡í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return []
        
        # 2. PostgreSQL + pgvectorë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰
        try:
            # pgvectorì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì—°ì‚°ì (<->) ì‚¬ìš©
            sql_query = text("""
                SELECT 
                    id, name, region, tags, lat, lon, contentid, image_url,
                    detailed_keywords, keywords,
                    (pref_vector <-> :query_vector::vector) as distance,
                    (1 - (pref_vector <-> :query_vector::vector)) as similarity
                FROM tour_spots 
                WHERE pref_vector IS NOT NULL
                  AND (:region IS NULL OR region = :region)
                ORDER BY pref_vector <-> :query_vector::vector
                LIMIT :limit
            """)
            
            result = db.execute(sql_query, {
                'query_vector': query_vector,
                'region': region,
                'limit': limit
            }).fetchall()
            
            print(f"âœ… PostgreSQL ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(result)}ê°œ ê²°ê³¼")
            
        except Exception as e:
            print(f"âŒ pgvector ê²€ìƒ‰ ì‹¤íŒ¨, ë©”ëª¨ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜: {e}")
            return self._fallback_memory_search(db, query_vector, region, limit, similarity_threshold)
        
        # 3. ê²°ê³¼ ê°€ê³µ
        recommendations = []
        for row in result:
            # ìœ ì‚¬ë„ ì„ê³„ê°’ í•„í„°ë§
            if row.similarity < similarity_threshold:
                continue
                
            recommendations.append({
                'id': row.id,
                'name': row.name,
                'region': row.region,
                'tags': row.tags,
                'lat': row.lat,
                'lon': row.lon,
                'contentid': row.contentid,
                'image_url': row.image_url,
                'keywords': row.keywords,
                'similarity_score': float(row.similarity),
                'distance': float(row.distance),
                'search_method': 'pgvector'
            })
        
        print(f"ğŸ¯ ìµœì¢… ì¶”ì²œ ê²°ê³¼: {len(recommendations)}ê°œ (ì„ê³„ê°’: {similarity_threshold})")
        return recommendations
    
    def _fallback_memory_search(self, 
                               db: Session, 
                               query_vector: List[float],
                               region: str = None,
                               limit: int = 10,
                               similarity_threshold: float = 0.7) -> List[Dict[str, Any]]:
        """
        pgvector ì‹¤íŒ¨ ì‹œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰ (í´ë°±)
        """
        print("ğŸ”„ ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì‹œì‘")
        
        # ë²¡í„°ê°€ ìˆëŠ” ê´€ê´‘ì§€ë§Œ ì¡°íšŒ
        query = db.query(TourSpot).filter(TourSpot.pref_vector.isnot(None))
        if region:
            query = query.filter(TourSpot.region == region)
        
        tour_spots = query.all()
        print(f"ğŸ“Š ê²€ìƒ‰ ëŒ€ìƒ ê´€ê´‘ì§€: {len(tour_spots)}ê°œ")
        
        # ê° ê´€ê´‘ì§€ì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for tour in tour_spots:
            if not tour.pref_vector:
                continue
                
            similarity = self.calculate_cosine_similarity(query_vector, tour.pref_vector)
            
            if similarity >= similarity_threshold:
                similarities.append({
                    'tour': tour,
                    'similarity': similarity
                })
        
        # ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        similarities = similarities[:limit]
        
        print(f"ğŸ¯ ë©”ëª¨ë¦¬ ê²€ìƒ‰ ê²°ê³¼: {len(similarities)}ê°œ")
        
        # ê²°ê³¼ í˜•ì‹ ë§ì¶¤
        recommendations = []
        for item in similarities:
            tour = item['tour']
            recommendations.append({
                'id': tour.id,
                'name': tour.name,
                'region': tour.region,
                'tags': tour.tags,
                'lat': tour.lat,
                'lon': tour.lon,
                'contentid': tour.contentid,
                'image_url': tour.image_url,
                'keywords': tour.keywords,
                'similarity_score': item['similarity'],
                'distance': 1 - item['similarity'],  # ê±°ë¦¬ = 1 - ìœ ì‚¬ë„
                'search_method': 'memory'
            })
        
        return recommendations
    
    def find_similar_jobs_by_vector(self, 
                                  db: Session,
                                  query_text: str,
                                  region: str = None,
                                  limit: int = 10,
                                  similarity_threshold: float = 0.7) -> List[Dict[str, Any]]:
        """
        ë²¡í„° ìœ ì‚¬ë„ë¥¼ í™œìš©í•œ ë†ê°€ ì¼ìë¦¬ ê²€ìƒ‰
        """
        print(f"ğŸšœ ë†ê°€ ë²¡í„° ê²€ìƒ‰ ì‹œì‘: '{query_text}'")
        
        # ì‚¬ìš©ì ì…ë ¥ì„ ë²¡í„°ë¡œ ë³€í™˜
        try:
            query_vector = embed_text(query_text)
        except Exception as e:
            print(f"âŒ ë†ê°€ ë²¡í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return []
        
        # ë†ê°€ ë°ì´í„° ê²€ìƒ‰ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        query = db.query(JobPost).filter(JobPost.pref_vector.isnot(None))
        if region:
            query = query.filter(JobPost.region == region)
        
        jobs = query.all()
        print(f"ğŸ“Š ê²€ìƒ‰ ëŒ€ìƒ ë†ê°€: {len(jobs)}ê°œ")
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for job in jobs:
            if not job.pref_vector:
                continue
                
            similarity = self.calculate_cosine_similarity(query_vector, job.pref_vector)
            
            if similarity >= similarity_threshold:
                similarities.append({
                    'job': job,
                    'similarity': similarity
                })
        
        # ì •ë ¬ ë° ì œí•œ
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        similarities = similarities[:limit]
        
        # ê²°ê³¼ í¬ë§·íŒ…
        recommendations = []
        for item in similarities:
            job = item['job']
            recommendations.append({
                'id': job.id,
                'title': job.title,
                'region': job.region,
                'address': job.address,
                'crop_type': job.crop_type,
                'work_date': job.work_date,
                'work_hours': job.work_hours,
                'tags': job.tags,
                'image_url': job.image_url,
                'similarity_score': item['similarity'],
                'search_method': 'vector'
            })
        
        print(f"ğŸ¯ ë†ê°€ ê²€ìƒ‰ ê²°ê³¼: {len(recommendations)}ê°œ")
        return recommendations
    
    def update_content_vectors(self, db: Session, content_type: str = "tour") -> Dict[str, int]:
        """
        ì½˜í…ì¸ ì˜ ë²¡í„°ë¥¼ ì¼ê´„ ì—…ë°ì´íŠ¸
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            content_type: "tour" ë˜ëŠ” "job"
            
        Returns:
            ì—…ë°ì´íŠ¸ í†µê³„
        """
        print(f"ğŸ“¦ {content_type} ë²¡í„° ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        if content_type == "tour":
            return self._update_tour_vectors(db)
        elif content_type == "job":
            return self._update_job_vectors(db)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” content_type: {content_type}")
    
    def _update_tour_vectors(self, db: Session) -> Dict[str, int]:
        """ê´€ê´‘ì§€ ë²¡í„° ì—…ë°ì´íŠ¸"""
        
        # ë²¡í„°ê°€ ì—†ëŠ” ê´€ê´‘ì§€ ì¡°íšŒ
        tours_without_vector = db.query(TourSpot).filter(
            TourSpot.pref_vector.is_(None)
        ).all()
        
        print(f"ğŸ“ ë²¡í„° ì—…ë°ì´íŠ¸ ëŒ€ìƒ ê´€ê´‘ì§€: {len(tours_without_vector)}ê°œ")
        
        if not tours_without_vector:
            return {"updated": 0, "failed": 0, "skipped": len(tours_without_vector)}
        
        # ë²¡í„°í™”í•  í…ìŠ¤íŠ¸ ì¤€ë¹„
        texts_to_embed = []
        for tour in tours_without_vector:
            # ê´€ê´‘ì§€ ì´ë¦„ + í‚¤ì›Œë“œ + ì§€ì—­ ì •ë³´ ê²°í•©
            text_content = f"{tour.name}"
            if tour.keywords:
                text_content += f" {tour.keywords}"
            if tour.tags:
                text_content += f" {tour.tags}"
            if tour.region:
                text_content += f" {tour.region}"
            
            texts_to_embed.append(text_content)
        
        try:
            # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
            vectors = embed_texts(texts_to_embed)
            print(f"âœ… ë²¡í„° ìƒì„± ì™„ë£Œ: {len(vectors)}ê°œ")
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            updated_count = 0
            for i, tour in enumerate(tours_without_vector):
                try:
                    tour.pref_vector = vectors[i]
                    db.add(tour)
                    updated_count += 1
                except Exception as e:
                    print(f"âŒ ê´€ê´‘ì§€ {tour.name} ë²¡í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            
            db.commit()
            print(f"âœ… ê´€ê´‘ì§€ ë²¡í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_count}ê°œ")
            
            return {
                "updated": updated_count,
                "failed": len(tours_without_vector) - updated_count,
                "skipped": 0
            }
            
        except Exception as e:
            print(f"âŒ ê´€ê´‘ì§€ ë²¡í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            db.rollback()
            return {"updated": 0, "failed": len(tours_without_vector), "skipped": 0}
    
    def _update_job_vectors(self, db: Session) -> Dict[str, int]:
        """ë†ê°€ ì¼ìë¦¬ ë²¡í„° ì—…ë°ì´íŠ¸"""
        
        jobs_without_vector = db.query(JobPost).filter(
            JobPost.pref_vector.is_(None)
        ).all()
        
        print(f"ğŸšœ ë²¡í„° ì—…ë°ì´íŠ¸ ëŒ€ìƒ ë†ê°€: {len(jobs_without_vector)}ê°œ")
        
        if not jobs_without_vector:
            return {"updated": 0, "failed": 0, "skipped": len(jobs_without_vector)}
        
        # ë²¡í„°í™”í•  í…ìŠ¤íŠ¸ ì¤€ë¹„
        texts_to_embed = []
        for job in jobs_without_vector:
            text_content = f"{job.title}"
            if job.crop_type:
                text_content += f" {job.crop_type}"
            if job.tags:
                text_content += f" {job.tags}"
            if job.region:
                text_content += f" {job.region}"
            if job.preference_condition:
                text_content += f" {job.preference_condition}"
            
            texts_to_embed.append(text_content)
        
        try:
            vectors = embed_texts(texts_to_embed)
            
            updated_count = 0
            for i, job in enumerate(jobs_without_vector):
                try:
                    job.pref_vector = vectors[i]
                    db.add(job)
                    updated_count += 1
                except Exception as e:
                    print(f"âŒ ë†ê°€ {job.title} ë²¡í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            
            db.commit()
            print(f"âœ… ë†ê°€ ë²¡í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_count}ê°œ")
            
            return {
                "updated": updated_count,
                "failed": len(jobs_without_vector) - updated_count,
                "skipped": 0
            }
            
        except Exception as e:
            print(f"âŒ ë†ê°€ ë²¡í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            db.rollback()
            return {"updated": 0, "failed": len(jobs_without_vector), "skipped": 0}
    
    def semantic_search_demo(self, db: Session, query: str) -> Dict[str, Any]:
        """
        ë²¡í„° ê¸°ë°˜ ì˜ë¯¸ì  ê²€ìƒ‰ ë°ëª¨
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            query: ìì—°ì–´ ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ì™€ ì„±ëŠ¥ ì •ë³´
        """
        import time
        
        start_time = time.time()
        
        print(f"ğŸ¯ ì˜ë¯¸ì  ê²€ìƒ‰ ë°ëª¨: '{query}'")
        
        # ê´€ê´‘ì§€ ê²€ìƒ‰
        tour_results = self.find_similar_tours_by_vector(
            db=db,
            query_text=query,
            limit=5,
            similarity_threshold=0.6
        )
        
        # ë†ê°€ ê²€ìƒ‰
        job_results = self.find_similar_jobs_by_vector(
            db=db,
            query_text=query,
            limit=3,
            similarity_threshold=0.6
        )
        
        end_time = time.time()
        
        return {
            "query": query,
            "tour_results": tour_results,
            "job_results": job_results,
            "performance": {
                "search_time": end_time - start_time,
                "tour_count": len(tour_results),
                "job_count": len(job_results)
            },
            "search_explanation": {
                "method": "ë²¡í„° ì˜ë¯¸ì  ê²€ìƒ‰",
                "embedding_model": "text-embedding-3-small",
                "vector_dimension": 1536,
                "similarity_metric": "ì½”ì‚¬ì¸ ìœ ì‚¬ë„"
            }
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_vector_service = None

def get_vector_similarity_service() -> VectorSimilarityService:
    """VectorSimilarityService ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _vector_service
    if _vector_service is None:
        _vector_service = VectorSimilarityService()
    return _vector_service