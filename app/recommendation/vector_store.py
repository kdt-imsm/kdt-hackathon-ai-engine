"""
app/recommendation/vector_store.py
==================================
pgvectorë¥¼ í™œìš©í•œ **ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰** í—¬í¼

* ê¸°ëŠ¥
  1. ``search_jobs``  : ì‚¬ìš©ì ë²¡í„° â†” JobPost.pref_vector ìœ ì‚¬ë„ ìƒìœ„ Nê°œ ì¡°íšŒ
  2. ``search_tours`` : ì‚¬ìš©ì ë²¡í„° â†” TourSpot.pref_vector ìœ ì‚¬ë„ ìƒìœ„ Nê°œ ì¡°íšŒ
  3. ``search_jobs_with_location`` : ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§ê³¼ ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ ê²€ìƒ‰
  4. ``search_tours_with_location`` : ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§ê³¼ ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ ê²€ìƒ‰

* êµ¬í˜„ ë°©ì‹
  - PostgreSQL + pgvector ì—°ì‚°ì ``<#>`` (inner product/cosine distance) ì‚¬ìš©
  - *1 - distance* ë¡œ ìŠ¤ì½”ì–´ë¥¼ ë³€í™˜í•˜ì—¬ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ìŒ
  - ìœ„ì¹˜ í•„í„°ë§ ì‹œ ê±°ë¦¬ ê³„ì‚°ê³¼ ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ ë³µí•© ì ìˆ˜ ì‚¬ìš©
  - ê²°ê³¼ëŠ” `(ORM ê°ì²´, score)` íŠœí”Œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•´ ì¶”í›„ ë­í‚¹Â·í•„í„°ë§ì— í™œìš©

ì£¼ì˜
----
ì´ ëª¨ë“ˆì€ ë‹¨ì¼ SQL ì¿¼ë¦¬ë¡œ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ, ëŒ€ê·œëª¨ íŠ¸ë˜í”½ í™˜ê²½ì—ì„œëŠ”
ë³„ë„ì˜ ë²¡í„° DB(ì˜ˆ: **Pinecone**, **Weaviate**) ë„ì…ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
"""

from typing import Optional, Tuple, List
from sqlalchemy import text  # RAW SQL ì‹¤í–‰ìš©
from app.db.database import SessionLocal
from app.config import get_settings
from app.utils.location import get_location_coords, calculate_distance, calculate_location_score
from app.utils.keyword_search import get_keyword_service
import json

settings = get_settings()  # .env â†’ Settings ì‹±ê¸€í„´


# ë‚´ë¶€ ì „ìš© RAW ì¿¼ë¦¬ ì‹¤í–‰ í•¸ë“¤ëŸ¬ -------------------------------------------

def _query(sql: str, vec: list[float], lim: int):
    """Parameterized RAW SQL ì‹¤í–‰ í›„ Row ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    with SessionLocal() as db:
        return db.execute(text(sql), {"uvec": vec, "lim": lim}).all()


def _query_with_location(sql: str, vec: list[float], lat: float, lon: float, lim: int):
    """ìœ„ì¹˜ íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ RAW SQL ì‹¤í–‰."""
    with SessionLocal() as db:
        return db.execute(text(sql), {"uvec": vec, "lat": lat, "lon": lon, "lim": lim}).all()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# JobPost ë²¡í„° ê²€ìƒ‰ -------------------------------------------------------
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def search_jobs(user_vec, limit=None):
    """JobPost í…Œì´ë¸”ì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìƒìœ„ *limit*ê±´ ì¡°íšŒ.

    Returns
    -------
    list[tuple[JobPost, float]]
        (ORM ì¸ìŠ¤í„´ìŠ¤, score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸.
    """
    if limit is None:
        limit = settings.max_results  # ì„¤ì •ì— ì—†ìœ¼ë©´ AttributeError ë°œìƒ ê°€ëŠ¥

    sql = """
    SELECT *, 1 - (pref_vector <#> CAST(:uvec AS vector)) AS score
    FROM jobs
    WHERE pref_vector IS NOT NULL
    ORDER BY pref_vector <#> CAST(:uvec AS vector)
    LIMIT :lim
    """

    rows = _query(sql, user_vec, limit)

    # ë²¡í„°ê°€ ì—†ëŠ” ê²½ìš° fallback: ìµœì‹  ë ˆì½”ë“œ ë°˜í™˜
    if not rows:
        fallback_sql = """
        SELECT *, 0.5 AS score
        FROM jobs
        ORDER BY id DESC
        LIMIT :lim
        """
        rows = _query(fallback_sql, user_vec, limit)

    from app.db.models import JobPost  # ìˆœí™˜ import ë°©ì§€ìš© ì§€ì—° import
    results = []
    for row in rows:
        data = row._mapping  # RowMapping
        # Row â†’ ORM ê°ì²´ë¡œ ë§¤í•‘ (í¸ì˜ìƒ ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
        job = JobPost(**{col.name: data[col.name] for col in JobPost.__table__.columns})
        score = data.get("score")
        results.append((job, score))
    return results


def search_jobs_with_location(
    user_vec, 
    user_coords: Optional[Tuple[float, float]] = None,
    max_distance_km: float = 100.0,
    location_weight: float = 0.3,
    limit=None
):
    """
    ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§ê³¼ ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ JobPost ê²€ìƒ‰.
    
    Parameters
    ----------
    user_vec : list[float]
        ì‚¬ìš©ì ì„ í˜¸ë„ ë²¡í„°
    user_coords : Optional[Tuple[float, float]]
        ì‚¬ìš©ì ìœ„ì¹˜ (ìœ„ë„, ê²½ë„). Noneì´ë©´ ìœ„ì¹˜ í•„í„°ë§ ì—†ìŒ
    max_distance_km : float, default=100.0
        ìµœëŒ€ ê²€ìƒ‰ ê±°ë¦¬ (km)
    location_weight : float, default=0.3
        ìœ„ì¹˜ ì ìˆ˜ ê°€ì¤‘ì¹˜ (0.0~1.0)
    limit : int, optional
        ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
    Returns
    -------
    list[tuple[JobPost, float]]
        (ORM ì¸ìŠ¤í„´ìŠ¤, ë³µí•© ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    if limit is None:
        limit = getattr(settings, 'max_results', 20)
        
    # ìœ„ì¹˜ í•„í„°ë§ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ ì‚¬ìš©
    if user_coords is None:
        return search_jobs(user_vec, limit)
    
    user_lat, user_lon = user_coords
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ Pythonì—ì„œ í•„í„°ë§ (PostGIS ì—†ì´ë„ ë™ì‘)
    all_jobs = search_jobs(user_vec, limit * 3)
    results = []
    
    for job, vector_score in all_jobs:
        if job.lat is None or job.lon is None:
            continue
            
        distance = calculate_distance(user_lat, user_lon, job.lat, job.lon)
        if distance <= max_distance_km:
            location_score = calculate_location_score(distance, max_distance_km)
            # ë³µí•© ì ìˆ˜ ê³„ì‚°: ë²¡í„° ìœ ì‚¬ë„ + ìœ„ì¹˜ ì ìˆ˜
            combined_score = (1 - location_weight) * float(vector_score) + location_weight * float(location_score)
            results.append((job, combined_score))
    
    # ë³µí•© ì ìˆ˜ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ limitê°œ ë°˜í™˜
    results.sort(key=lambda x: x[1], reverse=True)
    return results[:limit]


def search_jobs_guaranteed(
    user_vec, 
    user_coords: Optional[Tuple[float, float]] = None,
    user_regions: Optional[List[str]] = None,
    target_count: int = 10,
    max_distance_km: float = 100.0,
    location_weight: float = 0.4
):
    """
    ì •í™•íˆ target_count ê°œì˜ ì¼ê±°ë¦¬ë¥¼ ë³´ì¥í•˜ëŠ” ê²€ìƒ‰ í•¨ìˆ˜.
    ì‚¬ìš©ìê°€ ì§€ì—­ì„ ì§€ì •í•œ ê²½ìš° í•´ë‹¹ ì§€ì—­ ë‚´ ê²°ê³¼ë¥¼ ìš°ì„  ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Parameters
    ----------
    user_vec : list[float]
        ì‚¬ìš©ì ì„ í˜¸ë„ ë²¡í„°
    user_coords : Optional[Tuple[float, float]]
        ì‚¬ìš©ì ìœ„ì¹˜ (ìœ„ë„, ê²½ë„)
    user_regions : Optional[List[str]]
        ì‚¬ìš©ì ì§€ì • ì§€ì—­ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["ì „ë¶ ê³ ì°½"])
    target_count : int, default=10
        ë°˜í™˜í•  ì •í™•í•œ ê²°ê³¼ ê°œìˆ˜
    max_distance_km : float, default=100.0
        ì´ˆê¸° ìµœëŒ€ ê²€ìƒ‰ ê±°ë¦¬ (km)
    location_weight : float, default=0.4
        ìœ„ì¹˜ ì ìˆ˜ ê°€ì¤‘ì¹˜
        
    Returns
    -------
    list[tuple[JobPost, float]]
        ì •í™•íˆ target_count ê°œì˜ (ì¼ê±°ë¦¬, ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    from app.utils.location import get_progressive_region_patterns, match_region_strict
    
    # ì§€ì—­ ê¸°ë°˜ ë‹¨ê³„ë³„ ê²€ìƒ‰
    if user_regions:
        expansion_patterns = get_progressive_region_patterns(user_regions)
        print(f"ì§€ì—­ í™•ì¥ íŒ¨í„´: {expansion_patterns}")
        
        accumulated_results = []
        existing_ids = set()
        
        for region_pattern, region_weight, _ in expansion_patterns:
            print(f"ì§€ì—­ '{region_pattern}' ê²€ìƒ‰ ì¤‘...")
            
            # í•´ë‹¹ ì§€ì—­ ë‚´ì—ì„œ ë²¡í„° ê²€ìƒ‰
            region_results = search_jobs_by_region(
                user_vec, region_pattern, user_coords, 
                max_distance_km, location_weight, target_count * 2
            )
            
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ê²°ê³¼ ëˆ„ì 
            for job, score in region_results:
                if job.id not in existing_ids:
                    accumulated_results.append((job, float(score) * region_weight))
                    existing_ids.add(job.id)
            
            print(f"ì§€ì—­ '{region_pattern}'ì—ì„œ {len(region_results)}ê°œ ë°œê²¬, ëˆ„ì : {len(accumulated_results)}ê°œ")
            
            if len(accumulated_results) >= target_count:
                # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ë°˜í™˜
                accumulated_results.sort(key=lambda x: x[1], reverse=True)
                return accumulated_results[:target_count]
        
        # ì§€ì—­ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°
        if accumulated_results:
            needed_count = target_count - len(accumulated_results)
            print(f"ì§€ì—­ ê²€ìƒ‰ìœ¼ë¡œ {len(accumulated_results)}ê°œ í™•ë³´, {needed_count}ê°œ ë” í•„ìš”")
            
            # ì „êµ­ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„
            additional_results = search_jobs(user_vec, target_count * 3)
            for job, score in additional_results:
                if job.id not in existing_ids:
                    accumulated_results.append((job, float(score) * 0.3))  # ì§€ì—­ ì™¸ ê²°ê³¼ëŠ” ì ìˆ˜ ë‚®ê²Œ
                    needed_count -= 1
                    if needed_count <= 0:
                        break
            
            accumulated_results.sort(key=lambda x: x[1], reverse=True)
            return accumulated_results[:target_count]
    # 1ë‹¨ê³„: ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ ì‹œë„
    if user_coords is not None:
        results = search_jobs_with_location(
            user_vec, user_coords, max_distance_km, location_weight, target_count
        )
        
        if len(results) >= target_count:
            return results[:target_count]
        
        # ë¶€ì¡±í•œ ê²½ìš° ê±°ë¦¬ ì œí•œì„ 2ë°°ë¡œ í™•ì¥
        extended_results = search_jobs_with_location(
            user_vec, user_coords, max_distance_km * 2, location_weight, target_count * 2
        )
        
        if len(extended_results) >= target_count:
            return extended_results[:target_count]
        
        # ì—¬ì „íˆ ë¶€ì¡±í•œ ê²½ìš° ê¸°ì¡´ ê²°ê³¼ ë³´ì¡´í•˜ê³  ì¶”ê°€ ê²€ìƒ‰
        existing_ids = {job.id for job, _ in extended_results}
        needed_count = target_count - len(extended_results)
    else:
        extended_results = []
        existing_ids = set()
        needed_count = target_count
    
    # 2ë‹¨ê³„: ìœ„ì¹˜ ì œí•œ ì—†ëŠ” ë²¡í„° ìœ ì‚¬ë„ë§Œìœ¼ë¡œ ë³´ì™„
    all_results = search_jobs(user_vec, target_count * 3)
    additional_results = []
    
    for job, score in all_results:
        if job.id not in existing_ids:
            additional_results.append((job, score))
            if len(additional_results) >= needed_count:
                break
    
    # 3ë‹¨ê³„: ê²°ê³¼ ê²°í•© ë° ì •ë ¬
    final_results = list(extended_results) + additional_results[:needed_count]
    
    # 4ë‹¨ê³„: ì—¬ì „íˆ ë¶€ì¡±í•œ ê²½ìš° ìµœí›„ ìˆ˜ë‹¨
    if len(final_results) < target_count:
        # ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëœë¤ ì„ íƒìœ¼ë¡œ ì±„ìš°ê¸°
        with SessionLocal() as db:
            from app.db.models import JobPost
            existing_job_ids = {job.id for job, _ in final_results}
            
            remaining_jobs = db.query(JobPost).filter(
                ~JobPost.id.in_(existing_job_ids)
            ).limit(target_count - len(final_results)).all()
            
            for job in remaining_jobs:
                final_results.append((job, 0.1))  # ìµœì†Œ ì ìˆ˜
    
    return final_results[:target_count]


def search_jobs_by_region(
    user_vec,
    region_pattern: str,
    user_coords: Optional[Tuple[float, float]] = None,
    max_distance_km: float = 100.0,
    location_weight: float = 0.4,
    limit: int = 10
):
    """
    íŠ¹ì • ì§€ì—­ íŒ¨í„´ì— í•´ë‹¹í•˜ëŠ” ì¼ê±°ë¦¬ë¥¼ ë²¡í„° ìœ ì‚¬ë„ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ì§€ì—­ ë§¤ì¹­ê³¼ ê±°ë¦¬ ê¸°ë°˜ í•„í„°ë§ì„ ëª¨ë‘ ì ìš©í•©ë‹ˆë‹¤.
    """
    from app.utils.location import is_region_match, calculate_distance, calculate_location_score
    
    print(f"ğŸ” ì¼ê±°ë¦¬ ì§€ì—­ ê²€ìƒ‰: '{region_pattern}' (ìµœëŒ€ê±°ë¦¬: {max_distance_km}km)")
    
    # ëª¨ë“  ì¼ê±°ë¦¬ë¥¼ ê°€ì ¸ì™€ì„œ ì§€ì—­ í•„í„°ë§
    all_results = search_jobs(user_vec, limit * 10)  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§
    
    region_filtered = []
    distance_filtered = []
    
    for job, score in all_results:
        # 1ë‹¨ê³„: ì§€ì—­ ë§¤ì¹­ í™•ì¸
        is_match, region_score = is_region_match(job.region, [region_pattern])
        
        if is_match:
            # ì§€ì—­ ë§¤ì¹­ ì„±ê³µ ì‹œ ê°•ë ¥í•œ ë¶€ìŠ¤íŠ¸ ì ìš©
            region_boost = 2.0 * float(region_score)
            boosted_score = float(score) + region_boost
            region_filtered.append((job, boosted_score))
            
            # 2ë‹¨ê³„: ê±°ë¦¬ ê¸°ë°˜ ì¶”ê°€ í•„í„°ë§ (ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš°)
            if user_coords and job.lat and job.lon:
                user_lat, user_lon = user_coords
                distance = calculate_distance(user_lat, user_lon, job.lat, job.lon)
                
                if distance <= max_distance_km:
                    location_score = calculate_location_score(distance, max_distance_km)
                    final_score = float(boosted_score) * (1 - location_weight) + float(location_score) * location_weight
                    distance_filtered.append((job, final_score, distance))
                    print(f"  âœ… {job.title} ({job.region}) - ê±°ë¦¬: {distance:.1f}km, ì ìˆ˜: {final_score:.3f}")
    
    print(f"í•„í„°ë§ ê²°ê³¼: ì§€ì—­ë§¤ì¹­ {len(region_filtered)}ê°œ â†’ ê±°ë¦¬í•„í„°ë§ {len(distance_filtered)}ê°œ")
    
    # ê±°ë¦¬ í•„í„°ë§ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    if distance_filtered:
        distance_filtered.sort(key=lambda x: x[1], reverse=True)
        return [(job, score) for job, score, _ in distance_filtered[:limit]]
    
    # ê±°ë¦¬ í•„í„°ë§ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì§€ì—­ ë§¤ì¹­ ê²°ê³¼ë§Œ ì‚¬ìš©
    region_filtered.sort(key=lambda x: x[1], reverse=True)
    return region_filtered[:limit]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TourSpot ë²¡í„° ê²€ìƒ‰ ------------------------------------------------------
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def search_tours(user_vec, limit=None):
    """TourSpot í…Œì´ë¸”ì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìƒìœ„ *limit*ê±´ ì¡°íšŒ."""
    if limit is None:
        limit = settings.max_results

    sql = """
    SELECT *, 1 - (pref_vector <#> CAST(:uvec AS vector)) AS score
    FROM tour_spots
    WHERE pref_vector IS NOT NULL
    ORDER BY pref_vector <#> CAST(:uvec AS vector)
    LIMIT :lim
    """

    rows = _query(sql, user_vec, limit)

    # ë²¡í„°ê°€ ì—†ëŠ” ê²½ìš° fallback: ìµœì‹  ë ˆì½”ë“œ ë°˜í™˜
    if not rows:
        fallback_sql = """
        SELECT *, 0.5 AS score
        FROM tour_spots
        ORDER BY id DESC
        LIMIT :lim
        """
        rows = _query(fallback_sql, user_vec, limit)

    from app.db.models import TourSpot
    results = []
    for row in rows:
        data = row._mapping
        tour = TourSpot(**{col.name: data[col.name] for col in TourSpot.__table__.columns})
        score = data.get("score")
        results.append((tour, score))
    return results


def search_tours_with_location(
    user_vec, 
    user_coords: Optional[Tuple[float, float]] = None,
    max_distance_km: float = 100.0,
    location_weight: float = 0.3,
    limit=None
):
    """
    ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§ê³¼ ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ TourSpot ê²€ìƒ‰.
    
    ParametersëŠ” search_jobs_with_locationê³¼ ë™ì¼.
    """
    if limit is None:
        limit = getattr(settings, 'max_results', 20)
        
    # ìœ„ì¹˜ í•„í„°ë§ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ ì‚¬ìš©
    if user_coords is None:
        return search_tours(user_vec, limit)
    
    user_lat, user_lon = user_coords
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ Pythonì—ì„œ í•„í„°ë§
    all_tours = search_tours(user_vec, limit * 3)
    results = []
    
    for tour, vector_score in all_tours:
        if tour.lat is None or tour.lon is None:
            continue
            
        distance = calculate_distance(user_lat, user_lon, tour.lat, tour.lon)
        if distance <= max_distance_km:
            location_score = calculate_location_score(distance, max_distance_km)
            combined_score = (1 - location_weight) * float(vector_score) + location_weight * float(location_score)
            results.append((tour, combined_score))
    
    results.sort(key=lambda x: x[1], reverse=True)
    return results[:limit]


def search_tours_guaranteed(
    user_vec, 
    user_coords: Optional[Tuple[float, float]] = None,
    user_regions: Optional[List[str]] = None,
    target_count: int = 10,
    max_distance_km: float = 100.0,
    location_weight: float = 0.4
):
    """
    ì •í™•íˆ target_count ê°œì˜ ê´€ê´‘ì§€ë¥¼ ë³´ì¥í•˜ëŠ” ê²€ìƒ‰ í•¨ìˆ˜.
    ì‚¬ìš©ìê°€ ì§€ì—­ì„ ì§€ì •í•œ ê²½ìš° í•´ë‹¹ ì§€ì—­ ë‚´ ê²°ê³¼ë¥¼ ìš°ì„  ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    from app.utils.location import get_progressive_region_patterns, match_region_strict
    
    # ì§€ì—­ ê¸°ë°˜ ë‹¨ê³„ë³„ ê²€ìƒ‰
    if user_regions:
        expansion_patterns = get_progressive_region_patterns(user_regions)
        
        accumulated_results = []
        existing_ids = set()
        
        for region_pattern, region_weight, _ in expansion_patterns:
            # í•´ë‹¹ ì§€ì—­ ë‚´ì—ì„œ ê´€ê´‘ì§€ ê²€ìƒ‰
            region_results = search_tours_by_region(
                user_vec, region_pattern, user_coords, 
                max_distance_km, location_weight, target_count * 2
            )
            
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ê²°ê³¼ ëˆ„ì 
            for tour, score in region_results:
                if tour.id not in existing_ids:
                    accumulated_results.append((tour, score * region_weight))
                    existing_ids.add(tour.id)
            
            if len(accumulated_results) >= target_count:
                # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ë°˜í™˜
                accumulated_results.sort(key=lambda x: x[1], reverse=True)
                return accumulated_results[:target_count]
        
        # ì§€ì—­ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš° ì „êµ­ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„
        if accumulated_results:
            needed_count = target_count - len(accumulated_results)
            additional_results = search_tours(user_vec, target_count * 3)
            for tour, score in additional_results:
                if tour.id not in existing_ids:
                    accumulated_results.append((tour, score * 0.3))
                    needed_count -= 1
                    if needed_count <= 0:
                        break
            
            accumulated_results.sort(key=lambda x: x[1], reverse=True)
            return accumulated_results[:target_count]
    # 1ë‹¨ê³„: ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰ ì‹œë„
    if user_coords is not None:
        results = search_tours_with_location(
            user_vec, user_coords, max_distance_km, location_weight, target_count
        )
        
        if len(results) >= target_count:
            return results[:target_count]
        
        # ë¶€ì¡±í•œ ê²½ìš° ê±°ë¦¬ ì œí•œì„ 2ë°°ë¡œ í™•ì¥
        extended_results = search_tours_with_location(
            user_vec, user_coords, max_distance_km * 2, location_weight, target_count * 2
        )
        
        if len(extended_results) >= target_count:
            return extended_results[:target_count]
        
        # ì—¬ì „íˆ ë¶€ì¡±í•œ ê²½ìš° ê¸°ì¡´ ê²°ê³¼ ë³´ì¡´í•˜ê³  ì¶”ê°€ ê²€ìƒ‰
        existing_ids = {tour.id for tour, _ in extended_results}
        needed_count = target_count - len(extended_results)
    else:
        extended_results = []
        existing_ids = set()
        needed_count = target_count
    
    # 2ë‹¨ê³„: ìœ„ì¹˜ ì œí•œ ì—†ëŠ” ë²¡í„° ìœ ì‚¬ë„ë§Œìœ¼ë¡œ ë³´ì™„
    all_results = search_tours(user_vec, target_count * 3)
    additional_results = []
    
    for tour, score in all_results:
        if tour.id not in existing_ids:
            additional_results.append((tour, score))
            if len(additional_results) >= needed_count:
                break
    
    # 3ë‹¨ê³„: ê²°ê³¼ ê²°í•© ë° ì •ë ¬
    final_results = list(extended_results) + additional_results[:needed_count]
    
    # 4ë‹¨ê³„: ì—¬ì „íˆ ë¶€ì¡±í•œ ê²½ìš° ìµœí›„ ìˆ˜ë‹¨
    if len(final_results) < target_count:
        # ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëœë¤ ì„ íƒìœ¼ë¡œ ì±„ìš°ê¸°
        with SessionLocal() as db:
            from app.db.models import TourSpot
            existing_tour_ids = {tour.id for tour, _ in final_results}
            
            remaining_tours = db.query(TourSpot).filter(
                ~TourSpot.id.in_(existing_tour_ids)
            ).limit(target_count - len(final_results)).all()
            
            for tour in remaining_tours:
                final_results.append((tour, 0.1))  # ìµœì†Œ ì ìˆ˜
    
    return final_results[:target_count]


def search_tours_by_region(
    user_vec,
    region_pattern: str,
    user_coords: Optional[Tuple[float, float]] = None,
    max_distance_km: float = 100.0,
    location_weight: float = 0.4,
    limit: int = 10
):
    """
    íŠ¹ì • ì§€ì—­ íŒ¨í„´ì— í•´ë‹¹í•˜ëŠ” ê´€ê´‘ì§€ë¥¼ ë²¡í„° ìœ ì‚¬ë„ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ì§€ì—­ ë§¤ì¹­ê³¼ ê±°ë¦¬ ê¸°ë°˜ í•„í„°ë§ì„ ëª¨ë‘ ì ìš©í•©ë‹ˆë‹¤.
    """
    from app.utils.location import is_region_match, calculate_distance, calculate_location_score
    
    print(f"ğŸ” ê´€ê´‘ì§€ ì§€ì—­ ê²€ìƒ‰: '{region_pattern}' (ìµœëŒ€ê±°ë¦¬: {max_distance_km}km)")
    
    # ëª¨ë“  ê´€ê´‘ì§€ë¥¼ ê°€ì ¸ì™€ì„œ ì§€ì—­ í•„í„°ë§
    all_results = search_tours(user_vec, limit * 10)  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§
    
    region_filtered = []
    distance_filtered = []
    
    for tour, score in all_results:
        # 1ë‹¨ê³„: ì§€ì—­ ë§¤ì¹­ í™•ì¸
        is_match, region_score = is_region_match(tour.region, [region_pattern])
        
        if is_match:
            # ì§€ì—­ ë§¤ì¹­ ì„±ê³µ ì‹œ ê°•ë ¥í•œ ë¶€ìŠ¤íŠ¸ ì ìš©
            region_boost = 2.0 * region_score
            boosted_score = score + region_boost
            region_filtered.append((tour, boosted_score))
            
            # 2ë‹¨ê³„: ê±°ë¦¬ ê¸°ë°˜ ì¶”ê°€ í•„í„°ë§ (ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš°)
            if user_coords and tour.lat and tour.lon:
                user_lat, user_lon = user_coords
                distance = calculate_distance(user_lat, user_lon, tour.lat, tour.lon)
                
                if distance <= max_distance_km:
                    location_score = calculate_location_score(distance, max_distance_km)
                    final_score = boosted_score * (1 - location_weight) + location_score * location_weight
                    distance_filtered.append((tour, final_score, distance))
                    print(f"  âœ… {tour.name} ({tour.region}) - ê±°ë¦¬: {distance:.1f}km, ì ìˆ˜: {final_score:.3f}")
    
    print(f"í•„í„°ë§ ê²°ê³¼: ì§€ì—­ë§¤ì¹­ {len(region_filtered)}ê°œ â†’ ê±°ë¦¬í•„í„°ë§ {len(distance_filtered)}ê°œ")
    
    # ê±°ë¦¬ í•„í„°ë§ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    if distance_filtered:
        # ì ìˆ˜ìˆœ ì •ë ¬
        distance_filtered.sort(key=lambda x: x[1], reverse=True)
        return [(tour, score) for tour, score, _ in distance_filtered[:limit]]
    
    # ê±°ë¦¬ í•„í„°ë§ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì§€ì—­ ë§¤ì¹­ ê²°ê³¼ë§Œ ì‚¬ìš©
    region_filtered.sort(key=lambda x: x[1], reverse=True)
    return region_filtered[:limit]
def search_jobs_region_first(
    user_vec, 
    user_regions: List[str],
    user_coords: Optional[Tuple[float, float]] = None,
    target_count: int = 10,
    max_distance_km: float = 100.0,
    location_weight: float = 0.4
):
    """
    ì§€ì—­ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ” ê²€ìƒ‰ í•¨ìˆ˜.
    ì§€ì—­ ë°ì´í„°ë¥¼ ë¨¼ì € ì¶”ì¶œí•œ í›„, í•´ë‹¹ ë²”ìœ„ ë‚´ì—ì„œë§Œ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    from app.utils.location import get_progressive_region_patterns
    
    print(f"ì§€ì—­ ìš°ì„  ì¼ê±°ë¦¬ ê²€ìƒ‰ ì‹œì‘")
    print(f"   ëŒ€ìƒ ì§€ì—­: {user_regions}")
    print(f"   ëª©í‘œ ê°œìˆ˜: {target_count}ê°œ")
    print(f"   ğŸ“ ìµœëŒ€ ê±°ë¦¬: {max_distance_km}km")
    print(f"   ğŸšï¸ ìœ„ì¹˜ ê°€ì¤‘ì¹˜: {location_weight}")
    if user_coords:
        print(f"   ì‚¬ìš©ì ì¢Œí‘œ: {user_coords}")
    
    expansion_patterns = get_progressive_region_patterns(user_regions)
    print(f"   ğŸ”„ í™•ì¥ íŒ¨í„´: {expansion_patterns}")
    
    accumulated_results = []
    existing_ids = set()
    
    for i, (region_pattern, region_weight, description) in enumerate(expansion_patterns, 1):
        print(f"\n[{i}/{len(expansion_patterns)}] '{region_pattern}' ({description})")
        print(f"   âš–ï¸ ì§€ì—­ ê°€ì¤‘ì¹˜: {region_weight}")
        
        # í•´ë‹¹ ì§€ì—­ ë‚´ì—ì„œ ë²¡í„° ê²€ìƒ‰
        region_results = search_jobs_by_region(
            user_vec, region_pattern, user_coords, 
            max_distance_km, location_weight, target_count * 3
        )
        
        # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ê²°ê³¼ ëˆ„ì 
        new_results = 0
        for job, score in region_results:
            if job.id not in existing_ids:
                # ì§€ì—­ë³„ ê°€ì¤‘ì¹˜ ì ìš© (ì •í™•í•œ ì§€ì—­ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
                final_score = float(score) * region_weight
                accumulated_results.append((job, final_score))
                existing_ids.add(job.id)
                new_results += 1
        
        print(f"   âœ… ìƒˆë¡œ ë°œê²¬: {new_results}ê°œ (ì¤‘ë³µ ì œì™¸)")
        print(f"   ğŸ“ˆ ëˆ„ì  ê²°ê³¼: {len(accumulated_results)}ê°œ")
        
        # ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ì–»ì—ˆìœ¼ë©´ ì¤‘ë‹¨
        if len(accumulated_results) >= target_count:
            print(f"   ğŸŠ ëª©í‘œ ë‹¬ì„±! ({target_count}ê°œ ì´ìƒ í™•ë³´)")
            break
    
    # ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°ì—ë§Œ ì „êµ­ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„
    if len(accumulated_results) < target_count:
        needed = target_count - len(accumulated_results)
        print(f"\nğŸŒ ì „êµ­ ê²€ìƒ‰ìœ¼ë¡œ {needed}ê°œ ì¶”ê°€ ê²€ìƒ‰...")
        
        nationwide_results = search_jobs(user_vec, target_count * 2)
        added = 0
        for job, score in nationwide_results:
            if job.id not in existing_ids:
                # ì „êµ­ ê²€ìƒ‰ ê²°ê³¼ëŠ” ë‚®ì€ ê°€ì¤‘ì¹˜ ì ìš©
                final_score = float(score) * 0.3
                accumulated_results.append((job, final_score))
                added += 1
                if added >= needed:
                    break
        
        print(f"   â• ì „êµ­ ê²€ìƒ‰ìœ¼ë¡œ {added}ê°œ ì¶”ê°€")
    
    # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ë°˜í™˜
    accumulated_results.sort(key=lambda x: x[1], reverse=True)
    final_results = accumulated_results[:target_count]
    
    print(f"\nğŸ† ìµœì¢… ì¼ê±°ë¦¬ ê²°ê³¼: {len(final_results)}ê°œ")
    print("   ğŸ“‹ ìƒìœ„ ê²°ê³¼:")
    for i, (job, score) in enumerate(final_results[:5], 1):
        distance_info = ""
        if user_coords and job.lat and job.lon:
            from app.utils.location import calculate_distance
            distance = calculate_distance(user_coords[0], user_coords[1], job.lat, job.lon)
            distance_info = f" (ê±°ë¦¬: {distance:.1f}km)"
        print(f"      {i}. {job.title} ({job.region}) - ì ìˆ˜: {score:.3f}{distance_info}")
    
    return final_results


def search_tours_matching_jobs(
    user_vec,
    job_regions: List[str],
    user_coords: Optional[Tuple[float, float]] = None,
    max_distance_km: float = 50.0,
    location_weight: float = 0.3
):
    """
    ì¼ê±°ë¦¬ ì§€ì—­ê³¼ 1:1 ë§¤ì¹­ë˜ëŠ” ê´€ê´‘ì§€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ê° ì¼ê±°ë¦¬ ì§€ì—­ë³„ë¡œ ê´€ê´‘ì§€ 1ê°œì”© ë°˜í™˜í•˜ì—¬ ì´ len(job_regions)ê°œ ë°˜í™˜.
    ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ ë” ì •êµí•œ ë§¤ì¹­ ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Parameters
    ----------
    user_vec : list[float]
        ì‚¬ìš©ì ì„ í˜¸ë„ ë²¡í„°
    job_regions : List[str]
        ì¼ê±°ë¦¬ ì§€ì—­ ë¦¬ìŠ¤íŠ¸ (ìˆœì„œëŒ€ë¡œ ë§¤ì¹­)
    user_coords : Optional[Tuple[float, float]]
        ì‚¬ìš©ì ìœ„ì¹˜ (ìœ„ë„, ê²½ë„)
    max_distance_km : float, default=50.0
        ìµœëŒ€ ê²€ìƒ‰ ê±°ë¦¬ (km)
    location_weight : float, default=0.3
        ìœ„ì¹˜ ì ìˆ˜ ê°€ì¤‘ì¹˜
        
    Returns
    -------
    List[Tuple[TourSpot, float]]
        ì¼ê±°ë¦¬ ìˆœì„œì™€ ë™ì¼í•œ ìˆœì„œì˜ (ê´€ê´‘ì§€, ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    from app.utils.location import is_region_match, get_similar_regions
    
    print(f"ì¼ê±°ë¦¬ ì§€ì—­ ìˆœì„œ ë§¤ì¹­ ì‹œì‘: {len(job_regions)}ê°œ ì§€ì—­")
    print(f"   ğŸ“‹ ì¼ê±°ë¦¬ ì§€ì—­ ìˆœì„œ: {job_regions}")
    
    # 1ë‹¨ê³„: ì „ì²´ ê´€ê´‘ì§€ í’€ì„ ë¯¸ë¦¬ ê°€ì ¸ì˜¤ê¸° (ë” ë§ì€ í›„ë³´ í™•ë³´)
    all_tours = search_tours(user_vec, limit=100)  # ì¶©ë¶„í•œ í›„ë³´ í™•ë³´
    print(f"   ì „ì²´ ê´€ê´‘ì§€ í›„ë³´: {len(all_tours)}ê°œ")
    
    # 2ë‹¨ê³„: ì§€ì—­ë³„ ê´€ê´‘ì§€ ê·¸ë£¹í™” (ë‹¤ì–‘í•œ ë§¤ì¹­ ì „ëµ ì‚¬ìš©)
    region_tour_map = {}
    unmatched_tours = []
    
    for tour, score in all_tours:
        tour_region = getattr(tour, 'region', '')
        if not tour_region:
            unmatched_tours.append((tour, score))
            continue
            
        # ê° ì¼ê±°ë¦¬ ì§€ì—­ê³¼ì˜ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        best_match_region = None
        best_match_score = 0
        
        for job_region in job_regions:
            if not job_region:
                continue
                
            # ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° (ë” ì •êµí•œ ì „ëµ ì¡°í•©)
            match_score = 0
            
            # is_region_match í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë§¤ì¹­ í™•ì¸
            is_match, region_match_score = is_region_match(tour_region, [job_region])
            
            if is_match:
                match_score = region_match_score
            else:
                # ì¶”ê°€ ë§¤ì¹­ ì „ëµ - ë” ì—„ê²©í•œ ê¸°ì¤€ ì ìš©
                # 1) ì‹œ/ë„ ì•½ì–´ ë§¤ì¹­ (ì˜ˆ: "ê²½ê¸°" vs "ê²½ê¸°ë„")
                from app.utils.location import extract_sido
                job_sido = extract_sido(job_region)
                tour_sido = extract_sido(tour_region)
                
                if job_sido and tour_sido and job_sido == tour_sido:
                    match_score = 0.7  # ê°™ì€ ì‹œë„ë©´ ë†’ì€ ì ìˆ˜
                # 2) ì¸ì ‘ ì§€ì—­ ë§¤ì¹­ (ë” ì œí•œì ìœ¼ë¡œ)
                elif job_sido and tour_sido and tour_sido in get_similar_regions(job_sido):
                    match_score = 0.3  # ì¸ì ‘ ì§€ì—­ì€ ë‚®ì€ ì ìˆ˜
            
            if match_score > best_match_score:
                best_match_score = match_score
                best_match_region = job_region
        
        # ê°€ì¥ ì˜ ë§¤ì¹­ë˜ëŠ” ì§€ì—­ì— ê´€ê´‘ì§€ ì¶”ê°€ (ë” ì—„ê²©í•œ ì„ê³„ê°’)
        if best_match_region and best_match_score > 0.5:  # ë†’ì€ ë§¤ì¹­ ì„ê³„ê°’ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
            if best_match_region not in region_tour_map:
                region_tour_map[best_match_region] = []
            # ë§¤ì¹­ ì ìˆ˜ë¥¼ ë°˜ì˜í•œ ë³´ì •ëœ ì ìˆ˜
            boosted_score = float(score) + (float(best_match_score) * 2.0)
            region_tour_map[best_match_region].append((tour, boosted_score, best_match_score))
        else:
            unmatched_tours.append((tour, score))
    
    # ê° ì§€ì—­ë³„ ê´€ê´‘ì§€ë¥¼ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
    for region in region_tour_map:
        region_tour_map[region].sort(key=lambda x: x[1], reverse=True)
    
    print(f"   ì§€ì—­ë³„ ê´€ê´‘ì§€ ë¶„í¬:")
    for region, tours in region_tour_map.items():
        print(f"      {region}: {len(tours)}ê°œ")
    print(f"   ğŸ” ë§¤ì¹­ë˜ì§€ ì•Šì€ ê´€ê´‘ì§€: {len(unmatched_tours)}ê°œ")
    
    # 3ë‹¨ê³„: ì¼ê±°ë¦¬ ìˆœì„œëŒ€ë¡œ ê´€ê´‘ì§€ í• ë‹¹
    results = []
    used_tour_ids = set()
    
    for i, job_region in enumerate(job_regions):
        print(f"\n[{i+1}/{len(job_regions)}] '{job_region}' â†’ ê´€ê´‘ì§€ ë§¤ì¹­")
        
        if not job_region:
            print(f"   âŒ ì§€ì—­ ì •ë³´ ì—†ìŒ")
            results.append(None)
            continue
        
        selected_tour = None
        
        # í•´ë‹¹ ì§€ì—­ì—ì„œ ì•„ì§ ì‚¬ìš©ë˜ì§€ ì•Šì€ ìµœê³  ì ìˆ˜ ê´€ê´‘ì§€ ì°¾ê¸°
        if job_region in region_tour_map:
            for tour, boosted_score, match_score in region_tour_map[job_region]:
                if tour.id not in used_tour_ids:
                    selected_tour = (tour, boosted_score)
                    used_tour_ids.add(tour.id)
                    print(f"   âœ… ì§€ì—­ ë§¤ì¹­: {tour.name} ({tour.region}) - ë§¤ì¹­ë„: {match_score:.2f}, ì ìˆ˜: {boosted_score:.3f}")
                    break
        
        # ì§€ì—­ ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš° ì¸ì ‘ ì§€ì—­ì—ì„œ ì°¾ê¸°
        if not selected_tour:
            print(f"   ğŸ” '{job_region}' ì§ì ‘ ë§¤ì¹­ ì‹¤íŒ¨, ì¸ì ‘ ì§€ì—­ ê²€ìƒ‰...")
            similar_regions = get_similar_regions(job_region)
            
            for similar_region in similar_regions:
                if similar_region in region_tour_map:
                    for tour, boosted_score, match_score in region_tour_map[similar_region]:
                        if tour.id not in used_tour_ids:
                            selected_tour = (tour, boosted_score * 0.7)  # ì¸ì ‘ ì§€ì—­ íŒ¨ë„í‹°
                            used_tour_ids.add(tour.id)
                            print(f"   âœ… ì¸ì ‘ ì§€ì—­ ë§¤ì¹­: {tour.name} ({tour.region}) - ì ìˆ˜: {boosted_score * 0.7:.3f}")
                            break
                if selected_tour:
                    break
        
        # ì—¬ì „íˆ ë§¤ì¹­ë˜ì§€ ì•Šì€ ê²½ìš° ë§¤ì¹­ë˜ì§€ ì•Šì€ ê´€ê´‘ì§€ì—ì„œ ì„ íƒ
        if not selected_tour and unmatched_tours:
            for tour, score in unmatched_tours:
                if tour.id not in used_tour_ids:
                    selected_tour = (tour, score * 0.5)  # ë§¤ì¹­ë˜ì§€ ì•Šì€ ê´€ê´‘ì§€ íŒ¨ë„í‹°
                    used_tour_ids.add(tour.id)
                    print(f"   âœ… ì „êµ­ ëŒ€ì²´: {tour.name} ({getattr(tour, 'region', 'ì •ë³´ì—†ìŒ')}) - ì ìˆ˜: {score * 0.5:.3f}")
                    break
        
        if selected_tour:
            results.append(selected_tour)
        else:
            print(f"   âŒ ë§¤ì¹­ ì‹¤íŒ¨: ì‚¬ìš© ê°€ëŠ¥í•œ ê´€ê´‘ì§€ ì—†ìŒ")
            results.append(None)
    
    # None ê°’ ì œê±°
    final_results = [tour for tour in results if tour is not None]
    
    # ë§¤ì¹­ ì„±ê³µë¥  ê³„ì‚°
    successful_matches = len([r for r in results if r is not None])
    match_rate = (successful_matches / len(job_regions)) * 100 if job_regions else 0
    
    print(f"\nğŸ† ìµœì¢… ìˆœì„œ ë§¤ì¹­ ê²°ê³¼:")
    print(f"   ì„±ê³µë¥ : {match_rate:.1f}% ({successful_matches}/{len(job_regions)})")
    print(f"   ğŸ“‹ ë°˜í™˜ ê´€ê´‘ì§€: {len(final_results)}ê°œ")
    
    # ë§¤ì¹­ ê²°ê³¼ ìƒì„¸ ë¡œê·¸
    for i, (job_region, result) in enumerate(zip(job_regions, results)):
        if result:
            tour, score = result
            print(f"   {i+1}. {job_region} â†’ {tour.name} ({getattr(tour, 'region', 'ì •ë³´ì—†ìŒ')})")
        else:
            print(f"   {i+1}. {job_region} â†’ ë§¤ì¹­ ì‹¤íŒ¨")
    
    return final_results


def search_tours_region_first(
    user_vec, 
    user_regions: List[str],
    user_coords: Optional[Tuple[float, float]] = None,
    target_count: int = 10,
    max_distance_km: float = 100.0,
    location_weight: float = 0.4
):
    """
    ì§€ì—­ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ” ê´€ê´‘ì§€ ê²€ìƒ‰ í•¨ìˆ˜.
    """
    from app.utils.location import get_progressive_region_patterns
    
    print(f"ì§€ì—­ ìš°ì„  ê´€ê´‘ì§€ ê²€ìƒ‰ ì‹œì‘")
    print(f"   ëŒ€ìƒ ì§€ì—­: {user_regions}")
    print(f"   ëª©í‘œ ê°œìˆ˜: {target_count}ê°œ")
    print(f"   ğŸ“ ìµœëŒ€ ê±°ë¦¬: {max_distance_km}km")
    print(f"   ğŸšï¸ ìœ„ì¹˜ ê°€ì¤‘ì¹˜: {location_weight}")
    if user_coords:
        print(f"   ì‚¬ìš©ì ì¢Œí‘œ: {user_coords}")
    
    expansion_patterns = get_progressive_region_patterns(user_regions)
    print(f"   ğŸ”„ í™•ì¥ íŒ¨í„´: {expansion_patterns}")
    
    accumulated_results = []
    existing_ids = set()
    
    for i, (region_pattern, region_weight, description) in enumerate(expansion_patterns, 1):
        print(f"\n[{i}/{len(expansion_patterns)}] '{region_pattern}' ê´€ê´‘ì§€ ({description})")
        print(f"   âš–ï¸ ì§€ì—­ ê°€ì¤‘ì¹˜: {region_weight}")
        
        region_results = search_tours_by_region(
            user_vec, region_pattern, user_coords, 
            max_distance_km, location_weight, target_count * 3
        )
        
        new_results = 0
        for tour, score in region_results:
            if tour.id not in existing_ids:
                final_score = float(score) * region_weight
                accumulated_results.append((tour, final_score))
                existing_ids.add(tour.id)
                new_results += 1
        
        print(f"   âœ… ìƒˆë¡œ ë°œê²¬: {new_results}ê°œ (ì¤‘ë³µ ì œì™¸)")
        print(f"   ğŸ“ˆ ëˆ„ì  ê²°ê³¼: {len(accumulated_results)}ê°œ")
        
        if len(accumulated_results) >= target_count:
            print(f"   ğŸŠ ëª©í‘œ ë‹¬ì„±! ({target_count}ê°œ ì´ìƒ í™•ë³´)")
            break
    
    # ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš° ì „êµ­ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„
    if len(accumulated_results) < target_count:
        needed = target_count - len(accumulated_results)
        print(f"\nğŸŒ ê´€ê´‘ì§€ ì „êµ­ ê²€ìƒ‰ìœ¼ë¡œ {needed}ê°œ ì¶”ê°€...")
        
        nationwide_results = search_tours(user_vec, target_count * 2)
        added = 0
        for tour, score in nationwide_results:
            if tour.id not in existing_ids:
                final_score = float(score) * 0.3
                accumulated_results.append((tour, final_score))
                added += 1
                if added >= needed:
                    break
        
        print(f"   â• ì „êµ­ ê²€ìƒ‰ìœ¼ë¡œ {added}ê°œ ì¶”ê°€")
    
    accumulated_results.sort(key=lambda x: x[1], reverse=True)
    final_results = accumulated_results[:target_count]
    
    print(f"\nğŸ† ìµœì¢… ê´€ê´‘ì§€ ê²°ê³¼: {len(final_results)}ê°œ")
    print("   ğŸ“‹ ìƒìœ„ ê²°ê³¼:")
    for i, (tour, score) in enumerate(final_results[:5], 1):
        distance_info = ""
        if user_coords and tour.lat and tour.lon:
            from app.utils.location import calculate_distance
            distance = calculate_distance(user_coords[0], user_coords[1], tour.lat, tour.lon)
            distance_info = f" (ê±°ë¦¬: {distance:.1f}km)"
        print(f"      {i}. {tour.name} ({tour.region}) - ì ìˆ˜: {score:.3f}{distance_info}")
    
    return final_results


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ ê²°í•© ë¡œì§ ----------------------------------
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def search_tours_hybrid(
    user_vec, 
    extracted_keywords: List[str] = None,
    user_coords: Optional[Tuple[float, float]] = None,
    user_regions: Optional[List[str]] = None,
    target_count: int = 10,
    keyword_weight: float = 0.3,
    vector_weight: float = 0.7
):
    """
    ì‹¤ì‹œê°„ í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê´€ê´‘ì§€ ê²€ìƒ‰.
    
    ì´ì œ ë°ì´í„°ë² ì´ìŠ¤ì˜ detailed_keywords ì»¬ëŸ¼ì„ í™œìš©í•˜ì—¬ 
    ê° ê´€ê´‘ì§€ì— ëŒ€í•´ ìˆ˜ì§‘ëœ ì‹¤ì œ í‚¤ì›Œë“œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­í•©ë‹ˆë‹¤.
    
    Parameters
    ----------
    user_vec : list[float]
        ì‚¬ìš©ì ì„ í˜¸ë„ ë²¡í„°
    extracted_keywords : List[str], optional
        ìŠ¬ë¡¯ ì¶”ì¶œì—ì„œ ì–»ì€ í‚¤ì›Œë“œë“¤ (ì˜ˆ: ["ì‚°", "ë°”ë‹¤", "ì²´í—˜"])
    user_coords : Optional[Tuple[float, float]]
        ì‚¬ìš©ì ìœ„ì¹˜ (ìœ„ë„, ê²½ë„)
    user_regions : Optional[List[str]]
        ì‚¬ìš©ì ì§€ì • ì§€ì—­ ë¦¬ìŠ¤íŠ¸
    target_count : int, default=10
        ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
    keyword_weight : float, default=0.3
        í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê°€ì¤‘ì¹˜
    vector_weight : float, default=0.7
        ë²¡í„° ìœ ì‚¬ë„ ì ìˆ˜ ê°€ì¤‘ì¹˜
        
    Returns
    -------
    List[Tuple[TourSpot, float]]
        (ê´€ê´‘ì§€, í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ” ì‹¤ì‹œê°„ í•˜ì´ë¸Œë¦¬ë“œ ê´€ê´‘ì§€ ê²€ìƒ‰ ì‹œì‘")
    print(f"   ëª©í‘œ: {target_count}ê°œ")
    print(f"   í‚¤ì›Œë“œ: {extracted_keywords}")
    print(f"   âš–ï¸ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜: {keyword_weight}, ë²¡í„° ê°€ì¤‘ì¹˜: {vector_weight}")
    
    # 1ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ (ì§€ì—­ ìš°ì„  ë˜ëŠ” ì¼ë°˜)
    if user_regions:
        vector_results = search_tours_region_first(
            user_vec, user_regions, user_coords, target_count * 3
        )
    else:
        vector_results = search_tours_guaranteed(
            user_vec, user_coords, user_regions, target_count * 3
        )
    
    print(f"   ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {len(vector_results)}ê°œ")
    
    # 1.5ë‹¨ê³„: í‚¤ì›Œë“œë³„ íŠ¹ë³„ ì²˜ë¦¬ - ì£¼ìš” í‚¤ì›Œë“œì— ë§ëŠ” ê´€ê´‘ì§€ ê°•ì œ ì¶”ê°€
    if extracted_keywords and user_regions:
        print(f"   í‚¤ì›Œë“œë³„ íŠ¹ë³„ ì²˜ë¦¬ ì‹œì‘: {extracted_keywords}")
        
        # í™•ì¥ëœ í‚¤ì›Œë“œë³„ ë§¤ì¹­ ê´€ê´‘ì§€ ì¡°ê±´ ì •ì˜
        keyword_conditions = {
            "ë°”ë‹¤": {
                "name_contains": ["í•´ìˆ˜ìš•ì¥", "í•´ë³€", "ë°”ë‹¤", "ë“±ëŒ€", "í¬êµ¬", "ê°¯ë²Œ", "í•´ì•ˆ", "í•´ë³€", "ì–´ì´Œ", "í•­êµ¬"],
                "busan_special": [
                    126078, 126079, 126122, 126080, 126098, 1939570, 126081,  # í•´ìˆ˜ìš•ì¥
                    127925, 3014437, 2785289,  # í•´ë³€
                    2715601, 129156, 3015365, 2726843, 2789460,  # ê°€ë•ë„
                    129157, 129155, 2775577, 3017467, 2744560,  # ë“±ëŒ€
                    2715652, 2606204,  # í¬êµ¬
                    137706, 127004, 2822343, 126674, 987810,  # í•´ìš´ëŒ€
                    769761, 3027228, 2784328  # ë‹¤ëŒ€í¬
                ],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "ì‚°": {
                "name_contains": ["ì‚°", "ë´‰", "ë ¹", "ì•”", "ê³ ê°œ", "ëŠ¥ì„ ", "ì •ìƒ", "ë“±ì‚°ë¡œ", "ë‘˜ë ˆê¸¸", "íŠ¸ë ˆí‚¹"],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "ì²´í—˜": {
                "name_contains": ["ì²´í—˜", "ë†ì¥", "ëª©ì¥", "ê³µë°©", "ë°•ë¬¼ê´€", "ì „ì‹œê´€", "í•™ìŠµ", "êµìœ¡", "ë§Œë“¤ê¸°", "DIY"],
                "tags_contains": ["ë¬¸í™”", "ì²´í—˜", "ê´€ê´‘"]
            },
            "ì¶•ì œ": {
                "name_contains": ["ì¶•ì œ", "í˜ìŠ¤í‹°ë²Œ", "í–‰ì‚¬", "ë§ˆì„", "ê´‘ì¥", "ë¬¸í™”ì›", "ì´ë²¤íŠ¸", "ê³µì—°", "í–‰ì‚¬ì¥"],
                "tags_contains": ["ë¬¸í™”", "ì¶•ì œ", "ê´€ê´‘"]
            },
            "ê³µì›": {
                "name_contains": ["ê³µì›", "ìˆ˜ëª©ì›", "ì‹ë¬¼ì›", "ë™ë¬¼ì›", "í…Œë§ˆíŒŒí¬", "ë†€ì´", "ì–´ë¦°ì´", "ìƒíƒœ"],
                "tags_contains": ["ìì—°", "ë¬¸í™”", "ê´€ê´‘"]
            },
            "ì˜¨ì²œ": {
                "name_contains": ["ì˜¨ì²œ", "ìŠ¤íŒŒ", "íë§", "íœ´ì–‘ë¦¼", "ì°œì§ˆë°©", "ì‚¬ìš°ë‚˜", "ì¹˜ìœ "],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "ë¬¸í™”": {
                "name_contains": ["ë¬¸í™”", "ë°•ë¬¼ê´€", "ë¯¸ìˆ ê´€", "ê°¤ëŸ¬ë¦¬", "ì „ì‹œ", "ì˜ˆìˆ ", "ì—­ì‚¬", "ìœ ì ", "ë¬¸í™”ì¬"],
                "tags_contains": ["ë¬¸í™”", "ê´€ê´‘"]
            },
            "ì‚¬ì°°": {
                "name_contains": ["ì‚¬", "ì ˆ", "ì•”", "ëŒ€ì›…ì „", "ë¶ˆêµ", "í…œí”ŒìŠ¤í…Œì´"],
                "tags_contains": ["ë¬¸í™”", "ê´€ê´‘"]
            },
            "íœ´ì–‘": {
                "name_contains": ["íœ´ì–‘", "íë§", "íœì…˜", "ë¦¬ì¡°íŠ¸", "í˜¸í…”", "ê¸€ë¨í•‘", "ìº í•‘"],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "ë§›ì§‘": {
                "name_contains": ["ë§›ì§‘", "ìŒì‹ì ", "ì¹´í˜", "ì‹ë‹¹", "ì „í†µìŒì‹", "íŠ¹ì‚°ë¬¼", "ì‹œì¥"],
                "tags_contains": ["ë¬¸í™”", "ê´€ê´‘"]
            },
            "ê°•": {
                "name_contains": ["ê°•", "í•˜ì²œ", "ë¬¼ê¸¸", "ë˜í”„íŒ…", "ì¹´ëˆ„", "ìˆ˜ìƒ"],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "í˜¸ìˆ˜": {
                "name_contains": ["í˜¸ìˆ˜", "ì €ìˆ˜ì§€", "ëŒ", "ë¬¼", "ìˆ˜ë³€"],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "ê³„ê³¡": {
                "name_contains": ["ê³„ê³¡", "í­í¬", "ë¬¼ë†€ì´", "ì—¬ë¦„", "ì‹œì›"],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "ì„¬": {
                "name_contains": ["ì„¬", "ë„", "í•´ìƒ", "ë°°", "ì—¬ê°ì„ "],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "ë²šê½ƒ": {
                "name_contains": ["ë²šê½ƒ", "ê½ƒ", "ë´„", "ë²šë‚˜ë¬´", "ê½ƒê¸¸"],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            },
            "ë‹¨í’": {
                "name_contains": ["ë‹¨í’", "ê°€ì„", "ë‹¨í’ë‚˜ë¬´", "ë‹¨í’ê¸¸", "ë‹¨í’ì¶•ì œ"],
                "tags_contains": ["ìì—°", "ê´€ê´‘"]
            }
        }
        
        # ê° í‚¤ì›Œë“œì— ëŒ€í•´ ì²˜ë¦¬
        for keyword in extracted_keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in keyword_conditions:
                condition = keyword_conditions[keyword_lower]
                print(f"      ğŸ” '{keyword}' í‚¤ì›Œë“œ íŠ¹ë³„ ì²˜ë¦¬")
                
                # í˜„ì¬ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œ ê´€ë ¨ ê´€ê´‘ì§€ ìˆ˜ í™•ì¸
                current_count = 0
                for tour, _ in vector_results:
                    tour_name = tour.name.lower() if tour.name else ""
                    if any(term in tour_name for term in condition["name_contains"]):
                        current_count += 1
                
                print(f"         í˜„ì¬ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ëœ {keyword} ê´€ë ¨ ê´€ê´‘ì§€: {current_count}ê°œ")
                
                # ê´€ë ¨ ê´€ê´‘ì§€ê°€ 3ê°œ ë¯¸ë§Œì´ë©´ ì§ì ‘ ì¶”ê°€
                if current_count < 3:
                    from app.db.models import TourSpot
                    from app.db.database import SessionLocal
                    
                    with SessionLocal() as db:
                        # ì´ë¦„ ê¸°ë°˜ ê²€ìƒ‰
                        name_conditions = [TourSpot.name.like(f"%{term}%") for term in condition["name_contains"]]
                        region_conditions = [TourSpot.region.like(f"%{region}%") for region in user_regions]
                        
                        # ì²« ë²ˆì§¸ ì§€ì—­ì—ì„œ ê²€ìƒ‰
                        main_region = user_regions[0].split()[0] if user_regions else ""
                        
                        from sqlalchemy import or_
                        missing_tours = db.query(TourSpot).filter(
                            or_(*name_conditions),
                            TourSpot.region.like(f"%{main_region}%")
                        ).limit(5 - current_count).all()
                        
                        if not missing_tours and keyword_lower == "ë°”ë‹¤" and "ë¶€ì‚°" in str(user_regions):
                            # ë¶€ì‚° ë°”ë‹¤ì˜ ê²½ìš° íŠ¹ë³„ contentid ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
                            busan_sea_contentids_str = {str(cid) for cid in condition["busan_special"]}
                            missing_tours = db.query(TourSpot).filter(
                                TourSpot.contentid.in_(busan_sea_contentids_str),
                                TourSpot.region.like("%ë¶€ì‚°%")
                            ).limit(5 - current_count).all()
                        
                        for tour in missing_tours:
                            vector_results.append((tour, 2.0))
                            print(f"         â• {keyword} ê´€ë ¨ ê´€ê´‘ì§€ ì¶”ê°€: {tour.name} (contentid: {tour.contentid})")
                
        print(f"   í‚¤ì›Œë“œ íŠ¹ë³„ ì²˜ë¦¬ í›„ ê²€ìƒ‰ ê²°ê³¼: {len(vector_results)}ê°œ")
    
    # 2ë‹¨ê³„: ì‹¤ì‹œê°„ í‚¤ì›Œë“œ ê²€ìƒ‰ + ì§€ì—­ë³„ í‚¤ì›Œë“œ ë§¤í•‘ìœ¼ë¡œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    keyword_matched_contentids = set()
    contentid_to_keywords = {}  # contentidë³„ ë§¤ì¹­ëœ í‚¤ì›Œë“œë“¤ ì €ì¥
    
    if extracted_keywords:
        print(f"   ğŸ” ì‹¤ì‹œê°„ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œì‘...")
        keyword_service = get_keyword_service()
        
        # ì§€ì—­ë³„ í‚¤ì›Œë“œ í™•ì¥ ë§¤í•‘
        expanded_keywords = set(extracted_keywords)
        if user_regions:
            for region in user_regions:
                if "ë¶€ì‚°" in region:
                    # ë¶€ì‚° + ë°”ë‹¤ í‚¤ì›Œë“œ ì¡°í•©ìœ¼ë¡œ í™•ì¥
                    if any(kw in ["ë°”ë‹¤", "í•´ë³€", "í•´ìˆ˜ìš•ì¥", "ë°”ë‹·ê°€"] for kw in extracted_keywords):
                        expanded_keywords.update(["í•´ìš´ëŒ€", "ê´‘ì•ˆë¦¬", "ì†¡ì •", "ë‹¤ëŒ€í¬", "ê°€ë•ë„", "í•´ìˆ˜ìš•ì¥", "í•´ë³€"])
                        print(f"      ğŸŒŠ ë¶€ì‚° ë°”ë‹¤ í‚¤ì›Œë“œ í™•ì¥: {list(expanded_keywords - set(extracted_keywords))}")
        
        # ê° í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰í•˜ì—¬ contentid ìˆ˜ì§‘
        for keyword in expanded_keywords:
            try:
                search_results = keyword_service.search_by_keyword(keyword, max_results=100)
                for result in search_results:
                    keyword_matched_contentids.add(result.contentid)
                    # contentidë³„ ë§¤ì¹­ëœ í‚¤ì›Œë“œ ì €ì¥
                    if result.contentid not in contentid_to_keywords:
                        contentid_to_keywords[result.contentid] = []
                    contentid_to_keywords[result.contentid].append(keyword)
                print(f"      '{keyword}': {len(search_results)}ê°œ ê²°ê³¼")
            except Exception as e:
                print(f"      âš ï¸ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        print(f"   í‚¤ì›Œë“œ ë§¤ì¹­ contentid: {len(keyword_matched_contentids)}ê°œ")
    
    # 3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
    hybrid_results = []
    
    for tour, vector_score in vector_results:
        keyword_score = 0.0
        matched_keywords = []
        
        # ë°©ë²• 1: contentidê°€ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë¶€ìŠ¤íŒ…
        tour_contentid_str = str(tour.contentid) if tour.contentid else None
        if extracted_keywords and tour_contentid_str and tour_contentid_str in keyword_matched_contentids:
            keyword_score = 1.0  # í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œ ìµœëŒ€ ì ìˆ˜
            matched_keywords = contentid_to_keywords.get(tour_contentid_str, [])
            # ì¤‘ë³µ ì œê±°
            matched_keywords = list(set(matched_keywords))
            print(f"   âœ… {tour.name} (contentid: {tour.contentid}): API í‚¤ì›Œë“œ ë§¤ì¹­ {matched_keywords}")
        
        # ë°©ë²• 2: NEW - DB ìƒì„¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­ (ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ í™œìš©)
        if keyword_score == 0.0 and extracted_keywords and hasattr(tour, 'detailed_keywords') and tour.detailed_keywords:
            try:
                # JSON í˜•íƒœë¡œ ì €ì¥ëœ ìƒì„¸ í‚¤ì›Œë“œë“¤ íŒŒì‹±
                detailed_keywords = json.loads(tour.detailed_keywords)
                detailed_keywords_lower = [kw.lower() for kw in detailed_keywords]
                
                # í–¥ìƒëœ í‚¤ì›Œë“œ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
                best_keyword_score = 0.0
                best_matched_keyword = None
                
                for keyword in extracted_keywords:
                    keyword_lower = keyword.lower()
                    current_score = 0.0
                    
                    # 1) ì •í™• ë§¤ì¹­ (ìµœê³  ì ìˆ˜)
                    if keyword_lower in detailed_keywords_lower:
                        current_score = 1.0
                        print(f"   âœ… {tour.name}: DB í‚¤ì›Œë“œ ì •í™• ë§¤ì¹­ [{keyword}]")
                    
                    # 2) ë¶€ë¶„ ë§¤ì¹­ - ìƒì„¸ í‚¤ì›Œë“œì— ì‚¬ìš©ì í‚¤ì›Œë“œ í¬í•¨
                    elif any(keyword_lower in detailed_kw for detailed_kw in detailed_keywords_lower):
                        current_score = 0.9
                        matching_kw = next(kw for kw in detailed_keywords_lower if keyword_lower in kw)
                        print(f"   âœ… {tour.name}: DB í‚¤ì›Œë“œ ë¶€ë¶„ ë§¤ì¹­ [{matching_kw}â†’{keyword}]")
                    
                    # 3) ì—­ë°©í–¥ ë¶€ë¶„ ë§¤ì¹­ - ì‚¬ìš©ì í‚¤ì›Œë“œì— ìƒì„¸ í‚¤ì›Œë“œ í¬í•¨
                    elif any(detailed_kw in keyword_lower for detailed_kw in detailed_keywords_lower):
                        current_score = 0.8
                        matching_kw = next(kw for kw in detailed_keywords_lower if kw in keyword_lower)
                        print(f"   âœ… {tour.name}: DB í‚¤ì›Œë“œ ì—­ë°©í–¥ ë§¤ì¹­ [{keyword}â†{matching_kw}]")
                    
                    # 4) ì˜ë¯¸ì  ìœ ì‚¬ì„± ë§¤ì¹­ (ê´€ë ¨ í‚¤ì›Œë“œ)
                    else:
                        # í‚¤ì›Œë“œ ê´€ë ¨ì„± ë§¤í•‘
                        semantic_mapping = {
                            "ë°”ë‹¤": ["í•´ë³€", "í•´ìˆ˜ìš•ì¥", "ë°”ë‹·ê°€", "ê°¯ë²Œ", "ë“±ëŒ€", "í•´ì•ˆ", "í•­êµ¬", "í¬êµ¬", "ì–´ì´Œ"],
                            "ì‚°": ["ë´‰", "ë ¹", "ì •ìƒ", "ë“±ì‚°", "íŠ¸ë ˆí‚¹", "ëŠ¥ì„ ", "ê³ ê°œ", "ì‚°ì•…", "ë“±ë°˜"],
                            "ì²´í—˜": ["ë†ì¥", "ëª©ì¥", "ê³µë°©", "í•™ìŠµ", "êµìœ¡", "ë§Œë“¤ê¸°", "DIY", "ì›Œí¬ìƒµ"],
                            "ë¬¸í™”": ["ë°•ë¬¼ê´€", "ë¯¸ìˆ ê´€", "ì „ì‹œ", "ì˜ˆìˆ ", "ì—­ì‚¬", "ìœ ì ", "ë¬¸í™”ì¬", "ê°¤ëŸ¬ë¦¬"],
                            "ì¶•ì œ": ["í˜ìŠ¤í‹°ë²Œ", "í–‰ì‚¬", "ì´ë²¤íŠ¸", "ê³µì—°", "ë§ˆì„", "ì¶•ì œ"],
                            "íœ´ì–‘": ["íë§", "ìŠ¤íŒŒ", "ì˜¨ì²œ", "íœì…˜", "ë¦¬ì¡°íŠ¸", "ê¸€ë¨í•‘"],
                            "ìì—°": ["ê³µì›", "ìˆ˜ëª©ì›", "ì‹ë¬¼ì›", "ìƒíƒœ", "í™˜ê²½", "ìì—°ë³´í˜¸"],
                            "ë¬¼": ["ê°•", "í˜¸ìˆ˜", "ê³„ê³¡", "í­í¬", "ë˜í”„íŒ…", "ì¹´ëˆ„", "ìˆ˜ìƒí™œë™"]
                        }
                        
                        for main_keyword, related_keywords in semantic_mapping.items():
                            if keyword_lower == main_keyword:
                                for detailed_kw in detailed_keywords_lower:
                                    if any(related in detailed_kw for related in related_keywords):
                                        current_score = max(current_score, 0.7)
                                        print(f"   âœ… {tour.name}: DB í‚¤ì›Œë“œ ì˜ë¯¸ì  ë§¤ì¹­ [{detailed_kw}â‰ˆ{keyword}]")
                                        break
                    
                    # ìµœê³  ì ìˆ˜ í‚¤ì›Œë“œ ì„ íƒ
                    if current_score > best_keyword_score:
                        best_keyword_score = current_score
                        best_matched_keyword = keyword
                
                if best_keyword_score > 0:
                    keyword_score = best_keyword_score
                    matched_keywords.append(best_matched_keyword)
                        
            except (json.JSONDecodeError, TypeError) as e:
                print(f"   âš ï¸ {tour.name} (contentid: {tour.contentid}): ìƒì„¸ í‚¤ì›Œë“œ íŒŒì‹± ì‹¤íŒ¨ - {e}")
        
        # ë°©ë²• 3: í´ë°± - ê¸°ë³¸ ì´ë¦„/ì§€ì—­ ë§¤ì¹­ (ìƒì„¸ í‚¤ì›Œë“œê°€ ì—†ê±°ë‚˜ ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš°)
        if keyword_score == 0.0 and extracted_keywords:
            tour_name = tour.name.lower() if tour.name else ""
            tour_region = tour.region.lower() if hasattr(tour, 'region') and tour.region else ""
            
            for keyword in extracted_keywords:
                keyword_lower = keyword.lower()
                
                # ì§ì ‘ í‚¤ì›Œë“œ ë§¤ì¹­ (ê°€ì¥ ê¸°ë³¸ì )
                if keyword_lower in tour_name or keyword_lower in tour_region:
                    keyword_score = 0.5  # í´ë°± ë°©ë²•ì´ë¯€ë¡œ ë‚®ì€ ì ìˆ˜
                    matched_keywords.append(keyword)
                    print(f"   âœ… {tour.name} (contentid: {tour.contentid}): í´ë°± ì§ì ‘ ë§¤ì¹­ [{keyword}]")
                    break
                
                # ì§€ì—­ ë§¤ì¹­ (ë¶€ì‚°, ì„œìš¸ ë“±)
                elif any(region_name in keyword_lower for region_name in ["ë¶€ì‚°", "ì„œìš¸", "ê²½ê¸°", "ê°•ì›", "ì¶©ì²­", "ì „ë¼", "ê²½ìƒ", "ì œì£¼"]):
                    if keyword_lower in tour_region:
                        keyword_score = 0.4  # ì§€ì—­ ë§¤ì¹­ë„ í´ë°±ì´ë¯€ë¡œ ë‚®ì€ ì ìˆ˜
                        matched_keywords.append(keyword)
                        print(f"   âœ… {tour.name} (contentid: {tour.contentid}): í´ë°± ì§€ì—­ ë§¤ì¹­ [{keyword}]")
                        break
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
        hybrid_score = (vector_weight * float(vector_score)) + (keyword_weight * float(keyword_score))
        hybrid_results.append((tour, hybrid_score, vector_score, keyword_score, matched_keywords))
    
    # 4ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¡œ ì •ë ¬ ë° í‚¤ì›Œë“œë³„ ë¶€ìŠ¤íŒ…
    # ì¶”ì¶œëœ í‚¤ì›Œë“œì™€ ë§¤ì¹­ëœ ê´€ê´‘ì§€ë“¤ì„ ìš°ì„ ìˆœìœ„ë¡œ ì˜¬ë¦¬ê¸°
    priority_keywords = [kw.lower() for kw in extracted_keywords if kw]
    if priority_keywords:
        print(f"   í‚¤ì›Œë“œ ë§¤ì¹­ ë¶€ìŠ¤íŒ… ì‹œì‘: {priority_keywords}")
        
        # í™•ì¥ëœ í‚¤ì›Œë“œë³„ ë¶€ìŠ¤íŒ… ì •ë³´
        keyword_boost_info = {
            "ë°”ë‹¤": {"boost": 3.0, "emoji": "ğŸ–ï¸", "related": ["í•´ìˆ˜ìš•ì¥", "í•´ë³€", "ê°€ë•ë„", "í•´ìš´ëŒ€", "ê´‘ì•ˆë¦¬", "ë“±ëŒ€", "í¬êµ¬", "ê°¯ë²Œ", "í•´ì•ˆ", "ì–´ì´Œ", "í•­êµ¬"]},
            "ì‚°": {"boost": 2.5, "emoji": "ğŸ”ï¸", "related": ["ë´‰", "ë ¹", "ì•”", "ê³ ê°œ", "ë“±ì‚°", "íŠ¸ë ˆí‚¹", "ëŠ¥ì„ ", "ì •ìƒ", "ë“±ì‚°ë¡œ", "ë‘˜ë ˆê¸¸"]},
            "ì²´í—˜": {"boost": 2.0, "emoji": "ğŸª", "related": ["ë†ì¥", "ëª©ì¥", "ê³µë°©", "ë°•ë¬¼ê´€", "ì „ì‹œê´€", "í•™ìŠµ", "êµìœ¡", "ë§Œë“¤ê¸°", "DIY"]},
            "ì¶•ì œ": {"boost": 2.0, "emoji": "ğŸ­", "related": ["í˜ìŠ¤í‹°ë²Œ", "í–‰ì‚¬", "ë§ˆì„", "ê´‘ì¥", "ë¬¸í™”ì›", "ì´ë²¤íŠ¸", "ê³µì—°", "í–‰ì‚¬ì¥"]},
            "ê³µì›": {"boost": 1.5, "emoji": "ğŸŒ³", "related": ["ìˆ˜ëª©ì›", "ì‹ë¬¼ì›", "ë™ë¬¼ì›", "í…Œë§ˆíŒŒí¬", "ë†€ì´ê³µì›", "ë†€ì´", "ì–´ë¦°ì´", "ìƒíƒœ"]},
            "ì˜¨ì²œ": {"boost": 2.0, "emoji": "â™¨ï¸", "related": ["ìŠ¤íŒŒ", "íë§", "íœ´ì–‘ë¦¼", "ì¹˜ìœ ", "ì°œì§ˆë°©", "ì‚¬ìš°ë‚˜"]},
            "ë¬¸í™”": {"boost": 1.8, "emoji": "ğŸ›ï¸", "related": ["ë°•ë¬¼ê´€", "ë¯¸ìˆ ê´€", "ê°¤ëŸ¬ë¦¬", "ì „ì‹œ", "ì˜ˆìˆ ", "ì—­ì‚¬", "ìœ ì ", "ë¬¸í™”ì¬"]},
            "ì‚¬ì°°": {"boost": 1.5, "emoji": "ğŸ¯", "related": ["ì‚¬", "ì ˆ", "ì•”", "ëŒ€ì›…ì „", "ë¶ˆêµ", "í…œí”ŒìŠ¤í…Œì´"]},
            "íœ´ì–‘": {"boost": 1.7, "emoji": "ğŸ–ï¸", "related": ["íë§", "íœì…˜", "ë¦¬ì¡°íŠ¸", "í˜¸í…”", "ê¸€ë¨í•‘", "ìº í•‘"]},
            "ë§›ì§‘": {"boost": 1.3, "emoji": "ğŸ´", "related": ["ìŒì‹ì ", "ì¹´í˜", "ì‹ë‹¹", "ì „í†µìŒì‹", "íŠ¹ì‚°ë¬¼", "ì‹œì¥"]},
            "ê°•": {"boost": 2.0, "emoji": "", "related": ["í•˜ì²œ", "ë¬¼ê¸¸", "ë˜í”„íŒ…", "ì¹´ëˆ„", "ìˆ˜ìƒ"]},
            "í˜¸ìˆ˜": {"boost": 1.8, "emoji": "", "related": ["ì €ìˆ˜ì§€", "ëŒ", "ë¬¼", "ìˆ˜ë³€"]},
            "ê³„ê³¡": {"boost": 2.2, "emoji": "ğŸ”ï¸", "related": ["í­í¬", "ë¬¼ë†€ì´", "ì—¬ë¦„", "ì‹œì›"]},
            "ì„¬": {"boost": 2.3, "emoji": "ğŸï¸", "related": ["ë„", "í•´ìƒ", "ë°°", "ì—¬ê°ì„ "]},
            "ë²šê½ƒ": {"boost": 2.5, "emoji": "ğŸŒ¸", "related": ["ê½ƒ", "ë´„", "ë²šë‚˜ë¬´", "ê½ƒê¸¸"]},
            "ë‹¨í’": {"boost": 2.5, "emoji": "ğŸ", "related": ["ê°€ì„", "ë‹¨í’ë‚˜ë¬´", "ë‹¨í’ê¸¸", "ë‹¨í’ì¶•ì œ"]}
        }
        
        # ì›ë³¸ í‚¤ì›Œë“œë¥¼ ì¶”ì • (ì²« 3ê°œ í‚¤ì›Œë“œë¥¼ ì›ë³¸ìœ¼ë¡œ ê°€ì • - ìŠ¬ë¡¯ì—ì„œ ë‚˜ì˜¨ ê²ƒë“¤)
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²•ì´ í•„ìš”í•˜ì§€ë§Œ, í˜„ì¬ëŠ” ì´ ë°©ë²• ì‚¬ìš©
        estimated_original_keywords = priority_keywords[:3] if len(priority_keywords) >= 3 else priority_keywords
        
        for i, (tour, hybrid_score, vector_score, keyword_score, matched_keywords) in enumerate(hybrid_results):
            applied_boost = 0.0
            boost_reasons = []
            
            for matched_kw in matched_keywords:
                matched_kw_lower = matched_kw.lower()
                
                # ì§ì ‘ í‚¤ì›Œë“œ ë§¤ì¹­
                if matched_kw_lower in priority_keywords:
                    if matched_kw_lower in keyword_boost_info:
                        boost_info = keyword_boost_info[matched_kw_lower]
                        current_boost = boost_info["boost"]
                        
                        # ì›ë³¸ í‚¤ì›Œë“œê°€ ì•„ë‹Œ ê²½ìš° ë¶€ìŠ¤íŠ¸ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì„
                        if matched_kw_lower not in estimated_original_keywords:
                            current_boost *= 0.5
                            boost_reasons.append(f"{boost_info['emoji']}{matched_kw}(ì‚¬ìš©ì)")
                        else:
                            boost_reasons.append(f"{boost_info['emoji']}{matched_kw}")
                            
                        applied_boost = max(applied_boost, current_boost)  # ìµœëŒ€ ë¶€ìŠ¤íŠ¸ ì ìš©
                
                # ê´€ë ¨ í‚¤ì›Œë“œ ë§¤ì¹­ (ë” ì‘ì€ ë¶€ìŠ¤íŠ¸)
                for priority_kw in priority_keywords:
                    if priority_kw in keyword_boost_info:
                        boost_info = keyword_boost_info[priority_kw]
                        if any(related in matched_kw_lower for related in boost_info["related"]):
                            current_boost = boost_info["boost"] * 0.8  # ê´€ë ¨ í‚¤ì›Œë“œëŠ” 80% ë¶€ìŠ¤íŠ¸
                            
                            # ì›ë³¸ í‚¤ì›Œë“œê°€ ì•„ë‹Œ ê²½ìš° ì¶”ê°€ë¡œ ì ˆë°˜ìœ¼ë¡œ ì¤„ì„
                            if priority_kw not in estimated_original_keywords:
                                current_boost *= 0.5
                                boost_reasons.append(f"{boost_info['emoji']}{matched_kw}({priority_kw},ì‚¬ìš©ì)")
                            else:
                                boost_reasons.append(f"{boost_info['emoji']}{matched_kw}({priority_kw})")
                                
                            applied_boost = max(applied_boost, current_boost)
            
            if applied_boost > 0:
                boost_score = hybrid_score + applied_boost
                hybrid_results[i] = (tour, boost_score, vector_score, keyword_score, matched_keywords)
                print(f"      {' '.join(boost_reasons)} {tour.name}: í‚¤ì›Œë“œ ë¶€ìŠ¤íŠ¸ ì ìš© {hybrid_score:.3f} â†’ {boost_score:.3f}")
    
    hybrid_results.sort(key=lambda x: x[1], reverse=True)
    final_results = [(tour, hybrid_score, matched_keywords) for tour, hybrid_score, _, _, matched_keywords in hybrid_results[:target_count]]
    
    print(f"   ğŸ† í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ")
    print("   ğŸ“‹ ìƒìœ„ ê²°ê³¼:")
    for i, (tour, hybrid_score, vector_score, keyword_score, matched_keywords) in enumerate(hybrid_results[:5], 1):
        boost_indicator = "" if keyword_score > 0 else ""
        keyword_info = f" [í‚¤ì›Œë“œ: {matched_keywords}]" if matched_keywords else ""
        print(f"      {i}. {tour.name} {boost_indicator}- ì¢…í•©: {hybrid_score:.3f} (ë²¡í„°: {vector_score:.3f}, í‚¤ì›Œë“œ: {keyword_score:.3f}){keyword_info}")
    
    return final_results


def search_jobs_hybrid(
    user_vec, 
    extracted_keywords: List[str] = None,
    user_coords: Optional[Tuple[float, float]] = None,
    user_regions: Optional[List[str]] = None,
    target_count: int = 10,
    keyword_weight: float = 0.1,
    vector_weight: float = 0.9
):
    """
    ì¼ê±°ë¦¬ ê²€ìƒ‰ì€ ì£¼ë¡œ ë²¡í„° ìœ ì‚¬ë„ì— ì˜ì¡´í•˜ë¯€ë¡œ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ë¥¼ ë§¤ìš° ë‚®ê²Œ ì„¤ì •.
    í‚¤ì›Œë“œëŠ” ë‹¨ìˆœíˆ íƒœê·¸ ê¸°ë°˜ ë§¤ì¹­ë§Œ ìˆ˜í–‰.
    """
    print(f"ğŸ” ì¼ê±°ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘")
    print(f"   ëª©í‘œ: {target_count}ê°œ")
    print(f"   í‚¤ì›Œë“œ: {extracted_keywords}")
    print(f"   âš–ï¸ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜: {keyword_weight}, ë²¡í„° ê°€ì¤‘ì¹˜: {vector_weight}")
    
    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ (ì§€ì—­ ìš°ì„  ë˜ëŠ” ì¼ë°˜)
    if user_regions:
        vector_results = search_jobs_region_first(
            user_vec, user_regions, user_coords, target_count * 2
        )
    else:
        vector_results = search_jobs_guaranteed(
            user_vec, user_coords, user_regions, target_count * 2
        )
    
    print(f"   ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {len(vector_results)}ê°œ")
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ì€ ì¼ê±°ë¦¬ íƒœê·¸ì™€ ë‹¨ìˆœ ë¹„êµ (contentid ê¸°ë°˜ ê²€ìƒ‰ ì—†ìŒ)
    hybrid_results = []
    
    for job, vector_score in vector_results:
        keyword_score = 0.0
        
        if extracted_keywords and hasattr(job, 'tags') and job.tags:
            job_tags = job.tags.lower().split(',')
            job_tags = [tag.strip() for tag in job_tags]
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            matched_count = 0
            for keyword in extracted_keywords:
                for tag in job_tags:
                    if keyword.lower() in tag or tag in keyword.lower():
                        matched_count += 1
                        break
            
            if matched_count > 0:
                keyword_score = matched_count / len(extracted_keywords)
                print(f"   âœ… {job.title}: í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ {keyword_score:.2f}")
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (ë²¡í„° ìœ ì‚¬ë„ ì¤‘ì‹¬)
        hybrid_score = (vector_weight * float(vector_score)) + (keyword_weight * float(keyword_score))
        hybrid_results.append((job, hybrid_score))
    
    # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¡œ ì •ë ¬
    hybrid_results.sort(key=lambda x: x[1], reverse=True)
    final_results = hybrid_results[:target_count]
    
    print(f"   ğŸ† ì¼ê±°ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ")
    
    return final_results