"""
ìµœì í™”ëœ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ
ì‚¬ì „ ìƒì„±ëœ ë²¡í„° ìºì‹œë¥¼ í™œìš©í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
"""

import json
import csv
import random
from pathlib import Path
from typing import List, Dict, Any, Optional
from app.utils.jeonbuk_region_mapping import extract_region_from_natural_text
from app.services.detail_loader import fetch_detail_image
from app.embeddings.openai_service import OpenAIService
from app.services.vector_cache_service import get_vector_cache_service
from app.utils.attraction_scoring import (
    score_and_rank_attractions,
    get_top_attractions_for_cards,
    get_attractions_for_schedule
)

class OptimizedVectorRecommendationService:
    """ìµœì í™”ëœ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.openai_service = OpenAIService()
        self.vector_cache = get_vector_cache_service()
        
        # ì„œë¹„ìŠ¤ ì‹œìž‘ì‹œ ë²¡í„° ìºì‹œ ë¡œë“œ
        self.vector_cache.load_vectors()
        
    def _load_farms_data(self) -> List[Dict[str, Any]]:
        """dummy_jobs.jsonì—ì„œ ë†ê°€ ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)"""
        try:
            json_path = self.project_root / "data" / "dummy_jobs.json"
            with open(json_path, 'r', encoding='utf-8') as f:
                farms = json.load(f)
            return farms
        except Exception as e:
            print(f"ë†ê°€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def _filter_farms_by_region(self, farms: List[Dict], region: str) -> List[Dict]:
        """ì§€ì—­ë³„ ë†ê°€ í•„í„°ë§ (ê¸°ì¡´ê³¼ ë™ì¼)"""
        return [farm for farm in farms if farm.get("region") == region]
    
    def _match_farms_by_job_keywords(self, farms: List[Dict], job_keywords: List[str]) -> List[Dict]:
        """ë†ê°€ í‚¤ì›Œë“œ ë§¤ì¹­ (ê¸°ì¡´ê³¼ ë™ì¼, ë†ê°€ëŠ” ë²¡í„° ì‚¬ìš© ì•ˆí•¨)"""
        if not job_keywords:
            return random.sample(farms, min(3, len(farms)))
        
        matched_farms = []
        for farm in farms:
            farm_title = farm.get("title", "").lower()
            farm_tag = farm.get("tag", "").lower()
            farm_text = f"{farm_title} {farm_tag}"
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in job_keywords:
                if keyword.lower() in farm_text:
                    matched_farms.append(farm)
                    break
        
        if not matched_farms:
            return random.sample(farms, min(3, len(farms)))
        
        return matched_farms[:10]
    
    def _get_optimized_vector_attractions(self, region: str, user_travel_styles: List[str], 
                                        user_landscapes: Optional[List[str]] = None) -> List[Dict]:
        """
        ìµœì í™”ëœ ë²¡í„° ê¸°ë°˜ ê´€ê´‘ì§€ ì¶”ì²œ
        ì‚¬ì „ ìƒì„±ëœ ë²¡í„° ìºì‹œ ì‚¬ìš©ìœ¼ë¡œ API í˜¸ì¶œ ìµœì†Œí™”
        """
        print(f"ðŸš€ ìµœì í™”ëœ ë²¡í„° ê¸°ë°˜ ê´€ê´‘ì§€ ì¶”ì²œ ì‹œìž‘")
        print(f"   - ëŒ€ìƒ ì§€ì—­: {region}")
        print(f"   - ì‚¬ìš©ìž ì—¬í–‰ ìŠ¤íƒ€ì¼: {user_travel_styles}")
        print(f"   - ì‚¬ìš©ìž í’ê²½ ì„ í˜¸: {user_landscapes}")
        
        # 1. ì‚¬ìš©ìž ì„ í˜¸ë„ ë²¡í„° ìƒì„± (API í˜¸ì¶œ 1ë²ˆë§Œ)
        user_keywords = user_travel_styles + (user_landscapes if user_landscapes else [])
        user_preference_text = " ".join(user_keywords)
        print(f"   - ì‚¬ìš©ìž ì„ í˜¸ë„ í…ìŠ¤íŠ¸: '{user_preference_text}'")
        
        user_vector = self.openai_service.get_embedding(user_preference_text)
        
        # 2. ìºì‹œëœ ë²¡í„°ë¡œ ìœ ì‚¬ë„ ê³„ì‚° (API í˜¸ì¶œ 0ë²ˆ)
        similar_attractions = self.vector_cache.find_similar_attractions(
            user_vector, region=region, top_k=50
        )
        
        print(f"ðŸŽ¯ ìºì‹œì—ì„œ {len(similar_attractions)}ê°œ ê´€ê´‘ì§€ ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ")
        
        if not similar_attractions:
            print(f"âš ï¸  {region} ì§€ì—­ì˜ ê´€ê´‘ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # 3. ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²°ê³¼ êµ¬ì„±
        attraction_results = []
        
        for attraction_data, similarity_score in similar_attractions:
            # ê¹€ì œì§€í‰ì„ ì¶•ì œ íŠ¹ë³„ ì²˜ë¦¬
            if 'ê¹€ì œì§€í‰ì„ ì¶•ì œ' in attraction_data.get('name', ''):
                similarity_score = 1.0  # ìµœê³  ì ìˆ˜ ë³´ìž¥
            
            # ê´€ê´‘ì§€ ì •ë³´ êµ¬ì„±
            attraction_dict = {
                'name': attraction_data.get('name'),
                'region': attraction_data.get('region'),
                'contentid': attraction_data.get('contentid'),
                'lat': attraction_data.get('lat'),
                'lon': attraction_data.get('lon'),
                'address_full': attraction_data.get('address_full'),
                'landscape_keywords': attraction_data.get('landscape_keywords'),
                'travel_style_keywords': attraction_data.get('travel_style_keywords'),
                '_vector_score': similarity_score,
                '_attraction_text': attraction_data.get('text', '')
            }
            
            attraction_results.append(attraction_dict)
        
        # 4. ì ìˆ˜ìˆœ ì •ë ¬ (ì´ë¯¸ ì •ë ¬ë˜ì–´ ìžˆì§€ë§Œ ê¹€ì œì§€í‰ì„ ì¶•ì œ ì²˜ë¦¬ ë•Œë¬¸ì— ìž¬ì •ë ¬)
        attraction_results.sort(key=lambda x: x['_vector_score'], reverse=True)
        
        # 5. ìƒìœ„ ì ìˆ˜ ì¶œë ¥
        print(f"ðŸ† ìµœì í™”ëœ ë²¡í„° ê¸°ë°˜ ìƒìœ„ ê´€ê´‘ì§€ ì ìˆ˜:")
        for i, attr in enumerate(attraction_results[:5]):
            print(f"   {i+1}. {attr['name']}: {attr['_vector_score']:.3f}")
        
        # 6. ì´ë¯¸ì§€ í•„í„°ë§
        print(f"ðŸ–¼ï¸  ì´ë¯¸ì§€ í•„í„°ë§ ì‹œìž‘: {len(attraction_results)}ê°œ ê´€ê´‘ì§€ í™•ì¸")
        
        filtered_attractions = []
        for i, attraction in enumerate(attraction_results):
            if len(filtered_attractions) >= 20:  # ìƒìœ„ 20ê°œê¹Œì§€ë§Œ
                break
                
            contentid = attraction.get('contentid')
            if contentid:
                print(f"   {i+1}. {attraction['name']} (ID: {contentid}) - ì´ë¯¸ì§€ í™•ì¸ì¤‘...")
                
                image_url = fetch_detail_image(contentid)
                if image_url:
                    print(f"      âœ… ì´ë¯¸ì§€ ìžˆìŒ")
                    attraction['image_url'] = image_url
                    filtered_attractions.append(attraction)
                else:
                    print(f"      âŒ ì´ë¯¸ì§€ ì—†ìŒ")
            else:
                print(f"   {i+1}. {attraction['name']}: ContentID ì—†ìŒ")
        
        print(f"ðŸ–¼ï¸  ì´ë¯¸ì§€ í•„í„°ë§ ì™„ë£Œ: {len(filtered_attractions)}ê°œ ê´€ê´‘ì§€")
        
        return filtered_attractions
    
    def get_recommendations(self, natural_request: str, preferences: Dict[str, List[str]]) -> Dict[str, Any]:
        """
        ìµœì í™”ëœ ì¶”ì²œ ì‹œìŠ¤í…œ ë©”ì¸ í•¨ìˆ˜
        """
        
        print(f"ðŸš€ ìµœì í™”ëœ ë²¡í„° ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œìž‘: {natural_request}")
        print(f"ë²¡í„° ìºì‹œ ìƒíƒœ: {self.vector_cache.get_cache_info()}")
        
        # 1. LLMìœ¼ë¡œ ìžì—°ì–´ ì˜ë„ ì¶”ì¶œ (ê¸°ì¡´ê³¼ ë™ì¼)
        extracted_intent = self.openai_service.extract_intent_from_natural_text(natural_request)
        
        # 2. LLM ê²°ê³¼ì™€ ê¸°ì¡´ ì„ í˜¸ë„ í†µí•© (ê¸°ì¡´ê³¼ ë™ì¼)
        try:
            enhanced_keywords = self.openai_service.enhance_keywords_with_context(extracted_intent, preferences)
            if not enhanced_keywords:
                enhanced_keywords = {
                    'travel_style_keywords': preferences.get('travel_style_keywords', []),
                    'landscape_keywords': preferences.get('landscape_keywords', []),
                    'job_type_keywords': preferences.get('job_type_keywords', []),
                    'activity_keywords': [],
                    'seasonal_keywords': []
                }
        except Exception as e:
            print(f"âŒ enhance_keywords_with_context ì˜¤ë¥˜: {e}")
            enhanced_keywords = {
                'travel_style_keywords': preferences.get('travel_style_keywords', []),
                'landscape_keywords': preferences.get('landscape_keywords', []),
                'job_type_keywords': preferences.get('job_type_keywords', []),
                'activity_keywords': [],
                'seasonal_keywords': []
            }
        
        # 3. ì§€ì—­ ê²°ì • (ê¸°ì¡´ê³¼ ë™ì¼)
        target_region = extracted_intent.get("ì§€ì—­")
        if not target_region:
            target_region = extract_region_from_natural_text(natural_request)
            
        if not target_region:
            return {
                "status": "error",
                "error_code": "INVALID_REGION",
                "message": "ì „ë¶ ì§€ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ë¶ ì§€ì—­ëª…ì„ í¬í•¨í•´ ì£¼ì„¸ìš”.",
                "available_regions": ["ê³ ì°½êµ°", "êµ°ì‚°ì‹œ", "ê¹€ì œì‹œ", "ë‚¨ì›ì‹œ", "ë¬´ì£¼êµ°", "ë¶€ì•ˆêµ°", 
                                    "ìˆœì°½êµ°", "ì™„ì£¼êµ°", "ìµì‚°ì‹œ", "ìž„ì‹¤êµ°", "ìž¥ìˆ˜êµ°", "ì „ì£¼ì‹œ", "ì •ìì‹œ", "ì§„ì•ˆêµ°"]
            }
        
        print(f"ðŸŽ¯ ê²°ì •ëœ ëŒ€ìƒ ì§€ì—­: {target_region}")
        
        # 4. ë†ê°€ ì¶”ì²œ (ê¸°ì¡´ í‚¤ì›Œë“œ ë°©ì‹ ìœ ì§€)
        all_farms = self._load_farms_data()
        regional_farms = self._filter_farms_by_region(all_farms, target_region)
        
        combined_job_keywords = enhanced_keywords.get('job_type_keywords', []) + \
                               enhanced_keywords.get('activity_keywords', []) + \
                               enhanced_keywords.get('seasonal_keywords', [])
        
        recommended_farms = self._match_farms_by_job_keywords(regional_farms, combined_job_keywords)
        
        # 5. âœ¨ ìµœì í™”ëœ ë²¡í„° ê¸°ë°˜ ê´€ê´‘ì§€ ì¶”ì²œ âœ¨
        user_travel_styles = preferences.get('travel_style_keywords', [])
        user_landscapes = preferences.get('landscape_keywords', [])
        
        enhanced_travel_styles = enhanced_keywords.get('travel_style_keywords', [])
        final_travel_styles = list(set(user_travel_styles + enhanced_travel_styles))
        
        # ìºì‹œ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì‚¬ìš©
        scored_attractions = self._get_optimized_vector_attractions(
            target_region, final_travel_styles, user_landscapes
        )
        
        print(f"âœ… ìµœì í™”ëœ ë²¡í„° ì¶”ì²œ ì™„ë£Œ: {len(scored_attractions)}ê°œ ê´€ê´‘ì§€")
        
        # ìƒìœ„ 5ê°œë¥¼ ì¹´ë“œìš©ìœ¼ë¡œ ì„ íƒ
        recommended_attractions = scored_attractions[:5]
        
        # 6. í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ê¸°ì¡´ê³¼ ë™ì¼)
        farm_cards = []
        for i, farm in enumerate(recommended_farms):
            farm_cards.append({
                "farm_id": f"farm_{i}",
                "farm": farm.get("farm", ""),
                "title": farm.get("title", ""),
                "address": farm.get("address", ""),
                "start_time": farm.get("start_time", "08:00"),
                "end_time": farm.get("end_time", "17:00"),
                "photo": f"/public/images/jobs/{farm.get('image', 'demo_image.jpg')}",
                "required_people": farm.get("required_people", "")
            })
        
        tour_cards = []
        for i, attraction in enumerate(recommended_attractions):
            region = attraction.get("region", "")
            address_full = attraction.get("address_full", "")
            addr1 = attraction.get("addr1", "")
            
            display_address = ""
            if addr1 and addr1 != "ì „ë¶íŠ¹ë³„ìžì¹˜ë„":
                display_address = addr1
            elif region:
                display_address = f"ì „ë¶ {region}"
            elif address_full:
                display_address = address_full
            else:
                display_address = region
            
            tour_cards.append({
                "tour_id": f"tour_{i}",
                "name": attraction.get("name", ""),
                "address": display_address,
                "photo": attraction.get("image_url", "/public/images/tours/demo_image.jpg"),
                "lat": attraction.get("lat", ""),
                "lon": attraction.get("lon", ""),
                "contentid": attraction.get("contentid", ""),
                "_vector_score": attraction.get("_vector_score", 0.0)  # ë””ë²„ê¹…ìš©
            })
        
        # 7. ê²°ê³¼ ë°˜í™˜
        return {
            "status": "success", 
            "data": {
                "recommended_farms": farm_cards,
                "recommended_attractions": tour_cards,
                "target_region": target_region,
                "natural_request": natural_request,
                "preferences": preferences,
                "llm_analysis": {
                    "extracted_intent": extracted_intent,
                    "confidence": extracted_intent.get("ì‹ ë¢°ë„", 0.0),
                    "enhanced_keywords": enhanced_keywords,
                    "region_source": "llm" if extracted_intent.get("ì§€ì—­") else "fallback"
                },
                "performance_info": {
                    "vector_cache_used": True,
                    "api_calls_saved": len(scored_attractions),  # ì ˆì•½ëœ API í˜¸ì¶œ ìˆ˜
                    "cache_status": self.vector_cache.get_cache_info()
                },
                "scored_attractions": scored_attractions
            }
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_service = None

def get_optimized_vector_recommendation_service() -> OptimizedVectorRecommendationService:
    """OptimizedVectorRecommendationService ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _service
    if _service is None:
        _service = OptimizedVectorRecommendationService()
    return _service