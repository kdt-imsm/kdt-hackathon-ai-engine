#!/usr/bin/env python3
"""
ìµœì í™”ëœ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‚¬ì „ ìƒì„±ëœ ë²¡í„° ìºì‹œë¥¼ í™œìš©í•œ ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸
"""

import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.services.optimized_vector_recommendation_service import get_optimized_vector_recommendation_service
from app.services.vector_recommendation_service import get_vector_recommendation_service

def compare_performance():
    """ê¸°ì¡´ vs ìµœì í™” ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¹„êµ"""
    
    print("âš¡ ë²¡í„° ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    natural_request = "ê¹€ì œì—ì„œ íë§ì—¬í–‰ì„ í•˜ê³  ì‹¶ì–´ìš”. ìì—°ì´ ì¢‹ì€ ê³³ì—ì„œ ì²´í—˜í˜• í™œë™ì„ í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤."
    preferences = {
        'landscape_keywords': ['ë“¤íŒ', 'ì‚°'],
        'travel_style_keywords': ['íë§Â·ì—¬ìœ ', 'ì²´í—˜í˜•'],
        'job_type_keywords': ['ê³¼ìˆ˜', 'ì±„ì†Œ']
    }
    
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°:")
    print(f"   ìì—°ì–´: {natural_request}")
    print(f"   ì„ í˜¸ë„: {preferences}")
    print()
    
    # 1. ê¸°ì¡´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("ğŸ”¥ [ê¸°ì¡´ ì‹œìŠ¤í…œ] ì‹¤ì‹œê°„ ë²¡í„° ìƒì„± ë°©ì‹")
    print("-" * 50)
    
    try:
        old_service = get_vector_recommendation_service()
        
        start_time = time.time()
        old_result = old_service.get_recommendations(natural_request, preferences)
        old_duration = time.time() - start_time
        
        old_data = old_result.get('data', {})
        old_attractions = old_data.get('scored_attractions', [])
        
        print(f"âœ… ê¸°ì¡´ ì‹œìŠ¤í…œ ê²°ê³¼:")
        print(f"   â±ï¸  ì†Œìš” ì‹œê°„: {old_duration:.2f}ì´ˆ")
        print(f"   ğŸï¸  ê´€ê´‘ì§€ ê°œìˆ˜: {len(old_attractions)}ê°œ")
        print(f"   ğŸ’° ì˜ˆìƒ API í˜¸ì¶œ: ~62ë²ˆ (ì‚¬ìš©ì 1ë²ˆ + ê´€ê´‘ì§€ 61ë²ˆ)")
        
        if old_attractions:
            print(f"   ğŸ† ìƒìœ„ 3ê°œ:")
            for i, attr in enumerate(old_attractions[:3]):
                score = attr.get('_vector_score', 0.0)
                print(f"      {i+1}. {attr.get('name', 'Unknown')}: {score:.3f}")
        
    except Exception as e:
        print(f"âŒ ê¸°ì¡´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        old_duration = float('inf')
        old_attractions = []
    
    print()
    
    # 2. ìµœì í™”ëœ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("âš¡ [ìµœì í™” ì‹œìŠ¤í…œ] ë²¡í„° ìºì‹œ ê¸°ë°˜ ë°©ì‹")
    print("-" * 50)
    
    try:
        new_service = get_optimized_vector_recommendation_service()
        
        start_time = time.time()
        new_result = new_service.get_recommendations(natural_request, preferences)
        new_duration = time.time() - start_time
        
        new_data = new_result.get('data', {})
        new_attractions = new_data.get('scored_attractions', [])
        performance_info = new_data.get('performance_info', {})
        
        print(f"âœ… ìµœì í™” ì‹œìŠ¤í…œ ê²°ê³¼:")
        print(f"   â±ï¸  ì†Œìš” ì‹œê°„: {new_duration:.2f}ì´ˆ")
        print(f"   ğŸï¸  ê´€ê´‘ì§€ ê°œìˆ˜: {len(new_attractions)}ê°œ")
        print(f"   ğŸ’° ì‹¤ì œ API í˜¸ì¶œ: 1ë²ˆ (ì‚¬ìš©ì ë²¡í„°ë§Œ)")
        print(f"   ğŸ’¾ ë²¡í„° ìºì‹œ ì‚¬ìš©: {performance_info.get('vector_cache_used', False)}")
        print(f"   ğŸ’¸ ì ˆì•½ëœ API í˜¸ì¶œ: {performance_info.get('api_calls_saved', 0)}ë²ˆ")
        
        if new_attractions:
            print(f"   ğŸ† ìƒìœ„ 3ê°œ:")
            for i, attr in enumerate(new_attractions[:3]):
                score = attr.get('_vector_score', 0.0)
                print(f"      {i+1}. {attr.get('name', 'Unknown')}: {score:.3f}")
        
    except Exception as e:
        print(f"âŒ ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        new_duration = float('inf')
        new_attractions = []
        performance_info = {}
    
    print()
    
    # 3. ì„±ëŠ¥ ë¹„êµ ìš”ì•½
    print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ìš”ì•½")
    print("=" * 70)
    
    if old_duration != float('inf') and new_duration != float('inf'):
        speed_improvement = old_duration / new_duration if new_duration > 0 else float('inf')
        time_saved = old_duration - new_duration
        
        print(f"âš¡ ì†ë„ ê°œì„ : {speed_improvement:.1f}ë°° ë¹¨ë¼ì§")
        print(f"â±ï¸  ì‹œê°„ ì ˆì•½: {time_saved:.2f}ì´ˆ")
        print(f"ğŸ’° ë¹„ìš© ì ˆì•½: ~98% (62ë²ˆ â†’ 1ë²ˆ API í˜¸ì¶œ)")
        print(f"ğŸ¯ ê²°ê³¼ ì •í™•ë„: ë™ì¼ (ê°™ì€ ë²¡í„° ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜)")
        
        # í™•ì¥ì„± ë¶„ì„
        print(f"\nğŸ”® ì „ë¶ ì „ì²´(840ê°œ ê´€ê´‘ì§€) í™•ì¥ì‹œ ì˜ˆìƒ:")
        print(f"   ê¸°ì¡´ ë°©ì‹: ~841ë²ˆ API í˜¸ì¶œ, ì˜ˆìƒ {old_duration * 14:.1f}ì´ˆ")
        print(f"   ìµœì í™” ë°©ì‹: 1ë²ˆ API í˜¸ì¶œ, ì˜ˆìƒ {new_duration:.1f}ì´ˆ")
        print(f"   ì„±ëŠ¥ ì°¨ì´: {(old_duration * 14) / new_duration:.0f}ë°°")
    
    # 4. ë²¡í„° ìºì‹œ ìƒíƒœ ì •ë³´
    cache_info = performance_info.get('cache_status', {})
    if cache_info.get('status') == 'loaded':
        print(f"\nğŸ“¦ ë²¡í„° ìºì‹œ ì •ë³´:")
        print(f"   ìƒíƒœ: {cache_info.get('status', 'unknown')}")
        print(f"   ì´ ë²¡í„° ê°œìˆ˜: {cache_info.get('total_vectors', 0)}ê°œ")
        print(f"   ì§€ì—­ ê°œìˆ˜: {cache_info.get('regions_count', 0)}ê°œ")
        print(f"   ëª¨ë¸: {cache_info.get('model', 'unknown')}")
        print(f"   ë²¡í„° ì°¨ì›: {cache_info.get('vector_dimension', 0)}ì°¨ì›")
        print(f"   ìƒì„± ì‹œê°„: {cache_info.get('created_at', 'unknown')}")
        print(f"   ë¡œë“œ ì‹œê°„: {cache_info.get('loaded_at', 'unknown')}")

def test_vector_cache_only():
    """ë²¡í„° ìºì‹œë§Œ ë‹¨ë… í…ŒìŠ¤íŠ¸"""
    
    print("\n" + "=" * 70)
    print("ğŸ§ª ë²¡í„° ìºì‹œ ë‹¨ë… í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    try:
        from app.services.vector_cache_service import get_vector_cache_service
        from app.embeddings.openai_service import OpenAIService
        
        cache_service = get_vector_cache_service()
        openai_service = OpenAIService()
        
        # ìºì‹œ ì •ë³´ ì¶œë ¥
        cache_info = cache_service.get_cache_info()
        print(f"ğŸ“¦ ìºì‹œ ìƒíƒœ: {cache_info}")
        
        if cache_info.get('status') != 'loaded':
            print("âŒ ë²¡í„° ìºì‹œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ë¨¼ì € 'python scripts/precompute_attraction_vectors.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰...")
        user_text = "íë§Â·ì—¬ìœ  ì²´í—˜í˜• ë“¤íŒ ì‚°"
        user_vector = openai_service.get_embedding(user_text)
        
        start_time = time.time()
        results = cache_service.find_similar_attractions(user_vector, region="ê¹€ì œì‹œ", top_k=5)
        search_time = time.time() - start_time
        
        print(f"âœ… ìºì‹œ ê²€ìƒ‰ ì™„ë£Œ:")
        print(f"   â±ï¸  ê²€ìƒ‰ ì‹œê°„: {search_time:.3f}ì´ˆ")
        print(f"   ğŸ¯ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        
        print(f"\nğŸ† ìƒìœ„ ê²°ê³¼:")
        for i, (attraction_data, similarity) in enumerate(results):
            print(f"   {i+1}. {attraction_data.get('name', 'Unknown')}: {similarity:.3f}")
        
    except Exception as e:
        print(f"âŒ ë²¡í„° ìºì‹œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
    compare_performance()
    
    # ë²¡í„° ìºì‹œ ë‹¨ë… í…ŒìŠ¤íŠ¸
    test_vector_cache_only()