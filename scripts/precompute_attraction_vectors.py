#!/usr/bin/env python3
"""
ê´€ê´‘ì§€ ë²¡í„° ì‚¬ì „ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
ëª¨ë“  ê´€ê´‘ì§€ ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥
"""

import sys
import json
import csv
from pathlib import Path
from typing import List, Dict, Any
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.embeddings.openai_service import OpenAIService

def load_all_attractions_data() -> List[Dict[str, Any]]:
    """ì „ë¶ ëª¨ë“  ì§€ì—­ì˜ ê´€ê´‘ì§€ ë°ì´í„° ë¡œë“œ"""
    
    data_dir = project_root / "data"
    all_attractions = []
    
    # ì „ë¶ 14ê°œ ì‹œêµ°
    regions = [
        "ê³ ì°½êµ°", "êµ°ì‚°ì‹œ", "ê¹€ì œì‹œ", "ë‚¨ì›ì‹œ", "ë¬´ì£¼êµ°", "ë¶€ì•ˆêµ°",
        "ìˆœì°½êµ°", "ì™„ì£¼êµ°", "ìµì‚°ì‹œ", "ì„ì‹¤êµ°", "ì¥ìˆ˜êµ°", "ì „ì£¼ì‹œ", "ì •ìì‹œ", "ì§„ì•ˆêµ°"
    ]
    
    for region in regions:
        csv_file = data_dir / f"jeonbuk_{region}_attractions.csv"
        
        if csv_file.exists():
            print(f"ğŸ“‚ {region} ê´€ê´‘ì§€ ë°ì´í„° ë¡œë“œ ì¤‘...")
            
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                region_attractions = []
                
                for row in reader:
                    attraction = dict(row)
                    attraction['region'] = region  # ì§€ì—­ ì •ë³´ ëª…ì‹œì  ì¶”ê°€
                    region_attractions.append(attraction)
                
                print(f"   âœ… {len(region_attractions)}ê°œ ê´€ê´‘ì§€ ë¡œë“œ")
                all_attractions.extend(region_attractions)
        else:
            print(f"   âŒ {csv_file} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    print(f"\nğŸ“Š ì „ì²´ ê´€ê´‘ì§€ ìˆ˜: {len(all_attractions)}ê°œ")
    return all_attractions

def create_attraction_text(attraction: Dict[str, Any]) -> str:
    """ê´€ê´‘ì§€ ì •ë³´ë¥¼ ë²¡í„°í™”ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    
    text_parts = []
    
    # ê¸°ë³¸ ì •ë³´
    if attraction.get('name'):
        text_parts.append(attraction['name'])
    
    # í‚¤ì›Œë“œ ì •ë³´
    if attraction.get('landscape_keywords'):
        text_parts.append(attraction['landscape_keywords'])
    
    if attraction.get('travel_style_keywords'):
        text_parts.append(attraction['travel_style_keywords'])
    
    # tagsê°€ ìˆë‹¤ë©´ ì¶”ê°€ (í–¥í›„ í™•ì¥ìš©)
    if attraction.get('tags'):
        text_parts.append(attraction['tags'])
    
    return " ".join(filter(None, text_parts))

def precompute_vectors_batch(attractions: List[Dict[str, Any]], batch_size: int = 100) -> Dict[str, Any]:
    """ê´€ê´‘ì§€ ë²¡í„°ë¥¼ ë°°ì¹˜ë¡œ ìƒì„±í•˜ì—¬ ì €ì¥"""
    
    print(f"ğŸ” ë²¡í„° ìƒì„± ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})")
    
    openai_service = OpenAIService()
    vectors_data = {
        "metadata": {
            "total_attractions": len(attractions),
            "vector_dimension": 1536,
            "model": "text-embedding-3-small",
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
        },
        "vectors": {}
    }
    
    # ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬
    for i in range(0, len(attractions), batch_size):
        batch = attractions[i:i + batch_size]
        batch_num = i // batch_size + 1
        total_batches = (len(attractions) + batch_size - 1) // batch_size
        
        print(f"\nğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ ê´€ê´‘ì§€)")
        
        for j, attraction in enumerate(batch):
            try:
                # ê´€ê´‘ì§€ ê³ ìœ  í‚¤ ìƒì„± (ì§€ì—­_ì´ë¦„_contentid)
                attraction_key = f"{attraction['region']}_{attraction['name']}_{attraction.get('contentid', 'no_id')}"
                
                # ë²¡í„°í™”ìš© í…ìŠ¤íŠ¸ ìƒì„±
                attraction_text = create_attraction_text(attraction)
                
                # ë²¡í„° ìƒì„±
                vector = openai_service.get_embedding(attraction_text)
                
                # ê²°ê³¼ ì €ì¥
                vectors_data["vectors"][attraction_key] = {
                    "name": attraction['name'],
                    "region": attraction['region'],
                    "contentid": attraction.get('contentid'),
                    "text": attraction_text,
                    "vector": vector,
                    "landscape_keywords": attraction.get('landscape_keywords'),
                    "travel_style_keywords": attraction.get('travel_style_keywords'),
                    "lat": attraction.get('lat'),
                    "lon": attraction.get('lon'),
                    "address_full": attraction.get('address_full')
                }
                
                print(f"   âœ… {j+1:2d}. {attraction['name']} (ë²¡í„° í¬ê¸°: {len(vector)})")
                
                # API í˜¸ì¶œ ì œí•œ ê³ ë ¤í•œ ì§€ì—°
                time.sleep(0.1)
                
            except Exception as e:
                print(f"   âŒ {j+1:2d}. {attraction['name']}: ë²¡í„° ìƒì„± ì‹¤íŒ¨ - {e}")
                continue
    
    print(f"\nâœ… ë²¡í„° ìƒì„± ì™„ë£Œ: {len(vectors_data['vectors'])}ê°œ")
    return vectors_data

def save_vectors_to_file(vectors_data: Dict[str, Any], output_path: Path):
    """ë²¡í„° ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    
    print(f"ğŸ’¾ ë²¡í„° ë°ì´í„° ì €ì¥ ì¤‘: {output_path}")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(vectors_data, f, ensure_ascii=False, indent=2)
    
    file_size_mb = output_path.stat().st_size / (1024 * 1024)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {file_size_mb:.2f}MB")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ ê´€ê´‘ì§€ ë²¡í„° ì‚¬ì „ ìƒì„± ì‹œì‘")
    print("=" * 60)
    
    # 1. ê´€ê´‘ì§€ ë°ì´í„° ë¡œë“œ
    attractions = load_all_attractions_data()
    
    if not attractions:
        print("âŒ ë¡œë“œí•  ê´€ê´‘ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 2. ë²¡í„° ìƒì„±
    vectors_data = precompute_vectors_batch(attractions, batch_size=50)
    
    # 3. íŒŒì¼ë¡œ ì €ì¥
    output_path = project_root / "data" / "attraction_vectors.json"
    save_vectors_to_file(vectors_data, output_path)
    
    print("\nğŸ‰ ê´€ê´‘ì§€ ë²¡í„° ì‚¬ì „ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {output_path}")
    print(f"ğŸ“Š ì´ ë²¡í„° ê°œìˆ˜: {len(vectors_data['vectors'])}ê°œ")

if __name__ == "__main__":
    main()